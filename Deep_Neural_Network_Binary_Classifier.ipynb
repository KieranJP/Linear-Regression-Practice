{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Neural Network Binary Classifier",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KieranJP/Linear-Regression-Practice/blob/master/Deep_Neural_Network_Binary_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "taMS2EsFt6hm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**This allows me to upload the csv files used as the training and the test data fom my PC:**"
      ]
    },
    {
      "metadata": {
        "id": "s55CvUy25TWe",
        "colab_type": "code",
        "outputId": "62cf4aa2-a29a-401f-a205-09407ce93a0a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "#Uploading Test Data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-49be3ddd-ec0d-484a-83e6-70de3a9d896c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-49be3ddd-ec0d-484a-83e6-70de3a9d896c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving FullELFFDataset.csv to FullELFFDataset.csv\n",
            "User uploaded file \"FullELFFDataset.csv\" with length 14744861 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i8BZisTk6HPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras as K\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "#Imports Required\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Selecting the Csv to use then Displaying it\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"FullELFFDataset.csv\")\n",
        "dataset.columns\n",
        "\n",
        "#Using sklearn's split function to split the data into training and testing data.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataset.values\n",
        "Y = dataset.Defective.values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8FEI3TuRC0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#Attempt at creating a Grid Search to optimise hyperparamter\n",
        "\n",
        "def create_model(batch=64, epoch=500, optimizer='adam', learn_rate=0.001, activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(K.layers.Dense(units=40, input_dim=40, activation='relu', kernel_initializer='truncated_normal')) \n",
        "  model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal')) \n",
        "  model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal'))\n",
        "  model.add(K.layers.Dense(units=1, activation='sigmoid', kernel_initializer='truncated_normal'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bnhCoMHUYpni",
        "colab_type": "code",
        "outputId": "01c8b080-f96b-4c56-d384-451bcaaadecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "hparamsBatch = [64, 128, 256]\n",
        "hparamsEpoch = [500, 1000]\n",
        "hparamsLR = [0.0001, 0.001, 0.01]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "#Defining the Range\n",
        "param_grid = dict(batch_size=hparamsBatch,\n",
        "                  epochs=hparamsEpoch,\n",
        "                  learn_rate=hparamsLR)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=18,\n",
        "                    cv=3,\n",
        "                    scoring='accuracy',\n",
        "                    verbose=10)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "#CREATE A SMALLER SAMPLE TO GRID SEARCH TO IMPROVE TIME\n",
        "\n",
        "# Show the results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=18)]: Using backend LokyBackend with 18 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=18)]: Done   3 out of  18 | elapsed: 105.3min remaining: 526.5min\n",
            "[Parallel(n_jobs=18)]: Done   5 out of  18 | elapsed: 110.1min remaining: 286.3min\n",
            "[Parallel(n_jobs=18)]: Done   7 out of  18 | elapsed: 119.6min remaining: 187.9min\n",
            "[Parallel(n_jobs=18)]: Done   9 out of  18 | elapsed: 119.7min remaining: 119.7min\n",
            "[Parallel(n_jobs=18)]: Done  11 out of  18 | elapsed: 180.2min remaining: 114.7min\n",
            "[Parallel(n_jobs=18)]: Done  13 out of  18 | elapsed: 180.9min remaining: 69.6min\n",
            "[Parallel(n_jobs=18)]: Done  15 out of  18 | elapsed: 181.1min remaining: 36.2min\n",
            "[Parallel(n_jobs=18)]: Done  18 out of  18 | elapsed: 181.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.951352 using {'batch_size': 64, 'epochs': 1000, 'learn_rate': 0.01}\n",
            "0.951308 (0.001095) with: {'batch_size': 64, 'epochs': 500, 'learn_rate': 0.0001}\n",
            "0.951264 (0.001146) with: {'batch_size': 64, 'epochs': 500, 'learn_rate': 0.001}\n",
            "0.951235 (0.001149) with: {'batch_size': 64, 'epochs': 500, 'learn_rate': 0.01}\n",
            "0.951250 (0.001133) with: {'batch_size': 64, 'epochs': 1000, 'learn_rate': 0.0001}\n",
            "0.951235 (0.001149) with: {'batch_size': 64, 'epochs': 1000, 'learn_rate': 0.001}\n",
            "0.951352 (0.001021) with: {'batch_size': 64, 'epochs': 1000, 'learn_rate': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oOiTuEbyUMW9",
        "colab_type": "code",
        "outputId": "93c04f8a-99bc-49a6-beac-2fc1a297ea44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#Creates a NN\n",
        "model = Sequential()\n",
        "#Input Layer\n",
        "model.add(K.layers.Dense(units=40, input_dim=40, activation='relu', kernel_initializer='truncated_normal')) \n",
        "#Hidden Layers\n",
        "model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal')) \n",
        "model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal'))\n",
        "#Output Layers\n",
        "model.add(K.layers.Dense(units=1, activation='sigmoid', kernel_initializer='truncated_normal'))\n",
        "\n",
        "simple_sgd = K.optimizers.Adam(lr=0.00001)  \n",
        "model.compile(loss='binary_crossentropy', optimizer=simple_sgd, metrics=['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TA4leyXvYfp1",
        "colab_type": "code",
        "outputId": "79d0f6b5-72a8-4edd-e08e-faf72d058872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34085
        }
      },
      "cell_type": "code",
      "source": [
        "#Find out the size of each class so can change weighting\n",
        "trueWeight = len(Y_train[Y_train==False])\n",
        "falseWeight = len(Y_train[Y_train==True])\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=64, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 54924 samples, validate on 13732 samples\n",
            "Epoch 1/1000\n",
            "54924/54924 [==============================] - 2s 38us/step - loss: 0.8238 - acc: 0.7278 - val_loss: 0.5758 - val_acc: 0.9513\n",
            "Epoch 2/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.4922 - acc: 0.9496 - val_loss: 0.3797 - val_acc: 0.9511\n",
            "Epoch 3/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.3205 - acc: 0.9495 - val_loss: 0.2661 - val_acc: 0.9511\n",
            "Epoch 4/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2572 - acc: 0.9481 - val_loss: 0.2330 - val_acc: 0.9512\n",
            "Epoch 5/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2328 - acc: 0.9490 - val_loss: 0.2180 - val_acc: 0.9511\n",
            "Epoch 6/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2259 - acc: 0.9474 - val_loss: 0.2125 - val_acc: 0.9510\n",
            "Epoch 7/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2133 - acc: 0.9491 - val_loss: 0.2112 - val_acc: 0.9484\n",
            "Epoch 8/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2108 - acc: 0.9485 - val_loss: 0.2008 - val_acc: 0.9502\n",
            "Epoch 9/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2093 - acc: 0.9482 - val_loss: 0.2039 - val_acc: 0.9512\n",
            "Epoch 10/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2027 - acc: 0.9492 - val_loss: 0.1909 - val_acc: 0.9508\n",
            "Epoch 11/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2016 - acc: 0.9489 - val_loss: 0.2469 - val_acc: 0.9341\n",
            "Epoch 12/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.2016 - acc: 0.9488 - val_loss: 0.2211 - val_acc: 0.9512\n",
            "Epoch 13/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1968 - acc: 0.9486 - val_loss: 0.2936 - val_acc: 0.9205\n",
            "Epoch 14/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1977 - acc: 0.9491 - val_loss: 0.1868 - val_acc: 0.9506\n",
            "Epoch 15/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1980 - acc: 0.9490 - val_loss: 0.2524 - val_acc: 0.9511\n",
            "Epoch 16/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1951 - acc: 0.9489 - val_loss: 0.1931 - val_acc: 0.9509\n",
            "Epoch 17/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1950 - acc: 0.9484 - val_loss: 0.1869 - val_acc: 0.9511\n",
            "Epoch 18/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.2003 - acc: 0.9480 - val_loss: 0.1875 - val_acc: 0.9511\n",
            "Epoch 19/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1933 - acc: 0.9497 - val_loss: 0.1950 - val_acc: 0.9510\n",
            "Epoch 20/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1951 - acc: 0.9488 - val_loss: 0.1825 - val_acc: 0.9511\n",
            "Epoch 21/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1930 - acc: 0.9482 - val_loss: 0.1864 - val_acc: 0.9497\n",
            "Epoch 22/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1974 - acc: 0.9485 - val_loss: 0.1863 - val_acc: 0.9510\n",
            "Epoch 23/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1876 - acc: 0.9498 - val_loss: 0.1836 - val_acc: 0.9510\n",
            "Epoch 24/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1862 - acc: 0.9493 - val_loss: 0.1848 - val_acc: 0.9511\n",
            "Epoch 25/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1911 - acc: 0.9483 - val_loss: 0.1798 - val_acc: 0.9513\n",
            "Epoch 26/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1923 - acc: 0.9479 - val_loss: 0.1870 - val_acc: 0.9470\n",
            "Epoch 27/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1876 - acc: 0.9494 - val_loss: 0.1802 - val_acc: 0.9506\n",
            "Epoch 28/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1840 - acc: 0.9495 - val_loss: 0.2065 - val_acc: 0.9511\n",
            "Epoch 29/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2020 - acc: 0.9489 - val_loss: 0.1904 - val_acc: 0.9512\n",
            "Epoch 30/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1845 - acc: 0.9498 - val_loss: 0.1790 - val_acc: 0.9512\n",
            "Epoch 31/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1853 - acc: 0.9492 - val_loss: 0.1775 - val_acc: 0.9513\n",
            "Epoch 32/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1863 - acc: 0.9499 - val_loss: 0.1762 - val_acc: 0.9512\n",
            "Epoch 33/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1833 - acc: 0.9499 - val_loss: 0.1757 - val_acc: 0.9512\n",
            "Epoch 34/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1861 - acc: 0.9494 - val_loss: 0.1756 - val_acc: 0.9516\n",
            "Epoch 35/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1816 - acc: 0.9502 - val_loss: 0.2162 - val_acc: 0.9374\n",
            "Epoch 36/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1828 - acc: 0.9493 - val_loss: 0.1753 - val_acc: 0.9510\n",
            "Epoch 37/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1842 - acc: 0.9496 - val_loss: 0.1840 - val_acc: 0.9511\n",
            "Epoch 38/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1924 - acc: 0.9493 - val_loss: 0.1873 - val_acc: 0.9460\n",
            "Epoch 39/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1865 - acc: 0.9489 - val_loss: 0.1815 - val_acc: 0.9514\n",
            "Epoch 40/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1919 - acc: 0.9495 - val_loss: 0.2225 - val_acc: 0.9511\n",
            "Epoch 41/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1910 - acc: 0.9485 - val_loss: 0.1746 - val_acc: 0.9515\n",
            "Epoch 42/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1939 - acc: 0.9486 - val_loss: 0.1921 - val_acc: 0.9428\n",
            "Epoch 43/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1829 - acc: 0.9489 - val_loss: 0.1773 - val_acc: 0.9514\n",
            "Epoch 44/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1901 - acc: 0.9484 - val_loss: 0.1761 - val_acc: 0.9500\n",
            "Epoch 45/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1848 - acc: 0.9487 - val_loss: 0.1783 - val_acc: 0.9514\n",
            "Epoch 46/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1813 - acc: 0.9497 - val_loss: 0.1825 - val_acc: 0.9513\n",
            "Epoch 47/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1852 - acc: 0.9493 - val_loss: 0.2749 - val_acc: 0.9251\n",
            "Epoch 48/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1871 - acc: 0.9488 - val_loss: 0.2408 - val_acc: 0.9333\n",
            "Epoch 49/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1845 - acc: 0.9500 - val_loss: 0.2231 - val_acc: 0.9358\n",
            "Epoch 50/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1883 - acc: 0.9493 - val_loss: 0.1843 - val_acc: 0.9513\n",
            "Epoch 51/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1859 - acc: 0.9497 - val_loss: 0.1725 - val_acc: 0.9504\n",
            "Epoch 52/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1899 - acc: 0.9491 - val_loss: 0.1975 - val_acc: 0.9408\n",
            "Epoch 53/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1786 - acc: 0.9501 - val_loss: 0.1805 - val_acc: 0.9514\n",
            "Epoch 54/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1830 - acc: 0.9491 - val_loss: 0.1724 - val_acc: 0.9516\n",
            "Epoch 55/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1794 - acc: 0.9493 - val_loss: 0.1723 - val_acc: 0.9513\n",
            "Epoch 56/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1844 - acc: 0.9491 - val_loss: 0.1728 - val_acc: 0.9514\n",
            "Epoch 57/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1800 - acc: 0.9493 - val_loss: 0.1758 - val_acc: 0.9512\n",
            "Epoch 58/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1880 - acc: 0.9497 - val_loss: 0.1752 - val_acc: 0.9484\n",
            "Epoch 59/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1828 - acc: 0.9496 - val_loss: 0.1782 - val_acc: 0.9513\n",
            "Epoch 60/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1836 - acc: 0.9502 - val_loss: 0.1738 - val_acc: 0.9511\n",
            "Epoch 61/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1780 - acc: 0.9495 - val_loss: 0.1713 - val_acc: 0.9514\n",
            "Epoch 62/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1823 - acc: 0.9490 - val_loss: 0.1766 - val_acc: 0.9512\n",
            "Epoch 63/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1815 - acc: 0.9498 - val_loss: 0.1741 - val_acc: 0.9514\n",
            "Epoch 64/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1805 - acc: 0.9485 - val_loss: 0.2141 - val_acc: 0.9366\n",
            "Epoch 65/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1825 - acc: 0.9490 - val_loss: 0.1701 - val_acc: 0.9516\n",
            "Epoch 66/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1773 - acc: 0.9503 - val_loss: 0.2232 - val_acc: 0.9512\n",
            "Epoch 67/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1806 - acc: 0.9500 - val_loss: 0.1930 - val_acc: 0.9408\n",
            "Epoch 68/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1753 - acc: 0.9494 - val_loss: 0.1761 - val_acc: 0.9511\n",
            "Epoch 69/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1798 - acc: 0.9494 - val_loss: 0.1713 - val_acc: 0.9506\n",
            "Epoch 70/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1811 - acc: 0.9492 - val_loss: 0.1777 - val_acc: 0.9511\n",
            "Epoch 71/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1892 - acc: 0.9484 - val_loss: 0.1683 - val_acc: 0.9516\n",
            "Epoch 72/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1784 - acc: 0.9500 - val_loss: 0.1730 - val_acc: 0.9511\n",
            "Epoch 73/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1766 - acc: 0.9494 - val_loss: 0.3202 - val_acc: 0.9165\n",
            "Epoch 74/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1761 - acc: 0.9493 - val_loss: 0.1676 - val_acc: 0.9517\n",
            "Epoch 75/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1833 - acc: 0.9491 - val_loss: 0.1759 - val_acc: 0.9478\n",
            "Epoch 76/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1851 - acc: 0.9496 - val_loss: 0.1717 - val_acc: 0.9495\n",
            "Epoch 77/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1782 - acc: 0.9502 - val_loss: 0.1698 - val_acc: 0.9512\n",
            "Epoch 78/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1771 - acc: 0.9495 - val_loss: 0.1738 - val_acc: 0.9484\n",
            "Epoch 79/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1810 - acc: 0.9498 - val_loss: 0.1845 - val_acc: 0.9512\n",
            "Epoch 80/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1770 - acc: 0.9501 - val_loss: 0.2591 - val_acc: 0.9266\n",
            "Epoch 81/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1770 - acc: 0.9499 - val_loss: 0.1777 - val_acc: 0.9512\n",
            "Epoch 82/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1820 - acc: 0.9491 - val_loss: 0.1868 - val_acc: 0.9512\n",
            "Epoch 83/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1806 - acc: 0.9491 - val_loss: 0.1707 - val_acc: 0.9500\n",
            "Epoch 84/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1808 - acc: 0.9491 - val_loss: 0.1667 - val_acc: 0.9512\n",
            "Epoch 85/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1737 - acc: 0.9501 - val_loss: 0.1717 - val_acc: 0.9509\n",
            "Epoch 86/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1777 - acc: 0.9502 - val_loss: 0.1669 - val_acc: 0.9514\n",
            "Epoch 87/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1745 - acc: 0.9502 - val_loss: 0.1724 - val_acc: 0.9489\n",
            "Epoch 88/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1761 - acc: 0.9498 - val_loss: 0.1711 - val_acc: 0.9511\n",
            "Epoch 89/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1732 - acc: 0.9503 - val_loss: 0.1651 - val_acc: 0.9514\n",
            "Epoch 90/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1767 - acc: 0.9500 - val_loss: 0.1657 - val_acc: 0.9507\n",
            "Epoch 91/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1760 - acc: 0.9499 - val_loss: 0.1689 - val_acc: 0.9511\n",
            "Epoch 92/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1896 - acc: 0.9488 - val_loss: 0.3425 - val_acc: 0.9511\n",
            "Epoch 93/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1844 - acc: 0.9508 - val_loss: 0.1670 - val_acc: 0.9513\n",
            "Epoch 94/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1739 - acc: 0.9498 - val_loss: 0.1670 - val_acc: 0.9502\n",
            "Epoch 95/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1779 - acc: 0.9497 - val_loss: 0.1680 - val_acc: 0.9492\n",
            "Epoch 96/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1725 - acc: 0.9491 - val_loss: 0.2011 - val_acc: 0.9511\n",
            "Epoch 97/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1750 - acc: 0.9500 - val_loss: 0.1671 - val_acc: 0.9498\n",
            "Epoch 98/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1772 - acc: 0.9497 - val_loss: 0.1824 - val_acc: 0.9511\n",
            "Epoch 99/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1744 - acc: 0.9495 - val_loss: 0.1635 - val_acc: 0.9511\n",
            "Epoch 100/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1769 - acc: 0.9495 - val_loss: 0.1649 - val_acc: 0.9511\n",
            "Epoch 101/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1710 - acc: 0.9503 - val_loss: 0.1647 - val_acc: 0.9512\n",
            "Epoch 102/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1736 - acc: 0.9495 - val_loss: 0.1642 - val_acc: 0.9516\n",
            "Epoch 103/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1783 - acc: 0.9492 - val_loss: 0.1760 - val_acc: 0.9511\n",
            "Epoch 104/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1735 - acc: 0.9494 - val_loss: 0.1742 - val_acc: 0.9510\n",
            "Epoch 105/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1684 - acc: 0.9499 - val_loss: 0.1887 - val_acc: 0.9512\n",
            "Epoch 106/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1730 - acc: 0.9501 - val_loss: 0.1640 - val_acc: 0.9511\n",
            "Epoch 107/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1715 - acc: 0.9497 - val_loss: 0.1615 - val_acc: 0.9511\n",
            "Epoch 108/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1749 - acc: 0.9496 - val_loss: 0.1693 - val_acc: 0.9473\n",
            "Epoch 109/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1649 - acc: 0.9510 - val_loss: 0.1635 - val_acc: 0.9500\n",
            "Epoch 110/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1819 - acc: 0.9493 - val_loss: 0.1895 - val_acc: 0.9509\n",
            "Epoch 111/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1683 - acc: 0.9505 - val_loss: 0.1607 - val_acc: 0.9515\n",
            "Epoch 112/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1674 - acc: 0.9501 - val_loss: 0.1880 - val_acc: 0.9425\n",
            "Epoch 113/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1692 - acc: 0.9503 - val_loss: 0.2210 - val_acc: 0.9359\n",
            "Epoch 114/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1782 - acc: 0.9489 - val_loss: 0.1631 - val_acc: 0.9497\n",
            "Epoch 115/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1692 - acc: 0.9499 - val_loss: 0.1848 - val_acc: 0.9511\n",
            "Epoch 116/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1638 - acc: 0.9507 - val_loss: 0.1586 - val_acc: 0.9514\n",
            "Epoch 117/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1714 - acc: 0.9508 - val_loss: 0.1648 - val_acc: 0.9509\n",
            "Epoch 118/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1727 - acc: 0.9497 - val_loss: 0.1575 - val_acc: 0.9515\n",
            "Epoch 119/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1661 - acc: 0.9503 - val_loss: 0.1639 - val_acc: 0.9512\n",
            "Epoch 120/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1608 - acc: 0.9508 - val_loss: 0.1606 - val_acc: 0.9513\n",
            "Epoch 121/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1696 - acc: 0.9499 - val_loss: 0.1628 - val_acc: 0.9490\n",
            "Epoch 122/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1715 - acc: 0.9506 - val_loss: 0.1615 - val_acc: 0.9497\n",
            "Epoch 123/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1717 - acc: 0.9503 - val_loss: 0.1570 - val_acc: 0.9505\n",
            "Epoch 124/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1815 - acc: 0.9505 - val_loss: 0.1583 - val_acc: 0.9520\n",
            "Epoch 125/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1715 - acc: 0.9495 - val_loss: 0.1545 - val_acc: 0.9514\n",
            "Epoch 126/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1857 - acc: 0.9472 - val_loss: 0.1556 - val_acc: 0.9518\n",
            "Epoch 127/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1649 - acc: 0.9508 - val_loss: 0.1706 - val_acc: 0.9513\n",
            "Epoch 128/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1644 - acc: 0.9506 - val_loss: 0.1864 - val_acc: 0.9511\n",
            "Epoch 129/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1640 - acc: 0.9510 - val_loss: 0.1541 - val_acc: 0.9522\n",
            "Epoch 130/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1610 - acc: 0.9518 - val_loss: 0.1537 - val_acc: 0.9518\n",
            "Epoch 131/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1669 - acc: 0.9511 - val_loss: 0.1597 - val_acc: 0.9519\n",
            "Epoch 132/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1668 - acc: 0.9500 - val_loss: 0.1958 - val_acc: 0.9511\n",
            "Epoch 133/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.2050 - acc: 0.9512 - val_loss: 0.1695 - val_acc: 0.9512\n",
            "Epoch 134/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1620 - acc: 0.9514 - val_loss: 0.1602 - val_acc: 0.9512\n",
            "Epoch 135/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1683 - acc: 0.9490 - val_loss: 0.1819 - val_acc: 0.9511\n",
            "Epoch 136/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1671 - acc: 0.9509 - val_loss: 0.1761 - val_acc: 0.9428\n",
            "Epoch 137/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1749 - acc: 0.9487 - val_loss: 0.1496 - val_acc: 0.9521\n",
            "Epoch 138/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1685 - acc: 0.9499 - val_loss: 0.1571 - val_acc: 0.9516\n",
            "Epoch 139/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1609 - acc: 0.9501 - val_loss: 0.1628 - val_acc: 0.9512\n",
            "Epoch 140/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1586 - acc: 0.9512 - val_loss: 0.1528 - val_acc: 0.9515\n",
            "Epoch 141/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1620 - acc: 0.9512 - val_loss: 0.1505 - val_acc: 0.9523\n",
            "Epoch 142/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1655 - acc: 0.9500 - val_loss: 0.1591 - val_acc: 0.9485\n",
            "Epoch 143/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1656 - acc: 0.9501 - val_loss: 0.1600 - val_acc: 0.9511\n",
            "Epoch 144/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1687 - acc: 0.9506 - val_loss: 0.2405 - val_acc: 0.9511\n",
            "Epoch 145/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1628 - acc: 0.9510 - val_loss: 0.1495 - val_acc: 0.9516\n",
            "Epoch 146/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1549 - acc: 0.9515 - val_loss: 0.1534 - val_acc: 0.9514\n",
            "Epoch 147/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1592 - acc: 0.9517 - val_loss: 0.1454 - val_acc: 0.9527\n",
            "Epoch 148/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1527 - acc: 0.9521 - val_loss: 0.1434 - val_acc: 0.9525\n",
            "Epoch 149/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1655 - acc: 0.9505 - val_loss: 0.1529 - val_acc: 0.9514\n",
            "Epoch 150/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1583 - acc: 0.9510 - val_loss: 0.1472 - val_acc: 0.9520\n",
            "Epoch 151/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1588 - acc: 0.9525 - val_loss: 0.1458 - val_acc: 0.9521\n",
            "Epoch 152/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1516 - acc: 0.9525 - val_loss: 0.1439 - val_acc: 0.9531\n",
            "Epoch 153/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1707 - acc: 0.9521 - val_loss: 0.1584 - val_acc: 0.9485\n",
            "Epoch 154/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1575 - acc: 0.9515 - val_loss: 0.1709 - val_acc: 0.9515\n",
            "Epoch 155/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1614 - acc: 0.9512 - val_loss: 0.1380 - val_acc: 0.9538\n",
            "Epoch 156/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1561 - acc: 0.9519 - val_loss: 0.1387 - val_acc: 0.9540\n",
            "Epoch 157/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1571 - acc: 0.9514 - val_loss: 0.1372 - val_acc: 0.9535\n",
            "Epoch 158/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1576 - acc: 0.9526 - val_loss: 0.1415 - val_acc: 0.9532\n",
            "Epoch 159/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1547 - acc: 0.9521 - val_loss: 0.1464 - val_acc: 0.9530\n",
            "Epoch 160/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1537 - acc: 0.9528 - val_loss: 0.1489 - val_acc: 0.9525\n",
            "Epoch 161/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1533 - acc: 0.9526 - val_loss: 0.1459 - val_acc: 0.9524\n",
            "Epoch 162/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1480 - acc: 0.9529 - val_loss: 0.1734 - val_acc: 0.9522\n",
            "Epoch 163/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1531 - acc: 0.9520 - val_loss: 0.1394 - val_acc: 0.9519\n",
            "Epoch 164/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1562 - acc: 0.9505 - val_loss: 0.1474 - val_acc: 0.9526\n",
            "Epoch 165/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1423 - acc: 0.9535 - val_loss: 0.1466 - val_acc: 0.9525\n",
            "Epoch 166/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1484 - acc: 0.9530 - val_loss: 0.1345 - val_acc: 0.9546\n",
            "Epoch 167/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1521 - acc: 0.9525 - val_loss: 0.1406 - val_acc: 0.9540\n",
            "Epoch 168/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1543 - acc: 0.9519 - val_loss: 0.1275 - val_acc: 0.9555\n",
            "Epoch 169/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1503 - acc: 0.9525 - val_loss: 0.1367 - val_acc: 0.9535\n",
            "Epoch 170/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1572 - acc: 0.9523 - val_loss: 0.2187 - val_acc: 0.9518\n",
            "Epoch 171/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1414 - acc: 0.9542 - val_loss: 0.1277 - val_acc: 0.9554\n",
            "Epoch 172/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1444 - acc: 0.9537 - val_loss: 0.1277 - val_acc: 0.9541\n",
            "Epoch 173/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1449 - acc: 0.9542 - val_loss: 0.1425 - val_acc: 0.9534\n",
            "Epoch 174/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1475 - acc: 0.9538 - val_loss: 0.1376 - val_acc: 0.9542\n",
            "Epoch 175/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1408 - acc: 0.9554 - val_loss: 0.1280 - val_acc: 0.9548\n",
            "Epoch 176/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1462 - acc: 0.9558 - val_loss: 0.1263 - val_acc: 0.9552\n",
            "Epoch 177/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1402 - acc: 0.9557 - val_loss: 0.1213 - val_acc: 0.9574\n",
            "Epoch 178/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1521 - acc: 0.9546 - val_loss: 0.1465 - val_acc: 0.9545\n",
            "Epoch 179/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1497 - acc: 0.9540 - val_loss: 0.1453 - val_acc: 0.9526\n",
            "Epoch 180/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1482 - acc: 0.9541 - val_loss: 0.1222 - val_acc: 0.9558\n",
            "Epoch 181/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1299 - acc: 0.9558 - val_loss: 0.1267 - val_acc: 0.9548\n",
            "Epoch 182/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1429 - acc: 0.9548 - val_loss: 0.2028 - val_acc: 0.9530\n",
            "Epoch 183/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1391 - acc: 0.9558 - val_loss: 0.1184 - val_acc: 0.9578\n",
            "Epoch 184/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1405 - acc: 0.9555 - val_loss: 0.1695 - val_acc: 0.9452\n",
            "Epoch 185/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1411 - acc: 0.9545 - val_loss: 0.1213 - val_acc: 0.9578\n",
            "Epoch 186/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1436 - acc: 0.9550 - val_loss: 0.1247 - val_acc: 0.9543\n",
            "Epoch 187/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1395 - acc: 0.9552 - val_loss: 0.1412 - val_acc: 0.9556\n",
            "Epoch 188/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1576 - acc: 0.9534 - val_loss: 0.1402 - val_acc: 0.9570\n",
            "Epoch 189/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1250 - acc: 0.9575 - val_loss: 0.1344 - val_acc: 0.9551\n",
            "Epoch 190/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1247 - acc: 0.9571 - val_loss: 0.1110 - val_acc: 0.9597\n",
            "Epoch 191/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1325 - acc: 0.9566 - val_loss: 0.1190 - val_acc: 0.9569\n",
            "Epoch 192/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1263 - acc: 0.9565 - val_loss: 0.1224 - val_acc: 0.9569\n",
            "Epoch 193/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1268 - acc: 0.9583 - val_loss: 0.1156 - val_acc: 0.9580\n",
            "Epoch 194/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1369 - acc: 0.9573 - val_loss: 0.1147 - val_acc: 0.9599\n",
            "Epoch 195/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1395 - acc: 0.9569 - val_loss: 0.1127 - val_acc: 0.9597\n",
            "Epoch 196/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1454 - acc: 0.9568 - val_loss: 0.1157 - val_acc: 0.9592\n",
            "Epoch 197/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1254 - acc: 0.9578 - val_loss: 0.1112 - val_acc: 0.9594\n",
            "Epoch 198/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1199 - acc: 0.9592 - val_loss: 0.1038 - val_acc: 0.9601\n",
            "Epoch 199/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1210 - acc: 0.9586 - val_loss: 0.1032 - val_acc: 0.9592\n",
            "Epoch 200/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1237 - acc: 0.9584 - val_loss: 0.1092 - val_acc: 0.9593\n",
            "Epoch 201/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1224 - acc: 0.9586 - val_loss: 0.1000 - val_acc: 0.9590\n",
            "Epoch 202/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1259 - acc: 0.9585 - val_loss: 0.1089 - val_acc: 0.9582\n",
            "Epoch 203/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1117 - acc: 0.9602 - val_loss: 0.1031 - val_acc: 0.9616\n",
            "Epoch 204/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1097 - acc: 0.9610 - val_loss: 0.0950 - val_acc: 0.9619\n",
            "Epoch 205/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1201 - acc: 0.9603 - val_loss: 0.1050 - val_acc: 0.9591\n",
            "Epoch 206/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1053 - acc: 0.9620 - val_loss: 0.1632 - val_acc: 0.9570\n",
            "Epoch 207/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1119 - acc: 0.9612 - val_loss: 0.1003 - val_acc: 0.9618\n",
            "Epoch 208/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1046 - acc: 0.9625 - val_loss: 0.0945 - val_acc: 0.9629\n",
            "Epoch 209/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1223 - acc: 0.9616 - val_loss: 0.1019 - val_acc: 0.9615\n",
            "Epoch 210/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1046 - acc: 0.9628 - val_loss: 0.0890 - val_acc: 0.9661\n",
            "Epoch 211/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1002 - acc: 0.9643 - val_loss: 0.1062 - val_acc: 0.9669\n",
            "Epoch 212/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1030 - acc: 0.9648 - val_loss: 0.0845 - val_acc: 0.9670\n",
            "Epoch 213/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1056 - acc: 0.9636 - val_loss: 0.0831 - val_acc: 0.9661\n",
            "Epoch 214/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1070 - acc: 0.9644 - val_loss: 0.1036 - val_acc: 0.9656\n",
            "Epoch 215/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0940 - acc: 0.9669 - val_loss: 0.1502 - val_acc: 0.9602\n",
            "Epoch 216/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1111 - acc: 0.9644 - val_loss: 0.1263 - val_acc: 0.9590\n",
            "Epoch 217/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1038 - acc: 0.9667 - val_loss: 0.5879 - val_acc: 0.8640\n",
            "Epoch 218/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1110 - acc: 0.9648 - val_loss: 0.0822 - val_acc: 0.9695\n",
            "Epoch 219/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1127 - acc: 0.9650 - val_loss: 0.0802 - val_acc: 0.9725\n",
            "Epoch 220/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1094 - acc: 0.9647 - val_loss: 0.0886 - val_acc: 0.9703\n",
            "Epoch 221/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0957 - acc: 0.9672 - val_loss: 0.0727 - val_acc: 0.9689\n",
            "Epoch 222/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1072 - acc: 0.9661 - val_loss: 0.1097 - val_acc: 0.9712\n",
            "Epoch 223/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0850 - acc: 0.9696 - val_loss: 0.0714 - val_acc: 0.9723\n",
            "Epoch 224/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1039 - acc: 0.9657 - val_loss: 0.0711 - val_acc: 0.9704\n",
            "Epoch 225/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0954 - acc: 0.9683 - val_loss: 0.0645 - val_acc: 0.9705\n",
            "Epoch 226/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1556 - acc: 0.9669 - val_loss: 0.0679 - val_acc: 0.9712\n",
            "Epoch 227/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0894 - acc: 0.9692 - val_loss: 0.1200 - val_acc: 0.9614\n",
            "Epoch 228/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0819 - acc: 0.9716 - val_loss: 0.0820 - val_acc: 0.9757\n",
            "Epoch 229/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0787 - acc: 0.9720 - val_loss: 0.0801 - val_acc: 0.9757\n",
            "Epoch 230/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0864 - acc: 0.9728 - val_loss: 0.0744 - val_acc: 0.9714\n",
            "Epoch 231/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0970 - acc: 0.9707 - val_loss: 0.0819 - val_acc: 0.9674\n",
            "Epoch 232/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0781 - acc: 0.9733 - val_loss: 0.0693 - val_acc: 0.9751\n",
            "Epoch 233/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0769 - acc: 0.9747 - val_loss: 0.0569 - val_acc: 0.9743\n",
            "Epoch 234/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0818 - acc: 0.9731 - val_loss: 0.2167 - val_acc: 0.9621\n",
            "Epoch 235/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0884 - acc: 0.9739 - val_loss: 0.0649 - val_acc: 0.9829\n",
            "Epoch 236/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0846 - acc: 0.9738 - val_loss: 0.1017 - val_acc: 0.9739\n",
            "Epoch 237/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0810 - acc: 0.9751 - val_loss: 0.0727 - val_acc: 0.9800\n",
            "Epoch 238/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0815 - acc: 0.9747 - val_loss: 0.0562 - val_acc: 0.9766\n",
            "Epoch 239/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0845 - acc: 0.9753 - val_loss: 0.0567 - val_acc: 0.9800\n",
            "Epoch 240/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0763 - acc: 0.9753 - val_loss: 0.0659 - val_acc: 0.9802\n",
            "Epoch 241/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0632 - acc: 0.9786 - val_loss: 0.0973 - val_acc: 0.9715\n",
            "Epoch 242/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0853 - acc: 0.9762 - val_loss: 0.0734 - val_acc: 0.9749\n",
            "Epoch 243/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0730 - acc: 0.9784 - val_loss: 0.0570 - val_acc: 0.9859\n",
            "Epoch 244/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0693 - acc: 0.9790 - val_loss: 0.0574 - val_acc: 0.9817\n",
            "Epoch 245/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0620 - acc: 0.9826 - val_loss: 0.0503 - val_acc: 0.9896\n",
            "Epoch 246/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0684 - acc: 0.9804 - val_loss: 0.0476 - val_acc: 0.9908\n",
            "Epoch 247/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0719 - acc: 0.9827 - val_loss: 0.0623 - val_acc: 0.9754\n",
            "Epoch 248/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0708 - acc: 0.9824 - val_loss: 0.0408 - val_acc: 0.9869\n",
            "Epoch 249/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0697 - acc: 0.9824 - val_loss: 0.0492 - val_acc: 0.9806\n",
            "Epoch 250/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0762 - acc: 0.9837 - val_loss: 0.1919 - val_acc: 0.9655\n",
            "Epoch 251/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0714 - acc: 0.9835 - val_loss: 0.0548 - val_acc: 0.9906\n",
            "Epoch 252/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0741 - acc: 0.9821 - val_loss: 0.0942 - val_acc: 0.9803\n",
            "Epoch 253/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0665 - acc: 0.9859 - val_loss: 0.0496 - val_acc: 0.9857\n",
            "Epoch 254/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0810 - acc: 0.9853 - val_loss: 0.0732 - val_acc: 0.9815\n",
            "Epoch 255/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0608 - acc: 0.9859 - val_loss: 0.0377 - val_acc: 0.9921\n",
            "Epoch 256/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0619 - acc: 0.9855 - val_loss: 0.0858 - val_acc: 0.9790\n",
            "Epoch 257/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0681 - acc: 0.9857 - val_loss: 0.0615 - val_acc: 0.9861\n",
            "Epoch 258/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0695 - acc: 0.9864 - val_loss: 0.0433 - val_acc: 0.9891\n",
            "Epoch 259/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0588 - acc: 0.9878 - val_loss: 0.0445 - val_acc: 0.9913\n",
            "Epoch 260/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0582 - acc: 0.9866 - val_loss: 0.0807 - val_acc: 0.9834\n",
            "Epoch 261/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0891 - acc: 0.9842 - val_loss: 0.0558 - val_acc: 0.9857\n",
            "Epoch 262/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0579 - acc: 0.9874 - val_loss: 0.0361 - val_acc: 0.9950\n",
            "Epoch 263/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0562 - acc: 0.9866 - val_loss: 0.0405 - val_acc: 0.9961\n",
            "Epoch 264/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0533 - acc: 0.9885 - val_loss: 0.0350 - val_acc: 0.9905\n",
            "Epoch 265/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0581 - acc: 0.9875 - val_loss: 0.0497 - val_acc: 0.9874\n",
            "Epoch 266/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0797 - acc: 0.9858 - val_loss: 0.0449 - val_acc: 0.9940\n",
            "Epoch 267/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0688 - acc: 0.9861 - val_loss: 0.0465 - val_acc: 0.9937\n",
            "Epoch 268/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0693 - acc: 0.9867 - val_loss: 0.0623 - val_acc: 0.9875\n",
            "Epoch 269/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0644 - acc: 0.9863 - val_loss: 0.0619 - val_acc: 0.9827\n",
            "Epoch 270/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0681 - acc: 0.9875 - val_loss: 0.0464 - val_acc: 0.9865\n",
            "Epoch 271/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0453 - acc: 0.9907 - val_loss: 0.0295 - val_acc: 0.9932\n",
            "Epoch 272/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0763 - acc: 0.9876 - val_loss: 0.0288 - val_acc: 0.9967\n",
            "Epoch 273/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0594 - acc: 0.9889 - val_loss: 0.0310 - val_acc: 0.9944\n",
            "Epoch 274/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0677 - acc: 0.9871 - val_loss: 0.0371 - val_acc: 0.9967\n",
            "Epoch 275/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0430 - acc: 0.9909 - val_loss: 0.0302 - val_acc: 0.9971\n",
            "Epoch 276/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0660 - acc: 0.9890 - val_loss: 0.0304 - val_acc: 0.9929\n",
            "Epoch 277/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0595 - acc: 0.9895 - val_loss: 0.0327 - val_acc: 0.9950\n",
            "Epoch 278/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0552 - acc: 0.9899 - val_loss: 0.0307 - val_acc: 0.9945\n",
            "Epoch 279/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0582 - acc: 0.9883 - val_loss: 0.0402 - val_acc: 0.9954\n",
            "Epoch 280/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0514 - acc: 0.9894 - val_loss: 0.0283 - val_acc: 0.9937\n",
            "Epoch 281/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0488 - acc: 0.9899 - val_loss: 0.0479 - val_acc: 0.9885\n",
            "Epoch 282/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0496 - acc: 0.9890 - val_loss: 0.0361 - val_acc: 0.9913\n",
            "Epoch 283/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0693 - acc: 0.9866 - val_loss: 0.0634 - val_acc: 0.9884\n",
            "Epoch 284/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0553 - acc: 0.9895 - val_loss: 0.1083 - val_acc: 0.9728\n",
            "Epoch 285/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0576 - acc: 0.9889 - val_loss: 0.0319 - val_acc: 0.9955\n",
            "Epoch 286/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0619 - acc: 0.9872 - val_loss: 0.0386 - val_acc: 0.9924\n",
            "Epoch 287/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0480 - acc: 0.9892 - val_loss: 0.0680 - val_acc: 0.9826\n",
            "Epoch 288/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0556 - acc: 0.9882 - val_loss: 0.0475 - val_acc: 0.9932\n",
            "Epoch 289/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0490 - acc: 0.9891 - val_loss: 0.0283 - val_acc: 0.9930\n",
            "Epoch 290/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1058 - acc: 0.9860 - val_loss: 0.0531 - val_acc: 0.9886\n",
            "Epoch 291/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0735 - acc: 0.9857 - val_loss: 0.2475 - val_acc: 0.9743\n",
            "Epoch 292/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0845 - acc: 0.9863 - val_loss: 0.0524 - val_acc: 0.9881\n",
            "Epoch 293/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0621 - acc: 0.9883 - val_loss: 0.0273 - val_acc: 0.9970\n",
            "Epoch 294/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0577 - acc: 0.9874 - val_loss: 0.0530 - val_acc: 0.9927\n",
            "Epoch 295/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0565 - acc: 0.9889 - val_loss: 0.0252 - val_acc: 0.9945\n",
            "Epoch 296/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0629 - acc: 0.9881 - val_loss: 0.0311 - val_acc: 0.9985\n",
            "Epoch 297/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1203 - acc: 0.9854 - val_loss: 0.0488 - val_acc: 0.9945\n",
            "Epoch 298/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0809 - acc: 0.9889 - val_loss: 0.0636 - val_acc: 0.9882\n",
            "Epoch 299/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0708 - acc: 0.9896 - val_loss: 0.0292 - val_acc: 0.9964\n",
            "Epoch 300/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0921 - acc: 0.9864 - val_loss: 0.0273 - val_acc: 0.9968\n",
            "Epoch 301/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0880 - acc: 0.9885 - val_loss: 0.0289 - val_acc: 0.9967\n",
            "Epoch 302/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0882 - acc: 0.9888 - val_loss: 0.1124 - val_acc: 0.9760\n",
            "Epoch 303/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0693 - acc: 0.9897 - val_loss: 0.0802 - val_acc: 0.9836\n",
            "Epoch 304/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0656 - acc: 0.9900 - val_loss: 0.0378 - val_acc: 0.9926\n",
            "Epoch 305/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1307 - acc: 0.9817 - val_loss: 0.0435 - val_acc: 0.9935\n",
            "Epoch 306/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0547 - acc: 0.9907 - val_loss: 0.0664 - val_acc: 0.9865\n",
            "Epoch 307/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0608 - acc: 0.9909 - val_loss: 0.0794 - val_acc: 0.9824\n",
            "Epoch 308/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0673 - acc: 0.9897 - val_loss: 0.0405 - val_acc: 0.9925\n",
            "Epoch 309/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0670 - acc: 0.9912 - val_loss: 0.0497 - val_acc: 0.9908\n",
            "Epoch 310/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0619 - acc: 0.9907 - val_loss: 0.0180 - val_acc: 0.9979\n",
            "Epoch 311/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0818 - acc: 0.9891 - val_loss: 0.0441 - val_acc: 0.9921\n",
            "Epoch 312/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0676 - acc: 0.9904 - val_loss: 0.0167 - val_acc: 0.9988\n",
            "Epoch 313/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0739 - acc: 0.9892 - val_loss: 0.0319 - val_acc: 0.9940\n",
            "Epoch 314/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0981 - acc: 0.9868 - val_loss: 0.0263 - val_acc: 0.9957\n",
            "Epoch 315/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0658 - acc: 0.9910 - val_loss: 0.0254 - val_acc: 0.9964\n",
            "Epoch 316/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0644 - acc: 0.9909 - val_loss: 0.0323 - val_acc: 0.9944\n",
            "Epoch 317/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0742 - acc: 0.9896 - val_loss: 0.1663 - val_acc: 0.9798\n",
            "Epoch 318/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0634 - acc: 0.9900 - val_loss: 0.2073 - val_acc: 0.9532\n",
            "Epoch 319/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0714 - acc: 0.9892 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 320/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0579 - acc: 0.9916 - val_loss: 0.1147 - val_acc: 0.9851\n",
            "Epoch 321/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0621 - acc: 0.9907 - val_loss: 0.0795 - val_acc: 0.9822\n",
            "Epoch 322/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0843 - acc: 0.9892 - val_loss: 0.0248 - val_acc: 0.9963\n",
            "Epoch 323/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1405 - acc: 0.9847 - val_loss: 0.0350 - val_acc: 0.9949\n",
            "Epoch 324/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0861 - acc: 0.9876 - val_loss: 0.0440 - val_acc: 0.9910\n",
            "Epoch 325/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0654 - acc: 0.9908 - val_loss: 0.0166 - val_acc: 0.9980\n",
            "Epoch 326/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0742 - acc: 0.9899 - val_loss: 0.0572 - val_acc: 0.9910\n",
            "Epoch 327/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0632 - acc: 0.9904 - val_loss: 0.0228 - val_acc: 0.9971\n",
            "Epoch 328/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0674 - acc: 0.9888 - val_loss: 0.1518 - val_acc: 0.9805\n",
            "Epoch 329/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0615 - acc: 0.9908 - val_loss: 0.0719 - val_acc: 0.9875\n",
            "Epoch 330/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0923 - acc: 0.9866 - val_loss: 0.0369 - val_acc: 0.9940\n",
            "Epoch 331/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0504 - acc: 0.9913 - val_loss: 0.0314 - val_acc: 0.9947\n",
            "Epoch 332/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0634 - acc: 0.9904 - val_loss: 0.1831 - val_acc: 0.9790\n",
            "Epoch 333/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0749 - acc: 0.9895 - val_loss: 0.0168 - val_acc: 0.9988\n",
            "Epoch 334/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1058 - acc: 0.9859 - val_loss: 0.0417 - val_acc: 0.9932\n",
            "Epoch 335/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0608 - acc: 0.9914 - val_loss: 0.2470 - val_acc: 0.9433\n",
            "Epoch 336/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0828 - acc: 0.9884 - val_loss: 0.0190 - val_acc: 0.9979\n",
            "Epoch 337/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0693 - acc: 0.9898 - val_loss: 0.0328 - val_acc: 0.9948\n",
            "Epoch 338/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0874 - acc: 0.9888 - val_loss: 0.1007 - val_acc: 0.9858\n",
            "Epoch 339/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0775 - acc: 0.9895 - val_loss: 0.0336 - val_acc: 0.9950\n",
            "Epoch 340/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0975 - acc: 0.9870 - val_loss: 0.0166 - val_acc: 0.9980\n",
            "Epoch 341/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0779 - acc: 0.9895 - val_loss: 0.2088 - val_acc: 0.9789\n",
            "Epoch 342/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0823 - acc: 0.9881 - val_loss: 0.0328 - val_acc: 0.9943\n",
            "Epoch 343/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0791 - acc: 0.9898 - val_loss: 0.1628 - val_acc: 0.9812\n",
            "Epoch 344/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0904 - acc: 0.9881 - val_loss: 0.0182 - val_acc: 0.9980\n",
            "Epoch 345/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0869 - acc: 0.9883 - val_loss: 0.1377 - val_acc: 0.9811\n",
            "Epoch 346/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0961 - acc: 0.9873 - val_loss: 0.0542 - val_acc: 0.9918\n",
            "Epoch 347/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0707 - acc: 0.9902 - val_loss: 0.0203 - val_acc: 0.9983\n",
            "Epoch 348/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0762 - acc: 0.9892 - val_loss: 0.0187 - val_acc: 0.9977\n",
            "Epoch 349/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0840 - acc: 0.9879 - val_loss: 0.0680 - val_acc: 0.9887\n",
            "Epoch 350/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0848 - acc: 0.9884 - val_loss: 0.0518 - val_acc: 0.9912\n",
            "Epoch 351/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0793 - acc: 0.9899 - val_loss: 0.0168 - val_acc: 0.9987\n",
            "Epoch 352/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1150 - acc: 0.9843 - val_loss: 0.0652 - val_acc: 0.9882\n",
            "Epoch 353/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1115 - acc: 0.9853 - val_loss: 0.1204 - val_acc: 0.9833\n",
            "Epoch 354/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0727 - acc: 0.9905 - val_loss: 0.1410 - val_acc: 0.9819\n",
            "Epoch 355/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0598 - acc: 0.9913 - val_loss: 0.0748 - val_acc: 0.9853\n",
            "Epoch 356/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1080 - acc: 0.9869 - val_loss: 0.1774 - val_acc: 0.9791\n",
            "Epoch 357/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0867 - acc: 0.9879 - val_loss: 0.1174 - val_acc: 0.9838\n",
            "Epoch 358/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0650 - acc: 0.9909 - val_loss: 0.0604 - val_acc: 0.9883\n",
            "Epoch 359/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1484 - acc: 0.9801 - val_loss: 0.3773 - val_acc: 0.9672\n",
            "Epoch 360/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0941 - acc: 0.9890 - val_loss: 0.0311 - val_acc: 0.9954\n",
            "Epoch 361/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0488 - acc: 0.9930 - val_loss: 0.0616 - val_acc: 0.9902\n",
            "Epoch 362/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0678 - acc: 0.9902 - val_loss: 0.0966 - val_acc: 0.9870\n",
            "Epoch 363/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0669 - acc: 0.9906 - val_loss: 0.0731 - val_acc: 0.9875\n",
            "Epoch 364/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0678 - acc: 0.9911 - val_loss: 0.0305 - val_acc: 0.9948\n",
            "Epoch 365/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0728 - acc: 0.9893 - val_loss: 0.1127 - val_acc: 0.9846\n",
            "Epoch 366/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0985 - acc: 0.9873 - val_loss: 0.0491 - val_acc: 0.9908\n",
            "Epoch 367/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1115 - acc: 0.9845 - val_loss: 0.0814 - val_acc: 0.9870\n",
            "Epoch 368/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0634 - acc: 0.9911 - val_loss: 0.0820 - val_acc: 0.9881\n",
            "Epoch 369/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1040 - acc: 0.9855 - val_loss: 0.0187 - val_acc: 0.9964\n",
            "Epoch 370/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0694 - acc: 0.9908 - val_loss: 0.0417 - val_acc: 0.9926\n",
            "Epoch 371/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0658 - acc: 0.9902 - val_loss: 0.0415 - val_acc: 0.9929\n",
            "Epoch 372/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0592 - acc: 0.9911 - val_loss: 0.0135 - val_acc: 0.9985\n",
            "Epoch 373/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0573 - acc: 0.9920 - val_loss: 0.0766 - val_acc: 0.9851\n",
            "Epoch 374/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1146 - acc: 0.9869 - val_loss: 0.0292 - val_acc: 0.9958\n",
            "Epoch 375/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0682 - acc: 0.9908 - val_loss: 0.0209 - val_acc: 0.9968\n",
            "Epoch 376/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1010 - acc: 0.9870 - val_loss: 0.0511 - val_acc: 0.9909\n",
            "Epoch 377/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1102 - acc: 0.9858 - val_loss: 0.1163 - val_acc: 0.9731\n",
            "Epoch 378/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0642 - acc: 0.9912 - val_loss: 0.0141 - val_acc: 0.9983\n",
            "Epoch 379/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0667 - acc: 0.9907 - val_loss: 0.2399 - val_acc: 0.9766\n",
            "Epoch 380/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0567 - acc: 0.9920 - val_loss: 0.0792 - val_acc: 0.9881\n",
            "Epoch 381/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0683 - acc: 0.9904 - val_loss: 0.0255 - val_acc: 0.9960\n",
            "Epoch 382/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1193 - acc: 0.9834 - val_loss: 0.1939 - val_acc: 0.9785\n",
            "Epoch 383/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0713 - acc: 0.9902 - val_loss: 0.0223 - val_acc: 0.9972\n",
            "Epoch 384/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0641 - acc: 0.9911 - val_loss: 0.1143 - val_acc: 0.9758\n",
            "Epoch 385/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0461 - acc: 0.9932 - val_loss: 0.0261 - val_acc: 0.9967\n",
            "Epoch 386/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0565 - acc: 0.9919 - val_loss: 0.1590 - val_acc: 0.9803\n",
            "Epoch 387/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0791 - acc: 0.9893 - val_loss: 0.0396 - val_acc: 0.9938\n",
            "Epoch 388/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0572 - acc: 0.9916 - val_loss: 0.0711 - val_acc: 0.9887\n",
            "Epoch 389/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0620 - acc: 0.9917 - val_loss: 0.0984 - val_acc: 0.9855\n",
            "Epoch 390/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1025 - acc: 0.9879 - val_loss: 0.0196 - val_acc: 0.9977\n",
            "Epoch 391/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1122 - acc: 0.9875 - val_loss: 0.0413 - val_acc: 0.9924\n",
            "Epoch 392/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1225 - acc: 0.9843 - val_loss: 0.0129 - val_acc: 0.9989\n",
            "Epoch 393/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0820 - acc: 0.9897 - val_loss: 0.2557 - val_acc: 0.9753\n",
            "Epoch 394/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0773 - acc: 0.9898 - val_loss: 0.0799 - val_acc: 0.9889\n",
            "Epoch 395/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0504 - acc: 0.9925 - val_loss: 0.0193 - val_acc: 0.9975\n",
            "Epoch 396/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1000 - acc: 0.9861 - val_loss: 0.1499 - val_acc: 0.9757\n",
            "Epoch 397/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0618 - acc: 0.9909 - val_loss: 0.0666 - val_acc: 0.9884\n",
            "Epoch 398/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0807 - acc: 0.9893 - val_loss: 0.0127 - val_acc: 0.9985\n",
            "Epoch 399/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0918 - acc: 0.9883 - val_loss: 0.0133 - val_acc: 0.9980\n",
            "Epoch 400/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0600 - acc: 0.9922 - val_loss: 0.0304 - val_acc: 0.9953\n",
            "Epoch 401/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1070 - acc: 0.9885 - val_loss: 0.0860 - val_acc: 0.9867\n",
            "Epoch 402/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0696 - acc: 0.9899 - val_loss: 0.0246 - val_acc: 0.9966\n",
            "Epoch 403/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0633 - acc: 0.9910 - val_loss: 0.0290 - val_acc: 0.9948\n",
            "Epoch 404/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0828 - acc: 0.9879 - val_loss: 0.0597 - val_acc: 0.9900\n",
            "Epoch 405/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0817 - acc: 0.9886 - val_loss: 0.0176 - val_acc: 0.9979\n",
            "Epoch 406/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0703 - acc: 0.9893 - val_loss: 0.0190 - val_acc: 0.9973\n",
            "Epoch 407/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0508 - acc: 0.9927 - val_loss: 0.0258 - val_acc: 0.9960\n",
            "Epoch 408/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0658 - acc: 0.9905 - val_loss: 1.4966 - val_acc: 0.8218\n",
            "Epoch 409/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1284 - acc: 0.9844 - val_loss: 0.0253 - val_acc: 0.9970\n",
            "Epoch 410/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1021 - acc: 0.9869 - val_loss: 0.1263 - val_acc: 0.9831\n",
            "Epoch 411/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0579 - acc: 0.9915 - val_loss: 0.0334 - val_acc: 0.9940\n",
            "Epoch 412/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0627 - acc: 0.9918 - val_loss: 0.0184 - val_acc: 0.9983\n",
            "Epoch 413/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0626 - acc: 0.9907 - val_loss: 0.1833 - val_acc: 0.9624\n",
            "Epoch 414/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1071 - acc: 0.9883 - val_loss: 0.0528 - val_acc: 0.9907\n",
            "Epoch 415/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0631 - acc: 0.9914 - val_loss: 0.0141 - val_acc: 0.9980\n",
            "Epoch 416/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0603 - acc: 0.9922 - val_loss: 0.0171 - val_acc: 0.9978\n",
            "Epoch 417/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0721 - acc: 0.9905 - val_loss: 0.0946 - val_acc: 0.9867\n",
            "Epoch 418/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0668 - acc: 0.9907 - val_loss: 0.2522 - val_acc: 0.9761\n",
            "Epoch 419/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1369 - acc: 0.9817 - val_loss: 0.1227 - val_acc: 0.9828\n",
            "Epoch 420/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0618 - acc: 0.9920 - val_loss: 0.0361 - val_acc: 0.9941\n",
            "Epoch 421/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0581 - acc: 0.9929 - val_loss: 0.0135 - val_acc: 0.9980\n",
            "Epoch 422/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0597 - acc: 0.9916 - val_loss: 0.0162 - val_acc: 0.9980\n",
            "Epoch 423/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0600 - acc: 0.9919 - val_loss: 0.0251 - val_acc: 0.9963\n",
            "Epoch 424/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0597 - acc: 0.9914 - val_loss: 0.0293 - val_acc: 0.9954\n",
            "Epoch 425/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0587 - acc: 0.9918 - val_loss: 0.0913 - val_acc: 0.9866\n",
            "Epoch 426/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0630 - acc: 0.9910 - val_loss: 0.2400 - val_acc: 0.9512\n",
            "Epoch 427/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0685 - acc: 0.9898 - val_loss: 0.0241 - val_acc: 0.9951\n",
            "Epoch 428/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1046 - acc: 0.9856 - val_loss: 0.0132 - val_acc: 0.9983\n",
            "Epoch 429/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0669 - acc: 0.9913 - val_loss: 0.0442 - val_acc: 0.9926\n",
            "Epoch 430/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0541 - acc: 0.9918 - val_loss: 0.0137 - val_acc: 0.9980\n",
            "Epoch 431/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0820 - acc: 0.9887 - val_loss: 0.0203 - val_acc: 0.9965\n",
            "Epoch 432/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0650 - acc: 0.9912 - val_loss: 0.0780 - val_acc: 0.9884\n",
            "Epoch 433/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0689 - acc: 0.9913 - val_loss: 0.0177 - val_acc: 0.9980\n",
            "Epoch 434/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0482 - acc: 0.9930 - val_loss: 0.0199 - val_acc: 0.9968\n",
            "Epoch 435/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0656 - acc: 0.9914 - val_loss: 0.0209 - val_acc: 0.9975\n",
            "Epoch 436/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0732 - acc: 0.9898 - val_loss: 0.0673 - val_acc: 0.9889\n",
            "Epoch 437/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1119 - acc: 0.9869 - val_loss: 0.0538 - val_acc: 0.9899\n",
            "Epoch 438/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0602 - acc: 0.9918 - val_loss: 0.0509 - val_acc: 0.9910\n",
            "Epoch 439/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1203 - acc: 0.9861 - val_loss: 0.0222 - val_acc: 0.9965\n",
            "Epoch 440/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1003 - acc: 0.9884 - val_loss: 0.1733 - val_acc: 0.9694\n",
            "Epoch 441/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0717 - acc: 0.9915 - val_loss: 0.0263 - val_acc: 0.9962\n",
            "Epoch 442/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1012 - acc: 0.9887 - val_loss: 0.0302 - val_acc: 0.9946\n",
            "Epoch 443/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0531 - acc: 0.9924 - val_loss: 0.0204 - val_acc: 0.9977\n",
            "Epoch 444/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0834 - acc: 0.9883 - val_loss: 0.0175 - val_acc: 0.9976\n",
            "Epoch 445/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0869 - acc: 0.9888 - val_loss: 0.0297 - val_acc: 0.9927\n",
            "Epoch 446/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0744 - acc: 0.9897 - val_loss: 0.0161 - val_acc: 0.9976\n",
            "Epoch 447/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0579 - acc: 0.9923 - val_loss: 0.0400 - val_acc: 0.9927\n",
            "Epoch 448/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0518 - acc: 0.9920 - val_loss: 0.1343 - val_acc: 0.9827\n",
            "Epoch 449/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0558 - acc: 0.9920 - val_loss: 0.1111 - val_acc: 0.9853\n",
            "Epoch 450/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0613 - acc: 0.9925 - val_loss: 0.0268 - val_acc: 0.9956\n",
            "Epoch 451/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0789 - acc: 0.9891 - val_loss: 0.0309 - val_acc: 0.9953\n",
            "Epoch 452/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0745 - acc: 0.9895 - val_loss: 0.0115 - val_acc: 0.9988\n",
            "Epoch 453/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0863 - acc: 0.9892 - val_loss: 0.1209 - val_acc: 0.9787\n",
            "Epoch 454/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0569 - acc: 0.9930 - val_loss: 0.0254 - val_acc: 0.9963\n",
            "Epoch 455/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0611 - acc: 0.9917 - val_loss: 0.1355 - val_acc: 0.9824\n",
            "Epoch 456/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0862 - acc: 0.9885 - val_loss: 0.0255 - val_acc: 0.9968\n",
            "Epoch 457/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0558 - acc: 0.9921 - val_loss: 0.0240 - val_acc: 0.9962\n",
            "Epoch 458/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0442 - acc: 0.9934 - val_loss: 0.0229 - val_acc: 0.9968\n",
            "Epoch 459/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1134 - acc: 0.9878 - val_loss: 0.0240 - val_acc: 0.9964\n",
            "Epoch 460/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0663 - acc: 0.9911 - val_loss: 0.2245 - val_acc: 0.9513\n",
            "Epoch 461/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0480 - acc: 0.9928 - val_loss: 0.0744 - val_acc: 0.9881\n",
            "Epoch 462/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1193 - acc: 0.9856 - val_loss: 0.2389 - val_acc: 0.9771\n",
            "Epoch 463/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0535 - acc: 0.9929 - val_loss: 0.0194 - val_acc: 0.9967\n",
            "Epoch 464/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1245 - acc: 0.9858 - val_loss: 0.0324 - val_acc: 0.9953\n",
            "Epoch 465/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1077 - acc: 0.9871 - val_loss: 0.0486 - val_acc: 0.9918\n",
            "Epoch 466/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0404 - acc: 0.9945 - val_loss: 0.2979 - val_acc: 0.9734\n",
            "Epoch 467/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1669 - acc: 0.9793 - val_loss: 0.2515 - val_acc: 0.9731\n",
            "Epoch 468/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0539 - acc: 0.9924 - val_loss: 0.1657 - val_acc: 0.9806\n",
            "Epoch 469/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0580 - acc: 0.9925 - val_loss: 0.0669 - val_acc: 0.9864\n",
            "Epoch 470/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0653 - acc: 0.9899 - val_loss: 0.1945 - val_acc: 0.9606\n",
            "Epoch 471/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0730 - acc: 0.9903 - val_loss: 0.0324 - val_acc: 0.9947\n",
            "Epoch 472/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0818 - acc: 0.9891 - val_loss: 0.0844 - val_acc: 0.9868\n",
            "Epoch 473/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0993 - acc: 0.9859 - val_loss: 0.0142 - val_acc: 0.9969\n",
            "Epoch 474/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0619 - acc: 0.9905 - val_loss: 0.0447 - val_acc: 0.9924\n",
            "Epoch 475/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0714 - acc: 0.9899 - val_loss: 0.0272 - val_acc: 0.9956\n",
            "Epoch 476/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0552 - acc: 0.9926 - val_loss: 0.0151 - val_acc: 0.9976\n",
            "Epoch 477/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0549 - acc: 0.9923 - val_loss: 0.0516 - val_acc: 0.9915\n",
            "Epoch 478/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0419 - acc: 0.9934 - val_loss: 0.1186 - val_acc: 0.9840\n",
            "Epoch 479/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1295 - acc: 0.9858 - val_loss: 0.0289 - val_acc: 0.9957\n",
            "Epoch 480/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0746 - acc: 0.9897 - val_loss: 0.0133 - val_acc: 0.9978\n",
            "Epoch 481/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0421 - acc: 0.9938 - val_loss: 0.0113 - val_acc: 0.9988\n",
            "Epoch 482/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0465 - acc: 0.9929 - val_loss: 0.0236 - val_acc: 0.9959\n",
            "Epoch 483/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0754 - acc: 0.9894 - val_loss: 0.0512 - val_acc: 0.9916\n",
            "Epoch 484/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0680 - acc: 0.9910 - val_loss: 0.0184 - val_acc: 0.9972\n",
            "Epoch 485/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0523 - acc: 0.9920 - val_loss: 0.0190 - val_acc: 0.9975\n",
            "Epoch 486/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0518 - acc: 0.9923 - val_loss: 0.1603 - val_acc: 0.9810\n",
            "Epoch 487/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1002 - acc: 0.9861 - val_loss: 0.0281 - val_acc: 0.9950\n",
            "Epoch 488/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0982 - acc: 0.9863 - val_loss: 0.2017 - val_acc: 0.9784\n",
            "Epoch 489/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0675 - acc: 0.9907 - val_loss: 0.1253 - val_acc: 0.9834\n",
            "Epoch 490/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0697 - acc: 0.9905 - val_loss: 0.2087 - val_acc: 0.9537\n",
            "Epoch 491/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0606 - acc: 0.9921 - val_loss: 0.0770 - val_acc: 0.9884\n",
            "Epoch 492/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0441 - acc: 0.9931 - val_loss: 0.0130 - val_acc: 0.9988\n",
            "Epoch 493/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0530 - acc: 0.9909 - val_loss: 0.0104 - val_acc: 0.9985\n",
            "Epoch 494/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0729 - acc: 0.9906 - val_loss: 0.0126 - val_acc: 0.9983\n",
            "Epoch 495/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0616 - acc: 0.9920 - val_loss: 0.0267 - val_acc: 0.9958\n",
            "Epoch 496/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0523 - acc: 0.9923 - val_loss: 0.1265 - val_acc: 0.9846\n",
            "Epoch 497/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0545 - acc: 0.9927 - val_loss: 0.0127 - val_acc: 0.9988\n",
            "Epoch 498/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0497 - acc: 0.9930 - val_loss: 0.0561 - val_acc: 0.9867\n",
            "Epoch 499/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0860 - acc: 0.9879 - val_loss: 0.0156 - val_acc: 0.9979\n",
            "Epoch 500/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0948 - acc: 0.9883 - val_loss: 0.0866 - val_acc: 0.9865\n",
            "Epoch 501/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1215 - acc: 0.9830 - val_loss: 0.3476 - val_acc: 0.9701\n",
            "Epoch 502/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1163 - acc: 0.9854 - val_loss: 0.0148 - val_acc: 0.9988\n",
            "Epoch 503/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0371 - acc: 0.9944 - val_loss: 0.0147 - val_acc: 0.9976\n",
            "Epoch 504/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0460 - acc: 0.9932 - val_loss: 0.0591 - val_acc: 0.9867\n",
            "Epoch 505/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0498 - acc: 0.9922 - val_loss: 0.0191 - val_acc: 0.9969\n",
            "Epoch 506/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0874 - acc: 0.9878 - val_loss: 0.0344 - val_acc: 0.9937\n",
            "Epoch 507/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0597 - acc: 0.9913 - val_loss: 0.0368 - val_acc: 0.9942\n",
            "Epoch 508/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0594 - acc: 0.9906 - val_loss: 0.0259 - val_acc: 0.9943\n",
            "Epoch 509/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0839 - acc: 0.9885 - val_loss: 0.0137 - val_acc: 0.9985\n",
            "Epoch 510/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0552 - acc: 0.9925 - val_loss: 0.0149 - val_acc: 0.9982\n",
            "Epoch 511/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0511 - acc: 0.9924 - val_loss: 0.0167 - val_acc: 0.9980\n",
            "Epoch 512/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0966 - acc: 0.9868 - val_loss: 0.1546 - val_acc: 0.9806\n",
            "Epoch 513/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0537 - acc: 0.9920 - val_loss: 0.0168 - val_acc: 0.9968\n",
            "Epoch 514/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0912 - acc: 0.9886 - val_loss: 0.0529 - val_acc: 0.9905\n",
            "Epoch 515/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0480 - acc: 0.9930 - val_loss: 0.0341 - val_acc: 0.9942\n",
            "Epoch 516/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0587 - acc: 0.9915 - val_loss: 0.0584 - val_acc: 0.9908\n",
            "Epoch 517/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0650 - acc: 0.9905 - val_loss: 0.0740 - val_acc: 0.9856\n",
            "Epoch 518/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0484 - acc: 0.9933 - val_loss: 0.0819 - val_acc: 0.9871\n",
            "Epoch 519/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0800 - acc: 0.9901 - val_loss: 0.0158 - val_acc: 0.9982\n",
            "Epoch 520/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0828 - acc: 0.9890 - val_loss: 0.0156 - val_acc: 0.9976\n",
            "Epoch 521/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0562 - acc: 0.9914 - val_loss: 0.0865 - val_acc: 0.9841\n",
            "Epoch 522/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0733 - acc: 0.9912 - val_loss: 0.0184 - val_acc: 0.9976\n",
            "Epoch 523/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0878 - acc: 0.9891 - val_loss: 0.0232 - val_acc: 0.9961\n",
            "Epoch 524/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0336 - acc: 0.9953 - val_loss: 0.0126 - val_acc: 0.9987\n",
            "Epoch 525/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0825 - acc: 0.9900 - val_loss: 0.0222 - val_acc: 0.9978\n",
            "Epoch 526/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0422 - acc: 0.9938 - val_loss: 0.0387 - val_acc: 0.9940\n",
            "Epoch 527/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0466 - acc: 0.9932 - val_loss: 0.0415 - val_acc: 0.9924\n",
            "Epoch 528/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1025 - acc: 0.9873 - val_loss: 0.0427 - val_acc: 0.9919\n",
            "Epoch 529/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0944 - acc: 0.9896 - val_loss: 0.0578 - val_acc: 0.9908\n",
            "Epoch 530/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0515 - acc: 0.9930 - val_loss: 0.0435 - val_acc: 0.9921\n",
            "Epoch 531/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0415 - acc: 0.9939 - val_loss: 0.0127 - val_acc: 0.9982\n",
            "Epoch 532/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2104 - acc: 0.9810 - val_loss: 0.3558 - val_acc: 0.9714\n",
            "Epoch 533/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1811 - acc: 0.9844 - val_loss: 0.0817 - val_acc: 0.9914\n",
            "Epoch 534/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1660 - acc: 0.9856 - val_loss: 0.0595 - val_acc: 0.9934\n",
            "Epoch 535/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1106 - acc: 0.9896 - val_loss: 0.0238 - val_acc: 0.9975\n",
            "Epoch 536/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1210 - acc: 0.9882 - val_loss: 0.0144 - val_acc: 0.9983\n",
            "Epoch 537/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0855 - acc: 0.9921 - val_loss: 0.0929 - val_acc: 0.9908\n",
            "Epoch 538/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1305 - acc: 0.9882 - val_loss: 0.0886 - val_acc: 0.9913\n",
            "Epoch 539/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1050 - acc: 0.9900 - val_loss: 0.0178 - val_acc: 0.9977\n",
            "Epoch 540/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1036 - acc: 0.9900 - val_loss: 0.0196 - val_acc: 0.9977\n",
            "Epoch 541/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1436 - acc: 0.9880 - val_loss: 0.0273 - val_acc: 0.9974\n",
            "Epoch 542/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0772 - acc: 0.9925 - val_loss: 0.3193 - val_acc: 0.9758\n",
            "Epoch 543/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1050 - acc: 0.9900 - val_loss: 0.0145 - val_acc: 0.9983\n",
            "Epoch 544/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1009 - acc: 0.9905 - val_loss: 0.0448 - val_acc: 0.9952\n",
            "Epoch 545/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0730 - acc: 0.9928 - val_loss: 0.1710 - val_acc: 0.9855\n",
            "Epoch 546/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1592 - acc: 0.9843 - val_loss: 0.0205 - val_acc: 0.9972\n",
            "Epoch 547/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0947 - acc: 0.9909 - val_loss: 0.0321 - val_acc: 0.9939\n",
            "Epoch 548/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1583 - acc: 0.9824 - val_loss: 0.0363 - val_acc: 0.9944\n",
            "Epoch 549/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0726 - acc: 0.9892 - val_loss: 0.0210 - val_acc: 0.9967\n",
            "Epoch 550/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0447 - acc: 0.9928 - val_loss: 0.0842 - val_acc: 0.9846\n",
            "Epoch 551/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0978 - acc: 0.9860 - val_loss: 0.0220 - val_acc: 0.9965\n",
            "Epoch 552/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0685 - acc: 0.9901 - val_loss: 0.1581 - val_acc: 0.9811\n",
            "Epoch 553/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0958 - acc: 0.9864 - val_loss: 0.0308 - val_acc: 0.9935\n",
            "Epoch 554/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0543 - acc: 0.9913 - val_loss: 0.0403 - val_acc: 0.9924\n",
            "Epoch 555/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0506 - acc: 0.9920 - val_loss: 0.0579 - val_acc: 0.9898\n",
            "Epoch 556/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0450 - acc: 0.9928 - val_loss: 0.1375 - val_acc: 0.9721\n",
            "Epoch 557/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0566 - acc: 0.9920 - val_loss: 0.2011 - val_acc: 0.9790\n",
            "Epoch 558/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0455 - acc: 0.9926 - val_loss: 0.0196 - val_acc: 0.9964\n",
            "Epoch 559/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0612 - acc: 0.9904 - val_loss: 0.0127 - val_acc: 0.9984\n",
            "Epoch 560/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0597 - acc: 0.9918 - val_loss: 0.0191 - val_acc: 0.9973\n",
            "Epoch 561/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0534 - acc: 0.9922 - val_loss: 0.0501 - val_acc: 0.9883\n",
            "Epoch 562/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1002 - acc: 0.9877 - val_loss: 0.0433 - val_acc: 0.9941\n",
            "Epoch 563/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0561 - acc: 0.9918 - val_loss: 0.0490 - val_acc: 0.9905\n",
            "Epoch 564/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0399 - acc: 0.9934 - val_loss: 0.1300 - val_acc: 0.9835\n",
            "Epoch 565/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0909 - acc: 0.9886 - val_loss: 0.2632 - val_acc: 0.9758\n",
            "Epoch 566/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0533 - acc: 0.9920 - val_loss: 0.0268 - val_acc: 0.9953\n",
            "Epoch 567/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0466 - acc: 0.9925 - val_loss: 0.1301 - val_acc: 0.9714\n",
            "Epoch 568/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0729 - acc: 0.9889 - val_loss: 0.0656 - val_acc: 0.9886\n",
            "Epoch 569/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0339 - acc: 0.9947 - val_loss: 0.0160 - val_acc: 0.9981\n",
            "Epoch 570/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0546 - acc: 0.9922 - val_loss: 0.0449 - val_acc: 0.9917\n",
            "Epoch 571/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0789 - acc: 0.9899 - val_loss: 0.2554 - val_acc: 0.9758\n",
            "Epoch 572/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0564 - acc: 0.9915 - val_loss: 0.0191 - val_acc: 0.9973\n",
            "Epoch 573/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0465 - acc: 0.9923 - val_loss: 0.0115 - val_acc: 0.9973\n",
            "Epoch 574/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0671 - acc: 0.9909 - val_loss: 0.0166 - val_acc: 0.9982\n",
            "Epoch 575/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0396 - acc: 0.9940 - val_loss: 0.0161 - val_acc: 0.9968\n",
            "Epoch 576/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0395 - acc: 0.9942 - val_loss: 0.0583 - val_acc: 0.9906\n",
            "Epoch 577/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0916 - acc: 0.9874 - val_loss: 0.0526 - val_acc: 0.9912\n",
            "Epoch 578/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0585 - acc: 0.9920 - val_loss: 0.0293 - val_acc: 0.9958\n",
            "Epoch 579/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0733 - acc: 0.9891 - val_loss: 0.0145 - val_acc: 0.9980\n",
            "Epoch 580/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0401 - acc: 0.9934 - val_loss: 0.0144 - val_acc: 0.9982\n",
            "Epoch 581/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0632 - acc: 0.9920 - val_loss: 0.0155 - val_acc: 0.9967\n",
            "Epoch 582/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0436 - acc: 0.9935 - val_loss: 0.0775 - val_acc: 0.9881\n",
            "Epoch 583/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0769 - acc: 0.9878 - val_loss: 0.0291 - val_acc: 0.9958\n",
            "Epoch 584/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0740 - acc: 0.9895 - val_loss: 0.0139 - val_acc: 0.9985\n",
            "Epoch 585/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0469 - acc: 0.9932 - val_loss: 0.0206 - val_acc: 0.9966\n",
            "Epoch 586/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0448 - acc: 0.9932 - val_loss: 0.0236 - val_acc: 0.9965\n",
            "Epoch 587/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0540 - acc: 0.9914 - val_loss: 0.0470 - val_acc: 0.9918\n",
            "Epoch 588/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0538 - acc: 0.9914 - val_loss: 0.0147 - val_acc: 0.9980\n",
            "Epoch 589/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0753 - acc: 0.9903 - val_loss: 0.0820 - val_acc: 0.9862\n",
            "Epoch 590/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0367 - acc: 0.9942 - val_loss: 0.0143 - val_acc: 0.9980\n",
            "Epoch 591/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0431 - acc: 0.9934 - val_loss: 0.0736 - val_acc: 0.9890\n",
            "Epoch 592/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0707 - acc: 0.9894 - val_loss: 0.0086 - val_acc: 0.9990\n",
            "Epoch 593/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1009 - acc: 0.9873 - val_loss: 0.0897 - val_acc: 0.9846\n",
            "Epoch 594/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0411 - acc: 0.9929 - val_loss: 0.0242 - val_acc: 0.9961\n",
            "Epoch 595/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0360 - acc: 0.9949 - val_loss: 0.0278 - val_acc: 0.9952\n",
            "Epoch 596/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0663 - acc: 0.9898 - val_loss: 0.0150 - val_acc: 0.9989\n",
            "Epoch 597/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0508 - acc: 0.9922 - val_loss: 0.0124 - val_acc: 0.9991\n",
            "Epoch 598/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0539 - acc: 0.9924 - val_loss: 0.0099 - val_acc: 0.9987\n",
            "Epoch 599/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0807 - acc: 0.9882 - val_loss: 0.0149 - val_acc: 0.9976\n",
            "Epoch 600/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0501 - acc: 0.9930 - val_loss: 0.0148 - val_acc: 0.9980\n",
            "Epoch 601/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0371 - acc: 0.9943 - val_loss: 0.0149 - val_acc: 0.9988\n",
            "Epoch 602/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0585 - acc: 0.9910 - val_loss: 0.0200 - val_acc: 0.9971\n",
            "Epoch 603/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0594 - acc: 0.9920 - val_loss: 0.0214 - val_acc: 0.9971\n",
            "Epoch 604/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0660 - acc: 0.9902 - val_loss: 0.0465 - val_acc: 0.9918\n",
            "Epoch 605/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0534 - acc: 0.9925 - val_loss: 0.0190 - val_acc: 0.9977\n",
            "Epoch 606/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0493 - acc: 0.9929 - val_loss: 0.0243 - val_acc: 0.9962\n",
            "Epoch 607/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0432 - acc: 0.9929 - val_loss: 0.0351 - val_acc: 0.9918\n",
            "Epoch 608/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0735 - acc: 0.9893 - val_loss: 0.0111 - val_acc: 0.9991\n",
            "Epoch 609/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0445 - acc: 0.9934 - val_loss: 0.0845 - val_acc: 0.9758\n",
            "Epoch 610/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0479 - acc: 0.9926 - val_loss: 0.0195 - val_acc: 0.9966\n",
            "Epoch 611/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0787 - acc: 0.9898 - val_loss: 0.0157 - val_acc: 0.9972\n",
            "Epoch 612/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0479 - acc: 0.9932 - val_loss: 0.8787 - val_acc: 0.8640\n",
            "Epoch 613/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1077 - acc: 0.9847 - val_loss: 0.0159 - val_acc: 0.9986\n",
            "Epoch 614/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0578 - acc: 0.9920 - val_loss: 0.0183 - val_acc: 0.9967\n",
            "Epoch 615/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0683 - acc: 0.9916 - val_loss: 0.0332 - val_acc: 0.9953\n",
            "Epoch 616/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0781 - acc: 0.9909 - val_loss: 0.1284 - val_acc: 0.9846\n",
            "Epoch 617/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0538 - acc: 0.9918 - val_loss: 0.1049 - val_acc: 0.9856\n",
            "Epoch 618/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0513 - acc: 0.9934 - val_loss: 0.0151 - val_acc: 0.9978\n",
            "Epoch 619/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0451 - acc: 0.9936 - val_loss: 0.0317 - val_acc: 0.9953\n",
            "Epoch 620/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0852 - acc: 0.9889 - val_loss: 0.0125 - val_acc: 0.9987\n",
            "Epoch 621/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0560 - acc: 0.9922 - val_loss: 0.0161 - val_acc: 0.9984\n",
            "Epoch 622/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0761 - acc: 0.9896 - val_loss: 0.0987 - val_acc: 0.9825\n",
            "Epoch 623/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0334 - acc: 0.9945 - val_loss: 0.0269 - val_acc: 0.9954\n",
            "Epoch 624/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0477 - acc: 0.9928 - val_loss: 0.0322 - val_acc: 0.9949\n",
            "Epoch 625/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0409 - acc: 0.9945 - val_loss: 0.0114 - val_acc: 0.9984\n",
            "Epoch 626/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0341 - acc: 0.9951 - val_loss: 0.0084 - val_acc: 0.9993\n",
            "Epoch 627/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0503 - acc: 0.9930 - val_loss: 0.1270 - val_acc: 0.9841\n",
            "Epoch 628/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0569 - acc: 0.9928 - val_loss: 0.0224 - val_acc: 0.9963\n",
            "Epoch 629/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0565 - acc: 0.9926 - val_loss: 0.0417 - val_acc: 0.9913\n",
            "Epoch 630/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0948 - acc: 0.9880 - val_loss: 0.0193 - val_acc: 0.9977\n",
            "Epoch 631/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0404 - acc: 0.9938 - val_loss: 0.0434 - val_acc: 0.9932\n",
            "Epoch 632/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1053 - acc: 0.9886 - val_loss: 0.0466 - val_acc: 0.9910\n",
            "Epoch 633/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0714 - acc: 0.9914 - val_loss: 0.3607 - val_acc: 0.9707\n",
            "Epoch 634/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0709 - acc: 0.9916 - val_loss: 0.1020 - val_acc: 0.9863\n",
            "Epoch 635/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0549 - acc: 0.9928 - val_loss: 0.0194 - val_acc: 0.9967\n",
            "Epoch 636/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0583 - acc: 0.9921 - val_loss: 0.0091 - val_acc: 0.9988\n",
            "Epoch 637/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0892 - acc: 0.9898 - val_loss: 0.0116 - val_acc: 0.9989\n",
            "Epoch 638/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0466 - acc: 0.9938 - val_loss: 0.0179 - val_acc: 0.9977\n",
            "Epoch 639/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0583 - acc: 0.9918 - val_loss: 0.0452 - val_acc: 0.9928\n",
            "Epoch 640/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0656 - acc: 0.9922 - val_loss: 0.0107 - val_acc: 0.9991\n",
            "Epoch 641/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1059 - acc: 0.9855 - val_loss: 0.1320 - val_acc: 0.9831\n",
            "Epoch 642/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0672 - acc: 0.9906 - val_loss: 0.0170 - val_acc: 0.9981\n",
            "Epoch 643/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0571 - acc: 0.9922 - val_loss: 0.0273 - val_acc: 0.9954\n",
            "Epoch 644/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0483 - acc: 0.9926 - val_loss: 0.0238 - val_acc: 0.9969\n",
            "Epoch 645/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0590 - acc: 0.9930 - val_loss: 0.1250 - val_acc: 0.9732\n",
            "Epoch 646/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0657 - acc: 0.9915 - val_loss: 0.0816 - val_acc: 0.9891\n",
            "Epoch 647/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0557 - acc: 0.9919 - val_loss: 0.0203 - val_acc: 0.9967\n",
            "Epoch 648/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0540 - acc: 0.9934 - val_loss: 0.1997 - val_acc: 0.9597\n",
            "Epoch 649/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0488 - acc: 0.9924 - val_loss: 0.0160 - val_acc: 0.9969\n",
            "Epoch 650/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0499 - acc: 0.9925 - val_loss: 0.0922 - val_acc: 0.9827\n",
            "Epoch 651/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0595 - acc: 0.9914 - val_loss: 0.0574 - val_acc: 0.9915\n",
            "Epoch 652/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0486 - acc: 0.9929 - val_loss: 0.0263 - val_acc: 0.9969\n",
            "Epoch 653/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0754 - acc: 0.9913 - val_loss: 0.0180 - val_acc: 0.9970\n",
            "Epoch 654/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0452 - acc: 0.9937 - val_loss: 0.0141 - val_acc: 0.9989\n",
            "Epoch 655/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0553 - acc: 0.9926 - val_loss: 0.0497 - val_acc: 0.9922\n",
            "Epoch 656/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0370 - acc: 0.9940 - val_loss: 0.0342 - val_acc: 0.9929\n",
            "Epoch 657/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0586 - acc: 0.9920 - val_loss: 0.0368 - val_acc: 0.9942\n",
            "Epoch 658/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0786 - acc: 0.9901 - val_loss: 0.0321 - val_acc: 0.9950\n",
            "Epoch 659/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0683 - acc: 0.9907 - val_loss: 0.0095 - val_acc: 0.9993\n",
            "Epoch 660/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0671 - acc: 0.9919 - val_loss: 0.0163 - val_acc: 0.9978\n",
            "Epoch 661/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0325 - acc: 0.9955 - val_loss: 0.0093 - val_acc: 0.9986\n",
            "Epoch 662/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1380 - acc: 0.9825 - val_loss: 0.0501 - val_acc: 0.9930\n",
            "Epoch 663/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0460 - acc: 0.9939 - val_loss: 0.0569 - val_acc: 0.9901\n",
            "Epoch 664/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0770 - acc: 0.9906 - val_loss: 0.0431 - val_acc: 0.9935\n",
            "Epoch 665/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0475 - acc: 0.9935 - val_loss: 0.0136 - val_acc: 0.9978\n",
            "Epoch 666/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0690 - acc: 0.9901 - val_loss: 0.0307 - val_acc: 0.9955\n",
            "Epoch 667/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0498 - acc: 0.9928 - val_loss: 0.0930 - val_acc: 0.9869\n",
            "Epoch 668/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0916 - acc: 0.9883 - val_loss: 0.1037 - val_acc: 0.9867\n",
            "Epoch 669/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0534 - acc: 0.9917 - val_loss: 0.0308 - val_acc: 0.9953\n",
            "Epoch 670/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0415 - acc: 0.9939 - val_loss: 0.0159 - val_acc: 0.9977\n",
            "Epoch 671/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0952 - acc: 0.9885 - val_loss: 0.0146 - val_acc: 0.9980\n",
            "Epoch 672/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0680 - acc: 0.9907 - val_loss: 0.1422 - val_acc: 0.9824\n",
            "Epoch 673/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0537 - acc: 0.9923 - val_loss: 0.0193 - val_acc: 0.9974\n",
            "Epoch 674/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0765 - acc: 0.9902 - val_loss: 0.0701 - val_acc: 0.9901\n",
            "Epoch 675/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0463 - acc: 0.9928 - val_loss: 0.0302 - val_acc: 0.9952\n",
            "Epoch 676/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0507 - acc: 0.9922 - val_loss: 0.2661 - val_acc: 0.9514\n",
            "Epoch 677/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0409 - acc: 0.9933 - val_loss: 0.0175 - val_acc: 0.9972\n",
            "Epoch 678/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0956 - acc: 0.9899 - val_loss: 0.0152 - val_acc: 0.9975\n",
            "Epoch 679/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0448 - acc: 0.9927 - val_loss: 0.0102 - val_acc: 0.9988\n",
            "Epoch 680/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0404 - acc: 0.9944 - val_loss: 0.0163 - val_acc: 0.9977\n",
            "Epoch 681/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0732 - acc: 0.9898 - val_loss: 0.0119 - val_acc: 0.9980\n",
            "Epoch 682/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0490 - acc: 0.9930 - val_loss: 0.0158 - val_acc: 0.9980\n",
            "Epoch 683/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0365 - acc: 0.9948 - val_loss: 0.0121 - val_acc: 0.9989\n",
            "Epoch 684/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0823 - acc: 0.9903 - val_loss: 0.0950 - val_acc: 0.9864\n",
            "Epoch 685/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0411 - acc: 0.9941 - val_loss: 0.0235 - val_acc: 0.9964\n",
            "Epoch 686/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0662 - acc: 0.9911 - val_loss: 0.0288 - val_acc: 0.9948\n",
            "Epoch 687/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0306 - acc: 0.9952 - val_loss: 0.0412 - val_acc: 0.9920\n",
            "Epoch 688/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1063 - acc: 0.9859 - val_loss: 0.0104 - val_acc: 0.9989\n",
            "Epoch 689/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0547 - acc: 0.9917 - val_loss: 0.0135 - val_acc: 0.9980\n",
            "Epoch 690/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0420 - acc: 0.9932 - val_loss: 0.0158 - val_acc: 0.9975\n",
            "Epoch 691/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0435 - acc: 0.9942 - val_loss: 0.0191 - val_acc: 0.9965\n",
            "Epoch 692/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0448 - acc: 0.9932 - val_loss: 0.0549 - val_acc: 0.9908\n",
            "Epoch 693/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0356 - acc: 0.9942 - val_loss: 0.0283 - val_acc: 0.9950\n",
            "Epoch 694/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0320 - acc: 0.9952 - val_loss: 0.0222 - val_acc: 0.9964\n",
            "Epoch 695/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0446 - acc: 0.9937 - val_loss: 0.0154 - val_acc: 0.9975\n",
            "Epoch 696/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0468 - acc: 0.9931 - val_loss: 0.0557 - val_acc: 0.9912\n",
            "Epoch 697/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0702 - acc: 0.9902 - val_loss: 0.0405 - val_acc: 0.9922\n",
            "Epoch 698/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0480 - acc: 0.9932 - val_loss: 0.0150 - val_acc: 0.9981\n",
            "Epoch 699/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0639 - acc: 0.9913 - val_loss: 0.0207 - val_acc: 0.9980\n",
            "Epoch 700/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0483 - acc: 0.9932 - val_loss: 0.0098 - val_acc: 0.9983\n",
            "Epoch 701/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0553 - acc: 0.9916 - val_loss: 0.0123 - val_acc: 0.9987\n",
            "Epoch 702/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0451 - acc: 0.9939 - val_loss: 0.0133 - val_acc: 0.9985\n",
            "Epoch 703/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0450 - acc: 0.9938 - val_loss: 0.1034 - val_acc: 0.9867\n",
            "Epoch 704/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0461 - acc: 0.9928 - val_loss: 0.0114 - val_acc: 0.9980\n",
            "Epoch 705/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0548 - acc: 0.9927 - val_loss: 0.0085 - val_acc: 0.9987\n",
            "Epoch 706/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0267 - acc: 0.9960 - val_loss: 0.0073 - val_acc: 0.9988\n",
            "Epoch 707/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0557 - acc: 0.9912 - val_loss: 0.0345 - val_acc: 0.9934\n",
            "Epoch 708/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0374 - acc: 0.9939 - val_loss: 0.0636 - val_acc: 0.9901\n",
            "Epoch 709/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0391 - acc: 0.9938 - val_loss: 0.0217 - val_acc: 0.9962\n",
            "Epoch 710/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0535 - acc: 0.9921 - val_loss: 0.0079 - val_acc: 0.9988\n",
            "Epoch 711/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0404 - acc: 0.9943 - val_loss: 0.0118 - val_acc: 0.9985\n",
            "Epoch 712/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0574 - acc: 0.9922 - val_loss: 0.0382 - val_acc: 0.9940\n",
            "Epoch 713/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0509 - acc: 0.9928 - val_loss: 0.0244 - val_acc: 0.9956\n",
            "Epoch 714/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0699 - acc: 0.9921 - val_loss: 0.0493 - val_acc: 0.9918\n",
            "Epoch 715/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0360 - acc: 0.9945 - val_loss: 0.0089 - val_acc: 0.9980\n",
            "Epoch 716/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0617 - acc: 0.9915 - val_loss: 0.0109 - val_acc: 0.9988\n",
            "Epoch 717/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0463 - acc: 0.9930 - val_loss: 0.0084 - val_acc: 0.9993\n",
            "Epoch 718/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0687 - acc: 0.9897 - val_loss: 0.0302 - val_acc: 0.9939\n",
            "Epoch 719/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0444 - acc: 0.9944 - val_loss: 0.0247 - val_acc: 0.9961\n",
            "Epoch 720/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0368 - acc: 0.9935 - val_loss: 0.0125 - val_acc: 0.9978\n",
            "Epoch 721/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0513 - acc: 0.9924 - val_loss: 0.0224 - val_acc: 0.9961\n",
            "Epoch 722/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0302 - acc: 0.9952 - val_loss: 0.0143 - val_acc: 0.9980\n",
            "Epoch 723/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1123 - acc: 0.9872 - val_loss: 0.0197 - val_acc: 0.9969\n",
            "Epoch 724/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0583 - acc: 0.9930 - val_loss: 0.0279 - val_acc: 0.9953\n",
            "Epoch 725/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0587 - acc: 0.9920 - val_loss: 0.0189 - val_acc: 0.9974\n",
            "Epoch 726/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0306 - acc: 0.9960 - val_loss: 0.0086 - val_acc: 0.9988\n",
            "Epoch 727/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0453 - acc: 0.9932 - val_loss: 0.1363 - val_acc: 0.9764\n",
            "Epoch 728/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0460 - acc: 0.9938 - val_loss: 0.1372 - val_acc: 0.9740\n",
            "Epoch 729/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0324 - acc: 0.9950 - val_loss: 0.0104 - val_acc: 0.9980\n",
            "Epoch 730/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0438 - acc: 0.9935 - val_loss: 0.0635 - val_acc: 0.9854\n",
            "Epoch 731/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0312 - acc: 0.9955 - val_loss: 0.1007 - val_acc: 0.9813\n",
            "Epoch 732/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0496 - acc: 0.9931 - val_loss: 0.0244 - val_acc: 0.9963\n",
            "Epoch 733/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0370 - acc: 0.9944 - val_loss: 0.0369 - val_acc: 0.9949\n",
            "Epoch 734/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0383 - acc: 0.9947 - val_loss: 0.0136 - val_acc: 0.9978\n",
            "Epoch 735/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0520 - acc: 0.9924 - val_loss: 0.0685 - val_acc: 0.9908\n",
            "Epoch 736/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0554 - acc: 0.9922 - val_loss: 0.0099 - val_acc: 0.9991\n",
            "Epoch 737/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0989 - acc: 0.9883 - val_loss: 0.0358 - val_acc: 0.9950\n",
            "Epoch 738/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0589 - acc: 0.9921 - val_loss: 0.0118 - val_acc: 0.9982\n",
            "Epoch 739/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0442 - acc: 0.9938 - val_loss: 0.0480 - val_acc: 0.9926\n",
            "Epoch 740/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0445 - acc: 0.9930 - val_loss: 0.0935 - val_acc: 0.9766\n",
            "Epoch 741/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0896 - acc: 0.9882 - val_loss: 0.0125 - val_acc: 0.9981\n",
            "Epoch 742/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0452 - acc: 0.9931 - val_loss: 0.0080 - val_acc: 0.9989\n",
            "Epoch 743/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0619 - acc: 0.9919 - val_loss: 0.0289 - val_acc: 0.9948\n",
            "Epoch 744/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0639 - acc: 0.9909 - val_loss: 0.0156 - val_acc: 0.9970\n",
            "Epoch 745/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0442 - acc: 0.9946 - val_loss: 0.0081 - val_acc: 0.9992\n",
            "Epoch 746/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0459 - acc: 0.9937 - val_loss: 0.0114 - val_acc: 0.9988\n",
            "Epoch 747/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0536 - acc: 0.9920 - val_loss: 0.0139 - val_acc: 0.9975\n",
            "Epoch 748/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0441 - acc: 0.9941 - val_loss: 0.0088 - val_acc: 0.9992\n",
            "Epoch 749/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0288 - acc: 0.9952 - val_loss: 0.0076 - val_acc: 0.9989\n",
            "Epoch 750/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0383 - acc: 0.9942 - val_loss: 0.0128 - val_acc: 0.9982\n",
            "Epoch 751/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0378 - acc: 0.9953 - val_loss: 0.0181 - val_acc: 0.9976\n",
            "Epoch 752/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0915 - acc: 0.9892 - val_loss: 0.2647 - val_acc: 0.9768\n",
            "Epoch 753/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0563 - acc: 0.9935 - val_loss: 0.0381 - val_acc: 0.9932\n",
            "Epoch 754/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0503 - acc: 0.9927 - val_loss: 0.0724 - val_acc: 0.9904\n",
            "Epoch 755/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0416 - acc: 0.9936 - val_loss: 0.0288 - val_acc: 0.9950\n",
            "Epoch 756/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0684 - acc: 0.9899 - val_loss: 0.0088 - val_acc: 0.9985\n",
            "Epoch 757/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0310 - acc: 0.9948 - val_loss: 0.0865 - val_acc: 0.9822\n",
            "Epoch 758/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0343 - acc: 0.9946 - val_loss: 0.0628 - val_acc: 0.9897\n",
            "Epoch 759/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0543 - acc: 0.9915 - val_loss: 0.0094 - val_acc: 0.9992\n",
            "Epoch 760/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0474 - acc: 0.9927 - val_loss: 0.0548 - val_acc: 0.9910\n",
            "Epoch 761/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0269 - acc: 0.9958 - val_loss: 0.0573 - val_acc: 0.9913\n",
            "Epoch 762/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0372 - acc: 0.9949 - val_loss: 0.0093 - val_acc: 0.9981\n",
            "Epoch 763/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0464 - acc: 0.9936 - val_loss: 0.0272 - val_acc: 0.9950\n",
            "Epoch 764/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0537 - acc: 0.9916 - val_loss: 0.0849 - val_acc: 0.9867\n",
            "Epoch 765/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0572 - acc: 0.9917 - val_loss: 0.0624 - val_acc: 0.9900\n",
            "Epoch 766/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0606 - acc: 0.9915 - val_loss: 0.0109 - val_acc: 0.9982\n",
            "Epoch 767/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0619 - acc: 0.9910 - val_loss: 0.0080 - val_acc: 0.9991\n",
            "Epoch 768/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0554 - acc: 0.9926 - val_loss: 0.1106 - val_acc: 0.9839\n",
            "Epoch 769/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0471 - acc: 0.9922 - val_loss: 0.0168 - val_acc: 0.9977\n",
            "Epoch 770/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0425 - acc: 0.9934 - val_loss: 0.0082 - val_acc: 0.9996\n",
            "Epoch 771/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0393 - acc: 0.9938 - val_loss: 0.0070 - val_acc: 0.9994\n",
            "Epoch 772/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0699 - acc: 0.9900 - val_loss: 0.0079 - val_acc: 0.9993\n",
            "Epoch 773/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0395 - acc: 0.9938 - val_loss: 0.0468 - val_acc: 0.9902\n",
            "Epoch 774/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0689 - acc: 0.9904 - val_loss: 0.0138 - val_acc: 0.9978\n",
            "Epoch 775/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0544 - acc: 0.9916 - val_loss: 0.0317 - val_acc: 0.9948\n",
            "Epoch 776/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0423 - acc: 0.9941 - val_loss: 0.0361 - val_acc: 0.9945\n",
            "Epoch 777/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0498 - acc: 0.9924 - val_loss: 0.0150 - val_acc: 0.9970\n",
            "Epoch 778/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0432 - acc: 0.9936 - val_loss: 0.0131 - val_acc: 0.9977\n",
            "Epoch 779/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0471 - acc: 0.9931 - val_loss: 0.0920 - val_acc: 0.9874\n",
            "Epoch 780/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0569 - acc: 0.9920 - val_loss: 0.0181 - val_acc: 0.9975\n",
            "Epoch 781/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0467 - acc: 0.9925 - val_loss: 0.0082 - val_acc: 0.9989\n",
            "Epoch 782/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0618 - acc: 0.9918 - val_loss: 0.0331 - val_acc: 0.9953\n",
            "Epoch 783/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0285 - acc: 0.9952 - val_loss: 0.0191 - val_acc: 0.9964\n",
            "Epoch 784/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0681 - acc: 0.9921 - val_loss: 0.0975 - val_acc: 0.9715\n",
            "Epoch 785/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1063 - acc: 0.9883 - val_loss: 0.0240 - val_acc: 0.9964\n",
            "Epoch 786/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0462 - acc: 0.9946 - val_loss: 0.0141 - val_acc: 0.9980\n",
            "Epoch 787/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0242 - acc: 0.9962 - val_loss: 0.0529 - val_acc: 0.9918\n",
            "Epoch 788/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0441 - acc: 0.9945 - val_loss: 0.0201 - val_acc: 0.9975\n",
            "Epoch 789/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0561 - acc: 0.9922 - val_loss: 0.0647 - val_acc: 0.9916\n",
            "Epoch 790/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0518 - acc: 0.9931 - val_loss: 0.0444 - val_acc: 0.9940\n",
            "Epoch 791/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0640 - acc: 0.9919 - val_loss: 0.0118 - val_acc: 0.9980\n",
            "Epoch 792/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0631 - acc: 0.9920 - val_loss: 0.0252 - val_acc: 0.9961\n",
            "Epoch 793/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0577 - acc: 0.9927 - val_loss: 0.0098 - val_acc: 0.9990\n",
            "Epoch 794/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0465 - acc: 0.9941 - val_loss: 0.0083 - val_acc: 0.9988\n",
            "Epoch 795/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0484 - acc: 0.9936 - val_loss: 0.0117 - val_acc: 0.9983\n",
            "Epoch 796/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0360 - acc: 0.9950 - val_loss: 0.0122 - val_acc: 0.9981\n",
            "Epoch 797/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0695 - acc: 0.9918 - val_loss: 0.0763 - val_acc: 0.9902\n",
            "Epoch 798/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0828 - acc: 0.9907 - val_loss: 0.1127 - val_acc: 0.9874\n",
            "Epoch 799/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0640 - acc: 0.9912 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 800/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0470 - acc: 0.9935 - val_loss: 0.0066 - val_acc: 0.9991\n",
            "Epoch 801/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0573 - acc: 0.9937 - val_loss: 0.0103 - val_acc: 0.9984\n",
            "Epoch 802/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0558 - acc: 0.9925 - val_loss: 0.0289 - val_acc: 0.9957\n",
            "Epoch 803/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0465 - acc: 0.9933 - val_loss: 0.0655 - val_acc: 0.9905\n",
            "Epoch 804/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0513 - acc: 0.9932 - val_loss: 0.0081 - val_acc: 0.9988\n",
            "Epoch 805/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0579 - acc: 0.9925 - val_loss: 0.0754 - val_acc: 0.9900\n",
            "Epoch 806/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0521 - acc: 0.9925 - val_loss: 0.0960 - val_acc: 0.9825\n",
            "Epoch 807/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0654 - acc: 0.9899 - val_loss: 0.0147 - val_acc: 0.9977\n",
            "Epoch 808/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0426 - acc: 0.9938 - val_loss: 0.1157 - val_acc: 0.9862\n",
            "Epoch 809/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0310 - acc: 0.9958 - val_loss: 0.1005 - val_acc: 0.9871\n",
            "Epoch 810/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0324 - acc: 0.9956 - val_loss: 0.0084 - val_acc: 0.9989\n",
            "Epoch 811/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0677 - acc: 0.9910 - val_loss: 0.0137 - val_acc: 0.9979\n",
            "Epoch 812/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0394 - acc: 0.9942 - val_loss: 0.0118 - val_acc: 0.9983\n",
            "Epoch 813/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0680 - acc: 0.9910 - val_loss: 0.0366 - val_acc: 0.9937\n",
            "Epoch 814/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0366 - acc: 0.9945 - val_loss: 0.0074 - val_acc: 0.9990\n",
            "Epoch 815/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0384 - acc: 0.9947 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 816/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0566 - acc: 0.9929 - val_loss: 0.0486 - val_acc: 0.9913\n",
            "Epoch 817/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0898 - acc: 0.9913 - val_loss: 0.0308 - val_acc: 0.9962\n",
            "Epoch 818/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0214 - acc: 0.9971 - val_loss: 0.0048 - val_acc: 0.9996\n",
            "Epoch 819/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0444 - acc: 0.9941 - val_loss: 0.0057 - val_acc: 0.9995\n",
            "Epoch 820/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0688 - acc: 0.9916 - val_loss: 0.0530 - val_acc: 0.9934\n",
            "Epoch 821/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0520 - acc: 0.9939 - val_loss: 0.0063 - val_acc: 0.9995\n",
            "Epoch 822/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0474 - acc: 0.9936 - val_loss: 0.0387 - val_acc: 0.9916\n",
            "Epoch 823/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0561 - acc: 0.9926 - val_loss: 0.0364 - val_acc: 0.9901\n",
            "Epoch 824/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0621 - acc: 0.9914 - val_loss: 0.0156 - val_acc: 0.9969\n",
            "Epoch 825/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0450 - acc: 0.9941 - val_loss: 0.0486 - val_acc: 0.9935\n",
            "Epoch 826/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0529 - acc: 0.9933 - val_loss: 0.0078 - val_acc: 0.9992\n",
            "Epoch 827/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0910 - acc: 0.9897 - val_loss: 0.0406 - val_acc: 0.9948\n",
            "Epoch 828/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0856 - acc: 0.9892 - val_loss: 0.0098 - val_acc: 0.9986\n",
            "Epoch 829/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0508 - acc: 0.9931 - val_loss: 0.0120 - val_acc: 0.9980\n",
            "Epoch 830/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0284 - acc: 0.9959 - val_loss: 0.0095 - val_acc: 0.9987\n",
            "Epoch 831/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0500 - acc: 0.9932 - val_loss: 0.0079 - val_acc: 0.9987\n",
            "Epoch 832/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0512 - acc: 0.9940 - val_loss: 0.0128 - val_acc: 0.9983\n",
            "Epoch 833/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0506 - acc: 0.9928 - val_loss: 0.0083 - val_acc: 0.9991\n",
            "Epoch 834/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0315 - acc: 0.9959 - val_loss: 0.2949 - val_acc: 0.9764\n",
            "Epoch 835/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0716 - acc: 0.9913 - val_loss: 0.0207 - val_acc: 0.9968\n",
            "Epoch 836/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0349 - acc: 0.9952 - val_loss: 0.0113 - val_acc: 0.9982\n",
            "Epoch 837/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0332 - acc: 0.9954 - val_loss: 0.1703 - val_acc: 0.9834\n",
            "Epoch 838/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0801 - acc: 0.9906 - val_loss: 0.0157 - val_acc: 0.9977\n",
            "Epoch 839/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0816 - acc: 0.9896 - val_loss: 0.0079 - val_acc: 0.9993\n",
            "Epoch 840/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0445 - acc: 0.9936 - val_loss: 0.0085 - val_acc: 0.9990\n",
            "Epoch 841/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0407 - acc: 0.9940 - val_loss: 0.0101 - val_acc: 0.9987\n",
            "Epoch 842/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0603 - acc: 0.9918 - val_loss: 0.0849 - val_acc: 0.9867\n",
            "Epoch 843/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0643 - acc: 0.9907 - val_loss: 0.0329 - val_acc: 0.9950\n",
            "Epoch 844/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0519 - acc: 0.9927 - val_loss: 0.0645 - val_acc: 0.9903\n",
            "Epoch 845/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0457 - acc: 0.9934 - val_loss: 0.0383 - val_acc: 0.9939\n",
            "Epoch 846/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0444 - acc: 0.9941 - val_loss: 0.0089 - val_acc: 0.9984\n",
            "Epoch 847/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0321 - acc: 0.9955 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 848/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0462 - acc: 0.9944 - val_loss: 0.0118 - val_acc: 0.9983\n",
            "Epoch 849/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0621 - acc: 0.9923 - val_loss: 0.0120 - val_acc: 0.9983\n",
            "Epoch 850/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0600 - acc: 0.9915 - val_loss: 0.0479 - val_acc: 0.9921\n",
            "Epoch 851/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0712 - acc: 0.9904 - val_loss: 0.0233 - val_acc: 0.9958\n",
            "Epoch 852/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0617 - acc: 0.9923 - val_loss: 0.0098 - val_acc: 0.9985\n",
            "Epoch 853/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0266 - acc: 0.9964 - val_loss: 0.0326 - val_acc: 0.9950\n",
            "Epoch 854/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0645 - acc: 0.9917 - val_loss: 0.0375 - val_acc: 0.9939\n",
            "Epoch 855/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0496 - acc: 0.9942 - val_loss: 0.0090 - val_acc: 0.9990\n",
            "Epoch 856/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0942 - acc: 0.9887 - val_loss: 0.2668 - val_acc: 0.9761\n",
            "Epoch 857/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0576 - acc: 0.9927 - val_loss: 0.0067 - val_acc: 0.9992\n",
            "Epoch 858/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0278 - acc: 0.9957 - val_loss: 0.0332 - val_acc: 0.9952\n",
            "Epoch 859/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0330 - acc: 0.9947 - val_loss: 0.0647 - val_acc: 0.9909\n",
            "Epoch 860/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0742 - acc: 0.9920 - val_loss: 0.0617 - val_acc: 0.9917\n",
            "Epoch 861/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0391 - acc: 0.9947 - val_loss: 0.0091 - val_acc: 0.9988\n",
            "Epoch 862/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0379 - acc: 0.9943 - val_loss: 0.0108 - val_acc: 0.9983\n",
            "Epoch 863/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0551 - acc: 0.9926 - val_loss: 0.0527 - val_acc: 0.9921\n",
            "Epoch 864/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0829 - acc: 0.9918 - val_loss: 0.0272 - val_acc: 0.9961\n",
            "Epoch 865/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0384 - acc: 0.9948 - val_loss: 0.0084 - val_acc: 0.9991\n",
            "Epoch 866/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0531 - acc: 0.9937 - val_loss: 0.0098 - val_acc: 0.9985\n",
            "Epoch 867/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0497 - acc: 0.9937 - val_loss: 0.0100 - val_acc: 0.9988\n",
            "Epoch 868/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0593 - acc: 0.9920 - val_loss: 0.0090 - val_acc: 0.9990\n",
            "Epoch 869/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0641 - acc: 0.9916 - val_loss: 0.0793 - val_acc: 0.9843\n",
            "Epoch 870/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0361 - acc: 0.9941 - val_loss: 0.0399 - val_acc: 0.9934\n",
            "Epoch 871/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0339 - acc: 0.9950 - val_loss: 0.0107 - val_acc: 0.9983\n",
            "Epoch 872/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0501 - acc: 0.9929 - val_loss: 0.0075 - val_acc: 0.9993\n",
            "Epoch 873/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0735 - acc: 0.9901 - val_loss: 0.1018 - val_acc: 0.9860\n",
            "Epoch 874/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0294 - acc: 0.9957 - val_loss: 0.0077 - val_acc: 0.9991\n",
            "Epoch 875/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0684 - acc: 0.9917 - val_loss: 0.1205 - val_acc: 0.9855\n",
            "Epoch 876/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0280 - acc: 0.9958 - val_loss: 0.0062 - val_acc: 0.9994\n",
            "Epoch 877/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0535 - acc: 0.9932 - val_loss: 0.0147 - val_acc: 0.9978\n",
            "Epoch 878/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0508 - acc: 0.9921 - val_loss: 0.0113 - val_acc: 0.9988\n",
            "Epoch 879/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0465 - acc: 0.9935 - val_loss: 0.0246 - val_acc: 0.9961\n",
            "Epoch 880/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0347 - acc: 0.9954 - val_loss: 0.0080 - val_acc: 0.9992\n",
            "Epoch 881/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0696 - acc: 0.9908 - val_loss: 0.0198 - val_acc: 0.9976\n",
            "Epoch 882/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0342 - acc: 0.9951 - val_loss: 0.0274 - val_acc: 0.9958\n",
            "Epoch 883/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0298 - acc: 0.9955 - val_loss: 0.0142 - val_acc: 0.9980\n",
            "Epoch 884/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0315 - acc: 0.9954 - val_loss: 0.0299 - val_acc: 0.9961\n",
            "Epoch 885/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0450 - acc: 0.9942 - val_loss: 0.0123 - val_acc: 0.9982\n",
            "Epoch 886/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0498 - acc: 0.9940 - val_loss: 0.0122 - val_acc: 0.9981\n",
            "Epoch 887/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0337 - acc: 0.9951 - val_loss: 0.0108 - val_acc: 0.9983\n",
            "Epoch 888/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0295 - acc: 0.9956 - val_loss: 0.0093 - val_acc: 0.9983\n",
            "Epoch 889/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0383 - acc: 0.9952 - val_loss: 0.0485 - val_acc: 0.9929\n",
            "Epoch 890/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0303 - acc: 0.9958 - val_loss: 0.0105 - val_acc: 0.9989\n",
            "Epoch 891/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0503 - acc: 0.9929 - val_loss: 0.0308 - val_acc: 0.9955\n",
            "Epoch 892/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0343 - acc: 0.9955 - val_loss: 0.0121 - val_acc: 0.9985\n",
            "Epoch 893/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0605 - acc: 0.9918 - val_loss: 0.0547 - val_acc: 0.9910\n",
            "Epoch 894/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0371 - acc: 0.9949 - val_loss: 0.0077 - val_acc: 0.9993\n",
            "Epoch 895/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0314 - acc: 0.9957 - val_loss: 0.0331 - val_acc: 0.9938\n",
            "Epoch 896/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0306 - acc: 0.9961 - val_loss: 0.1177 - val_acc: 0.9857\n",
            "Epoch 897/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0431 - acc: 0.9937 - val_loss: 0.0109 - val_acc: 0.9986\n",
            "Epoch 898/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0325 - acc: 0.9954 - val_loss: 0.0173 - val_acc: 0.9969\n",
            "Epoch 899/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0550 - acc: 0.9924 - val_loss: 0.0087 - val_acc: 0.9985\n",
            "Epoch 900/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0411 - acc: 0.9940 - val_loss: 0.0144 - val_acc: 0.9980\n",
            "Epoch 901/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0610 - acc: 0.9917 - val_loss: 0.0213 - val_acc: 0.9962\n",
            "Epoch 902/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0447 - acc: 0.9942 - val_loss: 0.0893 - val_acc: 0.9870\n",
            "Epoch 903/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0446 - acc: 0.9941 - val_loss: 0.0265 - val_acc: 0.9954\n",
            "Epoch 904/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0432 - acc: 0.9942 - val_loss: 0.0255 - val_acc: 0.9960\n",
            "Epoch 905/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0356 - acc: 0.9951 - val_loss: 0.0124 - val_acc: 0.9988\n",
            "Epoch 906/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0759 - acc: 0.9902 - val_loss: 0.1098 - val_acc: 0.9857\n",
            "Epoch 907/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0394 - acc: 0.9944 - val_loss: 0.0594 - val_acc: 0.9913\n",
            "Epoch 908/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0341 - acc: 0.9945 - val_loss: 0.1014 - val_acc: 0.9811\n",
            "Epoch 909/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0419 - acc: 0.9943 - val_loss: 0.0095 - val_acc: 0.9986\n",
            "Epoch 910/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0579 - acc: 0.9917 - val_loss: 0.0390 - val_acc: 0.9953\n",
            "Epoch 911/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0470 - acc: 0.9931 - val_loss: 0.0280 - val_acc: 0.9953\n",
            "Epoch 912/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0316 - acc: 0.9949 - val_loss: 0.0105 - val_acc: 0.9988\n",
            "Epoch 913/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0467 - acc: 0.9936 - val_loss: 0.0675 - val_acc: 0.9868\n",
            "Epoch 914/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0356 - acc: 0.9952 - val_loss: 0.0084 - val_acc: 0.9985\n",
            "Epoch 915/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0566 - acc: 0.9924 - val_loss: 0.0089 - val_acc: 0.9993\n",
            "Epoch 916/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0266 - acc: 0.9956 - val_loss: 0.0128 - val_acc: 0.9979\n",
            "Epoch 917/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0555 - acc: 0.9922 - val_loss: 0.0105 - val_acc: 0.9987\n",
            "Epoch 918/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0549 - acc: 0.9936 - val_loss: 0.0081 - val_acc: 0.9992\n",
            "Epoch 919/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0487 - acc: 0.9933 - val_loss: 0.0129 - val_acc: 0.9986\n",
            "Epoch 920/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0385 - acc: 0.9950 - val_loss: 0.0233 - val_acc: 0.9955\n",
            "Epoch 921/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0365 - acc: 0.9948 - val_loss: 0.0071 - val_acc: 0.9993\n",
            "Epoch 922/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0604 - acc: 0.9920 - val_loss: 0.0316 - val_acc: 0.9921\n",
            "Epoch 923/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0549 - acc: 0.9928 - val_loss: 0.1632 - val_acc: 0.9835\n",
            "Epoch 924/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0480 - acc: 0.9934 - val_loss: 0.0474 - val_acc: 0.9933\n",
            "Epoch 925/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1493 - acc: 0.9866 - val_loss: 0.1639 - val_acc: 0.9834\n",
            "Epoch 926/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0653 - acc: 0.9936 - val_loss: 0.0155 - val_acc: 0.9981\n",
            "Epoch 927/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1057 - acc: 0.9907 - val_loss: 0.1130 - val_acc: 0.9902\n",
            "Epoch 928/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0570 - acc: 0.9944 - val_loss: 0.0434 - val_acc: 0.9959\n",
            "Epoch 929/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0471 - acc: 0.9951 - val_loss: 0.0636 - val_acc: 0.9940\n",
            "Epoch 930/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0450 - acc: 0.9956 - val_loss: 0.0384 - val_acc: 0.9960\n",
            "Epoch 931/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0541 - acc: 0.9947 - val_loss: 0.0116 - val_acc: 0.9988\n",
            "Epoch 932/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0746 - acc: 0.9930 - val_loss: 0.0279 - val_acc: 0.9970\n",
            "Epoch 933/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0708 - acc: 0.9930 - val_loss: 0.0264 - val_acc: 0.9968\n",
            "Epoch 934/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0873 - acc: 0.9923 - val_loss: 0.0296 - val_acc: 0.9971\n",
            "Epoch 935/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1401 - acc: 0.9874 - val_loss: 0.1183 - val_acc: 0.9892\n",
            "Epoch 936/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0634 - acc: 0.9939 - val_loss: 0.0239 - val_acc: 0.9978\n",
            "Epoch 937/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0554 - acc: 0.9951 - val_loss: 0.0162 - val_acc: 0.9984\n",
            "Epoch 938/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0850 - acc: 0.9925 - val_loss: 0.0237 - val_acc: 0.9979\n",
            "Epoch 939/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0918 - acc: 0.9924 - val_loss: 0.0227 - val_acc: 0.9977\n",
            "Epoch 940/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0698 - acc: 0.9939 - val_loss: 0.0468 - val_acc: 0.9946\n",
            "Epoch 941/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0722 - acc: 0.9936 - val_loss: 0.0145 - val_acc: 0.9980\n",
            "Epoch 942/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0552 - acc: 0.9948 - val_loss: 0.0912 - val_acc: 0.9918\n",
            "Epoch 943/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0577 - acc: 0.9949 - val_loss: 0.0355 - val_acc: 0.9968\n",
            "Epoch 944/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0803 - acc: 0.9930 - val_loss: 0.0138 - val_acc: 0.9985\n",
            "Epoch 945/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0638 - acc: 0.9945 - val_loss: 0.0281 - val_acc: 0.9976\n",
            "Epoch 946/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0697 - acc: 0.9936 - val_loss: 0.0187 - val_acc: 0.9981\n",
            "Epoch 947/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0792 - acc: 0.9929 - val_loss: 0.0187 - val_acc: 0.9980\n",
            "Epoch 948/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0519 - acc: 0.9953 - val_loss: 0.0102 - val_acc: 0.9990\n",
            "Epoch 949/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0665 - acc: 0.9942 - val_loss: 0.0347 - val_acc: 0.9968\n",
            "Epoch 950/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0884 - acc: 0.9929 - val_loss: 0.0982 - val_acc: 0.9918\n",
            "Epoch 951/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0863 - acc: 0.9929 - val_loss: 0.3528 - val_acc: 0.9752\n",
            "Epoch 952/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1262 - acc: 0.9899 - val_loss: 0.0080 - val_acc: 0.9989\n",
            "Epoch 953/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0539 - acc: 0.9952 - val_loss: 0.0084 - val_acc: 0.9988\n",
            "Epoch 954/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0664 - acc: 0.9941 - val_loss: 0.0273 - val_acc: 0.9977\n",
            "Epoch 955/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0883 - acc: 0.9927 - val_loss: 0.2591 - val_acc: 0.9815\n",
            "Epoch 956/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0697 - acc: 0.9942 - val_loss: 0.0565 - val_acc: 0.9910\n",
            "Epoch 957/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1637 - acc: 0.9864 - val_loss: 0.0760 - val_acc: 0.9936\n",
            "Epoch 958/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0637 - acc: 0.9939 - val_loss: 0.0293 - val_acc: 0.9971\n",
            "Epoch 959/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1364 - acc: 0.9880 - val_loss: 0.0220 - val_acc: 0.9972\n",
            "Epoch 960/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0762 - acc: 0.9925 - val_loss: 0.1066 - val_acc: 0.9908\n",
            "Epoch 961/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0503 - acc: 0.9955 - val_loss: 0.0102 - val_acc: 0.9988\n",
            "Epoch 962/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0650 - acc: 0.9942 - val_loss: 0.0513 - val_acc: 0.9914\n",
            "Epoch 963/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0893 - acc: 0.9924 - val_loss: 0.0299 - val_acc: 0.9975\n",
            "Epoch 964/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0505 - acc: 0.9951 - val_loss: 0.0066 - val_acc: 0.9992\n",
            "Epoch 965/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1100 - acc: 0.9906 - val_loss: 0.0913 - val_acc: 0.9926\n",
            "Epoch 966/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0901 - acc: 0.9922 - val_loss: 0.0707 - val_acc: 0.9940\n",
            "Epoch 967/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0631 - acc: 0.9946 - val_loss: 0.1860 - val_acc: 0.9857\n",
            "Epoch 968/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0774 - acc: 0.9933 - val_loss: 0.0186 - val_acc: 0.9981\n",
            "Epoch 969/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1777 - acc: 0.9861 - val_loss: 0.0176 - val_acc: 0.9964\n",
            "Epoch 970/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0911 - acc: 0.9922 - val_loss: 0.2494 - val_acc: 0.9822\n",
            "Epoch 971/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0637 - acc: 0.9942 - val_loss: 0.0585 - val_acc: 0.9907\n",
            "Epoch 972/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1127 - acc: 0.9905 - val_loss: 0.1027 - val_acc: 0.9853\n",
            "Epoch 973/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0490 - acc: 0.9956 - val_loss: 0.0429 - val_acc: 0.9960\n",
            "Epoch 974/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.2261 - acc: 0.9807 - val_loss: 0.0657 - val_acc: 0.9937\n",
            "Epoch 975/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0617 - acc: 0.9942 - val_loss: 0.0210 - val_acc: 0.9981\n",
            "Epoch 976/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0689 - acc: 0.9940 - val_loss: 0.0092 - val_acc: 0.9988\n",
            "Epoch 977/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0748 - acc: 0.9925 - val_loss: 0.0166 - val_acc: 0.9983\n",
            "Epoch 978/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0867 - acc: 0.9923 - val_loss: 0.1726 - val_acc: 0.9869\n",
            "Epoch 979/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0657 - acc: 0.9941 - val_loss: 0.0818 - val_acc: 0.9930\n",
            "Epoch 980/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0583 - acc: 0.9944 - val_loss: 0.1516 - val_acc: 0.9876\n",
            "Epoch 981/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0657 - acc: 0.9942 - val_loss: 0.0200 - val_acc: 0.9982\n",
            "Epoch 982/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0650 - acc: 0.9939 - val_loss: 0.0407 - val_acc: 0.9961\n",
            "Epoch 983/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0690 - acc: 0.9935 - val_loss: 0.2077 - val_acc: 0.9686\n",
            "Epoch 984/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0886 - acc: 0.9914 - val_loss: 1.1174 - val_acc: 0.8834\n",
            "Epoch 985/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1017 - acc: 0.9913 - val_loss: 0.0121 - val_acc: 0.9985\n",
            "Epoch 986/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0784 - acc: 0.9928 - val_loss: 0.0228 - val_acc: 0.9963\n",
            "Epoch 987/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1164 - acc: 0.9906 - val_loss: 0.0261 - val_acc: 0.9958\n",
            "Epoch 988/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0668 - acc: 0.9938 - val_loss: 0.0188 - val_acc: 0.9974\n",
            "Epoch 989/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0915 - acc: 0.9921 - val_loss: 0.0652 - val_acc: 0.9946\n",
            "Epoch 990/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0401 - acc: 0.9960 - val_loss: 0.0293 - val_acc: 0.9973\n",
            "Epoch 991/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0786 - acc: 0.9936 - val_loss: 0.0150 - val_acc: 0.9985\n",
            "Epoch 992/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1409 - acc: 0.9870 - val_loss: 0.2504 - val_acc: 0.9816\n",
            "Epoch 993/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0839 - acc: 0.9929 - val_loss: 0.0461 - val_acc: 0.9947\n",
            "Epoch 994/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1075 - acc: 0.9909 - val_loss: 0.0159 - val_acc: 0.9983\n",
            "Epoch 995/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0650 - acc: 0.9939 - val_loss: 0.1352 - val_acc: 0.9804\n",
            "Epoch 996/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0773 - acc: 0.9933 - val_loss: 0.2473 - val_acc: 0.9816\n",
            "Epoch 997/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0697 - acc: 0.9938 - val_loss: 0.0760 - val_acc: 0.9939\n",
            "Epoch 998/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.1739 - acc: 0.9848 - val_loss: 0.0070 - val_acc: 0.9991\n",
            "Epoch 999/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0616 - acc: 0.9948 - val_loss: 0.0984 - val_acc: 0.9912\n",
            "Epoch 1000/1000\n",
            "54924/54924 [==============================] - 1s 25us/step - loss: 0.0825 - acc: 0.9928 - val_loss: 0.0244 - val_acc: 0.9967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x6RFAgEdZvNJ",
        "colab_type": "code",
        "outputId": "cec3c3d5-43d9-4549-d890-91e93d3b47a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        }
      },
      "cell_type": "code",
      "source": [
        "Y_predict = model.predict(X_test)\n",
        "Y_predict =(Y_predict>0.5)\n",
        "print(confusion_matrix(Y_test, Y_predict))\n",
        "print(classification_report(Y_test, Y_predict))\n",
        "\n",
        "pyplot.plot(history.history['acc'])\n",
        "pyplot.plot(history.history['val_acc'])\n",
        "pyplot.title('Model Train vs Test Accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'test'], loc='upper left')\n",
        "pyplot.show()\n",
        "\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('Model Train vs Test loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'test'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[27871    66]\n",
            " [   44  1443]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00     27937\n",
            "        True       0.96      0.97      0.96      1487\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     29424\n",
            "   macro avg       0.98      0.98      0.98     29424\n",
            "weighted avg       1.00      1.00      1.00     29424\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXlclNX+xz/PrGwDDDCArAIqCIiK\nCCruAuKSWuaSeSstTds087ZoZYvXlpuVrbe61e2XefOWWlmZZZq55ZJ7mikoIiiy7wyz/f4YZn9m\neGaYgWH8vl8vi3me85znPGeeOZ/z/Z7vOYfRaDQaEARBEATR7eF1dQEIgiAIgnAOJOoEQRAE4SGQ\nqBMEQRCEh0CiThAEQRAeAok6QRAEQXgIJOoEQRAE4SGQqBM3PImJiXjooYcsjq9cuRKJiYl257dy\n5Uq8+eabNtNs3rwZd911l8XxRYsWIT8/H/n5+UhMTERubi7y8/Nx66232lWGsrIyTJ482a5rOsKm\nTZv05R40aBCGDBmi/3zgwAGH8ty9ezeuXbtmM82sWbMwbdo0h/InCE9E0NUFIAh34Ny5c2hoaICf\nnx8AoLW1FadOner0cvzrX//S/52YmIhPP/0U4eHhducTFhaGb7/91plFs8n06dMxffp0AMDjjz+O\nmJgY3HfffR3K8+OPP8bSpUutPv/Zs2chlUqhVCpx8uRJpKWldeh+BOEJkKVOEACysrLw008/6T/v\n3bsX/fr1M0mzbds2TJ48Gfn5+bjjjjtw+fJlAEB1dTXmz5+PsWPHYuHChaivr9dfc+HCBcydOxfj\nx4/HTTfd1OGOwtixY/HWW29h/PjxKC0tRWFhIW677TZMmDABubm5eiG/cuUKkpOTAWi9Ag899BBW\nrFiB8ePHY+LEiTh//rxJvmq1GsOHD8fp06f1x/7zn//g4YcfRmNjI+6//35MmDAB48aNw5NPPgmF\nQmFXueVyOZ577jmMHz8eY8eOxfvvv68/98knn2DChAnIz8/HjBkzUFBQgLVr1+Lw4cNYtmwZfvjh\nB9Y8t2zZgvz8fEyePBlff/21yblNmzYhLy8P48ePx2OPPYbW1larx/fv34/8/Hz9tcafX3vtNTz9\n9NOYPn06Pv30U6hUKqxatUr/HI8//jiUSiUAoKqqCgsXLsS4ceMwZcoU7N+/Hzt27MDUqVNNyjZ1\n6lTs2rXLrvojCK6QqBMEgAkTJphYtt99951JQ19aWoqnnnoKb7/9Nn744QeMHj0aTz/9NADggw8+\ngFQqxc6dO/H0009j7969ALRCef/992Pq1KnYvn07nnnmGdx33316EXCUsrIybN++HREREXj55Zcx\nZswYbNu2DWvWrMHKlStZBffXX3/FnDlzsH37dmRlZeGTTz4xOc/j8ZCTk4OdO3fqj+3YsQMTJkzA\nV199BX9/f2zbtg3bt28Hn8/HhQsX7Crze++9h6KiImzduhVbt27Fd999h19//RV1dXV4++238eWX\nX+KHH37AXXfdhd27d+ORRx5BcHAwXn31VZPvQYdSqcTPP/+MvLw85ObmYteuXfrnLioqwtq1a/HZ\nZ59h27ZtqK2txYYNG6web4/du3fjww8/xN/+9jds374dJ06cwHfffYfvv/8ex44dw/bt2wEAL7/8\nMvr27Yuff/4Zq1evxrJlyzBy5EiUlpaioKAAAFBcXIyrV69i+PDhdtUfQXCFRJ0gAGRmZuL8+fOo\nrKxEc3Mzjh07hqFDh+rP79u3D1lZWYiNjQUAzJgxAwcPHoRSqcSRI0cwYcIEAEBUVBQyMzMBAIWF\nhaisrNSPhw8aNAhBQUE4duxYh8o6evRo/d/vvPMO7r77bn3+crkc5eXlFtckJCQgNTUVAJCcnIyr\nV69apBk/frxe1KuqqvDnn39i1KhR+jLv3bsXarUazz77LPr27WtXmXft2oU5c+ZAJBLB19cXU6ZM\nwU8//QQvLy9oNBps2rQJFRUVmDRpEubPn99ufrt378bAgQPh4+MDX19fDBw4ELt37wag9bJkZGRA\nJpOBx+Nh3bp1mDt3rtXj7TFgwAAEBgYCACZOnIj//e9/EAgE8PLyQmpqKoqLi/VlmjRpEgAgLS0N\nO3bsgEgkQm5uLrZu3QpA21HKycmBUCi0q/4Igis0pk4QAPh8PvLy8rBt2zYEBQVh+PDhEAgMP4/q\n6mr4+/vrP0skEmg0GlRXV6O2thYSiUR/Tpeurq4OLS0tesEHgIaGBtTU1HSorAEBAfq/9+zZg3ff\nfRfV1dVgGAYajQZqtdriGuPy8fl8qFQqizSZmZkoKytDaWkp9u/fj1GjRkEsFmPChAmora3FunXr\nUFhYiClTpuCJJ56ASCTiXOa6ujqsXr0a//znPwFoYxYGDhwIkUiEjz/+GO+//z7WrVuHvn37YtWq\nVejdu7fN/LZs2YJ9+/YhIyMDAKBSqSCXy5GTk4Pq6mqT5xWLxQBg9Xh7GNd3RUUFVq9ejbNnz4Jh\nGJSXlyMhIQEAUFNTY/KO6OIzJk+ejFWrVmHp0qXYsWMHFi9ezOm+BOEIJOoE0cbEiRPx2muvQSqV\nYs6cOSbngoODTSzs2tpa8Hg8SKVS+Pv7m4yjV1VVITo6GqGhofD19WUdE968eXOHy6tQKLB06VK8\n/vrrGDVqFFpbWzsULMbn85GTk4Ndu3Zhz549JhH3s2fPxuzZs1FWVoYHH3wQX331FWbOnMk579DQ\nUCxevBgjR460OJeamoo33ngDra2teO+99/Dss89i/fr1VvOqrq7G0aNHcejQIb3Fq1AoMGrUKNTU\n1EAqleLMmTP69PX19ZDL5VaP83g8k45QbW2t1XuvXbsWXl5e2Lp1K0QiEZYuXao/FxgYiOrqan1g\nX3FxMcLDw5GVlYXm5mb88ssvuHTpEoYMGcKhxgjCMcj9ThBtDBw4ENevX8f58+f1LnQd2dnZOHLk\niN7V+vnnnyM7OxsCgQADBgzAjh07AACXL1/G77//DgCIjIxEeHi4XtSrqqqwbNkyNDU1OaW8zc3N\naGpq0rvVP/nkEwiFwg7lr3PBnzp1Si/AujFvQBtVHxUVBYZh7Mp33Lhx+OKLL6BSqaDRaPDWW29h\n7969OHv2LB5++GEoFAqIRCKkpqbq8xYIBKirq7PI69tvv8WwYcNMXNhCoRBDhw7Fd999h9GjR+PI\nkSMoLS2FRqPBk08+iS1btlg9LpPJUFZWhurqaiiVSpuzBqqqqpCYmAiRSIQzZ87gxIkT+voeO3as\nvrN27tw53HrrrdBoNODz+cjPz8dzzz2HcePGmXiACMLZkKgTRBsMwyA3NxfDhg0Dj2f60wgPD8fq\n1atx3333IT8/H4cPH8Zzzz0HALj33ntRUlKCsWPH4vnnn0deXp4+v1dffRWfffYZ8vPzMXfuXAwd\nOhQ+Pj5OKa+/vz/uueceTJs2DdOmTUNMTAxycnKwaNEiNDc3O5TnkCFDcPr0aQwbNkzvXp86dSq+\n/vprjB8/Hvn5+RAKhRYR3e1xxx13IDQ0FJMmTUJ+fj6KioowaNAgJCYmIiwsDBMnTsSkSZPw7rvv\n4oknngCg7WAsWbLEIqhvy5YtyMnJsbhHbm4uvv76a0RGRmLVqlWYO3cu8vPzIRKJcOedd1o9npCQ\ngClTpmDKlCmYO3cuhg0bZvU55s+fj/Xr12PixInYuHEjHn30UXz++ef48ccf8eijj6K4uBhjx47F\n8uXLsXbtWn0dTp48GSUlJZg4caJd9UYQ9sLQfuoEQRCupaysDLNmzcLOnTstOowE4Uzo7SIIgnAh\nGo0Gb775JubMmUOCTrgcesMIgiBcRFlZGcaNG4fa2lrWZYEJwtmQ+50gCIIgPASy1AmCIAjCQyBR\nJwiCIAgPodtPmCwvr28/kR1IpT6ornbOPOIbFapD50D12HGoDjsO1WHHcXYdymQSq+fIUjdDIOB3\ndRG6PVSHzoHqseNQHXYcqsOO05l1SKJOEARBEB4CiTpBEARBeAgk6gRBEAThIZCoEwRBEISHQKJO\nEARBEB4CiTpBEARBeAgk6gRBEAThIbhU1P/66y/k5ORg/fr1Fuf279+PW2+9FbNmzcLbb7+tP75m\nzRrMmjULs2fPxsmTJ11ZPJfyyy8/c0q3bt1alJaWuLg0BEEQxI2Ay1aUa2pqwvPPP4+hQ4eynl+9\nejU+/PBDhIWFYe7cuRg/fjyqqqpQVFSEjRs3oqCgACtWrMDGjRtdVUSXcfVqKXbs2I7Ro8e1m3bJ\nkkc6oUQEQRDEjYDLRF0kEuGDDz7ABx98YHGuuLgYAQEB6NGjBwBg1KhROHDgAKqqqpCTkwMASEhI\nQG1tLRoaGuDn5+eqYrqEV199CWfP/oERIwYjL28Crl4txeuvv4MXXngO5eXX0dzcjPnzFyI7ewQe\neGAhli17FLt2/YzGxgZcvlyEkpIreOihRzB0aHZXPwpBEATRjXCZqAsEAggE7NmXl5cjKChI/zko\nKAjFxcWorq5GSkqKyfHy8vIOifr/dl7A4T+vc07P5zNQqWzvRjs4KRQzx/ayev622/6GzZv/h7i4\nBFy+fAnvvPNvVFdXITNzCCZMmIySkit46qnHkZ09wuS669fL8Morb+C33/bj6683kagThINoNBow\nDGP1szFyVSt4YCDkC23mYYxao0ZVSw1CvINYz3eUFqUcfIZnUSZrKFQK8Hl88BjDiKpao4ZGowGf\np12iVKlW4vC1Y4gPiEWYb2i7eao1ajQoGiGD5Trjlc1VqGqpwZWGUvT0j0ZcQCxrHpXN1ZB6BYDH\n8FDVUg0/oS9EfJH+vHEd6/6ub22AgMfH9aYKREsiAcDkuQCgvrUBQp4AXgIvq2Uvb65EsJcUKo0a\nAoavrwdH0Gg00EBjUQ53xK03dOGy1btU6mNzXV1vHxH4fPYfpjXaS+/tI7K5oH5goA/EYiF8fcUY\nPHgQZDIJAgO98Pnn5/HggwvA4/HQ2FgPmUwCkUgAqdQXvr5iDB2aBZlMgsTEOMjlzTbv4e64Y9lL\n665BwBci1DfY5HhtSx2++fMnzEidDC+BmPXanYX7IeDxMbJnlsnxisYqtCjlOFJ6ElOT8qyKwPnK\niwjxCUKglz+alS3wEXqbnP/sxBb4iyUYGz8MJ8vOIjNyAABDPSrVKijVStbyVTZVQ+odYLPBuVRd\njB0FezEvfSanxu1wyQlUNdVgfO9RAICm1mZ8fvobDAhPxsmyPzEuPhvfnvsZk/qMRahfCA5dOY6M\nyDT9c6nUKqg0anzz50/ISRiOQC9/KNUqCHh8NCma4SP0hlKlRIOiCYFe/hb3L627hkDvAH1+ugZf\nrVabiEBh9WWIBSJEB0Tg54K9OHjlGIR8IS5UXUK/sCQMV2YiNjAS937zOP7Wfzqk3v5IkvWCn9AH\n35zbgaHR6Xj0xzWIC4zGmtzHAAA/XdiD7//aiZL6a7hjwK2YnGgYRiusuoxNZ75HbGAUvvzjOwyN\nHoSHh91jUf6a5lr834nNCPUNRr28AalhiThW+gcWDr4dgrb6r2yqxk8FexDo5Y+/Ki8iXhqDa/XX\nMbVvHh7//ln0CYnHqjEPo1XZii/PfI+x8dkI95OhSdGMZ3e+hql981Avb8R/jn8BlVoFAJjYewzu\nSp+JM9fPY/XuNyDmC/HxLa9iR8FevH/kM3353pn8D4T4BuF/p7fCW+CNm5K0HlK1Ro11Bz4CAIT4\nSLH13A6M7JkFf7EEt/WbgncPfQo1NNh/+YjJ8w6NHoQDxb+jd1BPnK+6hPQeqcjrNQovHngbqaGJ\nWJgxB0/tfAHx0hjM7X8zfirYiwPFvyNeGoOkkARcb6zEkdKTiAuMxsWaYov6/L9bXoNCrcSRkpP4\nqWAPLlRdAgDckjwBw6IHQQMNtl/4FUOj01FUcwWfndgClUatvz41NBFPjV4ChmHw04U9CPIJRP/w\nZFytL0N0QASuN1TgSt01/FTwK8J8Q3C5thRj47MxPHYwdl/8DW8f+gQA8P7Ul/Tv64Hi33Hm+nnc\nOXAG+AwPf1ZcQLBPELz4IlyouoTk0D74+Oj/8Gf5Bbw+8ZlOaxMZDRfl7ABvvvkmpFIp5s6dqz92\n5coVPPLII/rx8rfeeguBgYGorq6GTCbD7NmzAQDjxo3D119/bdNSd/YubTKZpMN5Hj16RG+pBwYG\nYvr0Wdi27VscPHgATz/9POrq6nDPPX/Dl19uNXG/69IWFl7Aq6++jLfeet9JT9W5OKMOXcH9Ox8F\nALw99mX9sVZVKx7e/SQAYFRUNmb2mdp2XIE3j3+AUZFDkRE+UH/t8MghqGiqhK/QB79fP2GS/4MD\nFiApqLfFfZsUzfj7nlUQ8YRIDemLo9dP4h/ZK+HF94KXQIyzlX/hrRP/BgAMkKXiePlpDOmRgVG9\nMrHzr99wW9ItePbAS6htrUeUXwSmJEzAt4U/IFAciGERg/Gvk/8BAHjxxcgMT8eMtmf4+fKvqG2t\nw7AemfjHoVcBAAv63YEBslSrdVRcX4K61nq8c0LbsM9Lvg29pb1wqa4I75/6P9Zr5iRNx4Y/N0HA\n8PHKqOdxteEa1h59B0q1EgAQ5iPDmOgR+PzcZvQPScGJij+QFpKCkxV/AACeylqOcCPLsb61AY/v\nfQ5RfhF4InMp1Bo1ntr/AuICYnG+ugApwUmoldehsK4IrapWq8+iw1fog0aF6Q5ZId7BqGiuNDl2\na+8pSA/tjxX7njc5/nD6YvQKjANgeIeMGRU1DMlBibhYdxkHr/6O+/rPxy9X9mJf6SGLtDP6TEW/\n4GTsvrIPPxf/ylpeb4E3mpXNrOdm9bkZ+0sPorih1Orz3pk8G5+c+Vz/WSoORLW8xiRNanBfyHyC\nsat4LwBgRORQXKq7jACRBKcr/7RSLi80K1us3tcWxt93VyEVByI+IFb/u80IG4AjZcdtXrNu9Bos\n+WWF/jOf4WNgaD/cnnSrvt3wF0lQ12q7vVt/6xuorXKs7tiw1UHoEks9KioKDQ0NuHLlCsLDw7Fr\n1y688sorqK6uxptvvonZs2fjjz/+QGhoaLcbTwcAHo8HlUplcqympgY9ekSAx+Nh9+6dUCgUXVQ6\nz6O04Rr+e24zKpursCT9XoT5yEzOK1QKvHHc0EH67OyXSAzqhYywAdhbelB//ET5aUxNmAAxX4Sj\n10+gsPYSCmsvwU9keAf3lvxmtRwtKjnr8Yt1RQCAVrUCR69rZ3S8+vs7qGypxrSEifiq4Ht92uPl\npwEAv109gt+uaq2hw2VH9eevNJTikz/+i0ZlEy7Xl6Cypcrk/r+WHIDMOxhgGH2+uoYbAHYU/YIN\nZ7/EnSm3obypAnEBMYj1j4ZGo8Hnf22xeL6Pz/wXIyOHIS4gxupzf39xBwBAqVHhs7NfoHdgvF7Q\nAaCsqRybzn8DADjR1rAbN/DPH3wFfaS9kCTthTHRI3Cp7rL+WeWqVqg1KtTIa3Gsre4OXvvdalnY\nMBd0ABaCDgBfnv8GPxbtsjj+2tF30TeoD0obrrLmv/vKfuy+sl//+R+HXjVxMRvz/cWf8MVfX9ss\nrzVBB4CNf22xeS0AbGv7PnSYCzoAnK48CxhVwZ6SAwAASxvZuFyOi1Jp4zWHr3UW1fIa/H7dUBft\nCToALP/1aZPPKo0KR8qOIydmtP5Ye4IOAL+XnkQvrz7cC9sBXCbqp0+fxksvvYSSkhIIBAJs374d\nY8eORVRUFHJzc/HMM8/gkUe0kd8TJ05EXFwc4uLikJKSgtmzZ4NhGKxatcpVxXMpsbFxOHfuT/To\nEYHAwEAAwOjRY/H448tw5sxpTJo0BaGhofj4Y8sgQqJ9Cmou4Z0TH+HetDvRR5qgt0IB4GT5H0gP\nTUOgOAB/1RQgUdoLhbVFKKwt0qfZf/UQ/qw+j4ywAXq3JQDUyGvxbeF2JAcl4tOz/9Mf33zhW07l\n4kHrFq5oroSAJ9CWofqC3uo1prKlGgBMBJ0rjUqDSJWwCM0mG+W92CaY75z4UH/s7bEvQ65qtdph\nuVRXhCi/HlbzrJHX6v8+XKYdszVHYSTybPxVfQF/VV9AjbwOAWKDO75J0eSQmEzoOQ5KtQo/Xf7F\nruusNdBnq/6yK59WVSuSgxPhK/DB4bJj+uNsHQxn8VD/RXjjxL9YRbwzCeJFokptOk23srnKSmrX\nIWREEPIEaFJxq/MYSSSkomCcqDRMpbb23r54+HW7yvLx0f/hH8OetOsaR3GZqKempuLTTz+1en7w\n4MGs09WWL1/uqiJ1GlKpFJs3f2dyrEePCHzyicEllpc3AQAwb94CAEB8vCHwLj6+V7d1vXcGH55e\njxZVC3Zf2Y8+0gSTc18VfI+vCr7H5Ljx+PbidkzsmYO+wZY9ZHXbeJv5GPiha0fBwPTY1cYyTuXS\n5bXqwEsAgDHRw9GiZLfe3YlzJRWo4RVZPX+5vsSkU9Qeda0NDpeloPYi+gX31X/+q7oA/3fW/mmt\nEoEUCZIEu0XdmfjxAlBRY11QGDDQwDmjn96ML9Z9Wggmrf0OFBeCeVGoVF9x6Nry6hbwA0yPOfqc\n6iY/MN4NYBhAcbUnhD0ucb62VaFGc4UMgnBu725ztT8KK2ohCHeoqDZRu3aU2wS3DpQjCDYaFY0A\ngOPlp/DjJUt3KQC9dXTg6hEktI2HGqPSqHCq4gzkZmOyao0awWYRzWqjgBtbmDemxm5vd+blL/fB\nq98+m2l+u3bE5nljtl3a0X4iK5Q0XDWJS3BE0AHgWkEAPjl0DN6DHS5Kh9l/WutyFoQ5nofyehQ0\ncm8Io8/bTFdzJhlquQbeNlNxoyc/DRfKKiAIsf/a1oJ+4AezD1NoNAwYxrq4qeVe4IlNvTKK4j5Q\n12rjLRivBrtEHQAUlxNZRZ3XEgC1V63JsdLyFkDJPmzSURqbVO0nchLuH59PEGYIeIZpPl8XbmNN\n09Tm5qyW1+DN45bDHPWtDfjXyf/g+4s/mRxvUclNxoPtgUvQljvCiDoewCMRWEawA4CmlX02gS12\nFtnuYHBh74kyQOPa5k1ZZj3OAACgYbT/rKBux3hTN/lBUdILqmrbvQJFSQLU9cE272UPfxW2AirH\n7D1VZSRgTbjby5NNUI2+w97hMsvz7cKDqtZy2qGiRduGqBuMXAoaBpoOirqqWgbl9SjL+yk6z1In\nUSe6BftKDmLF3udRK68Dj2Xa2OCwdKSFpOijlJUa+4W5d2A81Bo1zl4pd6iM9S0tkLd2Xo9co3SO\no40RWw/M4oJYHoaqQnafparWfnNPw3S8DhtbOuaCVre0b/MqKyLbz8iGZcrmkVZWROj/lp8eDii8\n2u+c6MXcOaKuafGBRmV92mPrxWT936oqQ4ej5fhIm/mazKGXW84v17SyzDlXa8shFvLx6Kws9Auy\nPnPDKmrT30lk03D28oEHjYK7qKsb2TqyDDQtvixHO09qSdQJt0ShUmBrwQ+43lSOfaUHseHcJtS2\n1mPFvtVoYokOrqlVo/HP/hgVPgYAe6RuSnCS1fv18RqI4jKtdX+25aDVdLb4Yvc5LH51t0PXOkJ7\nVoWyMhzKa+yLghjDCDrmYWhsYKCxIjyaZj+o6qQdyr892BtXLao6xxaHURQnWj9XkgD5mSxomi0b\nb2M0Zpaz4rJpbIe6zrLDI2zRWqOKUqMho/Ys8LbzmX074Oc3Isy7B5JjbCxOozEIvrLSEECpadV2\nhOJ6sH8f3iIhWouS0Fpk+TtkyhMgYyyHyXTvFcNoOwWLBtwBmZjbcwr4DG4a1hOJkab1nBQTBB9x\nm7eP0SBXNg3eAm+suXUGHp2VySlvAFY7AObfOwAkyCJYUroGEnXCLdlauB0/FO3Es7/9Exv+3NRu\n+jMF9ThdWIW3vzhnNU2wl3VxObEnBI1N3MbOrcJTg9X8chFB3u0tZsFAo+SwIpmRNalRGxqk5t/b\n37tAdx9b1qTicl+Tz7asQK4Yu01bC/uZ5m/0FbT+mYnmw7kO3MD689w/9BaoG6QWFqAFGga690Gj\nEEJZ1hO+PH8MCOkPxdWeaC1Is7jk7vw0vDXmJSivGDoVbCJheh8eJgyJwaKpDlixRviUD8SLw5/G\nP+4ahdRYG6Ku5mEwZmKwaCKWTxxvdEJbTqGAve56BcYiyScdqrKeJsfnp8zBmzMX4ubhlms83D9V\nW0d/yzPUxz1pt3F6HqGAj5tHxiNCahq1FxscDJ2zTyziY1q/YXhl5LMI8pJCwLP8TjVqBsFMlKmr\nHrD+zrO8OzN6zeRUZmdAok64Jacrz9p3Qdt4nS0RO/ZnLetxZVkMoOFDY/ZjbL3Q374y8FQA08GO\ngR2EB3CwgNUcBNS4zMbpVdyWKIUGNq1JTZO/iYC1nBgF+VnHItgYMGg5PhLyM0MM+Vt4LAxlefRv\nGcjs60A4s416699Lhjk5veEjFqD1YgpU9YFW0/J0r5RG2/GZ1WMhFqTdjhmJN+HvMw1WYV7sGAyP\nyEJaSDIYhsGto41mdZiJR0JATzQfMoipRsNgxmj2Zaun95psccy3JhWzou62OK5QMJC0rckg8zG8\nW0+Oesgk3UO3DMRdYzNw1/DRSIoOxuzEmzE+Ml9/Xshnl5U7UmbhgZv7YdHUFPB52u8osDUBg8IG\ngGEYCBjLOo8M8cdHj4/F0FTDdxglicDNvSax3sMYvXDzTeM60iOSIFBrvSx8pY/JObYytBwZj8nh\nsxDfw+x7Zvmt942VYliKqVWuuJwIqW/nrbBJou4iuG69quP48aOoru78uZzuSqtKuziP+fQya+jF\n3IZLutJyvREAQHJ0WwCOWeOpsTNYiOGpIE5zXsS7RsWHusXH6nmJyOD+1Vmn5mPBGg6izvAMjZPx\nMw/oZcd4uBXLtm+s1LIcal6Hgtg0rT4wFm4hTL9z4zdmxIBI3HsTNwvW2Euxcm6WjZRATkY0JgyJ\ngao8GsrSBNY0k4fGYXiazj2tzdvXS/ue5mZE6+sGAGIlUbgtabp+Cd8JWTF4d9ko+HkLrXSYjI7Z\nqEtzQQOAl2+5AyP7WA4vBPkZ3h2Zt+G77x1s6hYX8kw7eyMih2JK4ljcPakvbs+1vsCKt8ALYhEf\nmX3D4CXSPmeo1HBP83y1x9h/g3wW8bWGcR4B8gQwDIPgpgFQlMbBrzLdJC2bpQ4AIgEfIr7ZOZ5l\n7Ie3WKhfBliHRs2HWNRx7xSPRiaPAAAgAElEQVRXSNRdgG7rVXv47rtvSNSN0AW6cZ3fqhOjZTMG\nIqBiCGsadUMgFJcToWk1FYFekW3jrubCxFHUW062bcwjaAWvg0FnxvB4gMiKK1Oj4sFHaAgs8rs0\nHvf3vxvyk6P0HYHoUD+M7GcZiWsB3yiozEh8U+O5jUczAPpEsVur/RLa1tnXmIpQalwwa3pjBE2W\nY6fG78OUqOlQlCRgwSRT9zsDBg9O74d7p2g3h7K2Hr85PCOhEHHYSEXv5rfScWIYBmqYWnM+Xtze\nKYZhIBbxER7kYyHqGgCr7jJ4OqZmx1vNR2xlLwM2cjMM0fwyb8P3IxaY/l7YxBcAsvv1wLhBUZx+\nszpRD5IY3mG278mayNqzsYpJ2rahpqQIGZRXEpHYw/Qds7YvQmp8kMU9jTvD+mNsZVPz9M/bGZCo\nu4BXX30Jx48fxUcfvY8nn3wUS5YsxgMPLMSFC9q5puvX/wcLFtyJe++dh//7v49w+PBv2LPnF6xZ\n8xyuXev65RS7mutN5ahvZwETVV0QFMWGMbiMXhGYNbYXUuODcWvWQPaL1Dwor8VB3Wg6NibiCXHL\nyHjLHjZHUb87T3s/a1HkrRdTWI+3x/TU8ZD4WBEXDd+ksdXIvZAcnIi7JhiCkHoE+yDF1thoGwKZ\nYfUvY6tTLOTWEC0ek4cMG0Faz87PRD8jER+RFolbRljf5VCf77AprMdfvHcInrozA+P7ZOG9uQuR\nkWT6jHweDwN7y5CVbF/gmLfQUNciXvtR0HpNb/aFj8AyWp4HBj18tWVQ1WutcvPx5oww7cY9URL2\nSPr7b+mHqcPMRVuD2HCDOzdYYj1SX8wX6WeEmLNqyN/xQH/DZjQ+YsMzC/lCPDLoPqwa8qiFSOme\nyRpskj6sh/lwi6WAq1jWgxAw1ix1Q5luS7wFkUYrHuos85l9pmnvZJQ2OEDbyZk8rCcWT0u12G2T\nzf0+bUQcBHweeDwzueSpEMb0QqiPsUeLQXyEmatdzef8W3IGHr/4zOYL3+LY9VOc0/N5DFTtTCAd\nGNoPt7CMVenQbb3K4/GQlTUMN900DRcvFmLdulfw+uvv4PPP1+Orr34An8/HV19twuDBQ9CrVx8s\nW/YowsNdsJxRN+PD05+1n0gpREBrApqg7ShNG5Ks3xQkJtQfKLC8JDY0EJcuKyGViFFndFzIEyJ3\nWE/Iz8dgZ7HRQhUcRT3ARzsFiC8xLM/JawyB2rdCm015NBBn32YWLw1fhZ4RYdh5wfpa88aN7Zh0\nrUU+sn8Evq8RoV7VBB7DQGTFqmKD0fAwrX8mvm/QLpOZGhcEtDO7ry9vJPrLUnBIddRqmuhQP/RP\nkOEv7Qq1kAV4c9opzlfIPvQQKjUc11l381LmYGvhdlQ0V7JOeeSCsVUoNHe1sqEz1ZVivDj8aRwu\nO2ayvDDDMBgdlQ2J0A8Vl/1xvKUWskBTAb4zeTZm9JkKPyF7JH2Arwg3ZcfjR6M1lszFz1ZdCnlC\nPJy+GAeuHsF6o7IBQKiPDKFG+yTwzcQ7PqCnRX4zek+12GGwPV4fvcaqG90YtcbSnW3tOt2CUlnh\ngzA8cgj6haToN+IJ9w3DYxkP6d8N4/dBKtF2XHg8BoOTLDu8bJ6BCVnaGSSDwwbiTKUhEFfT4ou0\ngByMGRiCFftWA2iz1HlmnhU1D2KRAM2NnbO6pMeLeldy6tRJ1NRUY/t27frecrl2mtXo0eOwdOl9\nyM3NR15evq0sbkiULD9uCxTeeOHukVjyyw8AgECj9cKtuewWTk5ByVU19jVdQF214bi8bSMW8+si\ngwJgZRjeBAnbuKfZ/OT7+y3ApoKvca3pusX1AoYPhVptstqWn8gXDMOAZ0OfeEbWTn6WwXXqLRKg\nvs1pYG1jETa8hGKMz4jH979oPwf4mbpuGTCI8uthskOYzM/S7f7s0Mfw7G//hFqj1lu8Qr5BeNIS\ngsFnDMuntpzKhjhlPxieaZ15W9krm42MsAHwFfjgrRP/xsioYe2m13WIjFcL9BKI9Wu/cxmzNS4t\nm7Ay4EHAEyCrxyCgBzCJZZiex/CsCrp5WXW0mE3XNBdj03P8trK0DxeXdlaPQRxyMoWLoAOGTpy3\nwBtPD1mOWnm91f3ke/iG4YXhT+nrLkAsQXxALApri6DWqE1c+cZxOe2tDsn2Peq8K5nh6RDzRfrd\nClsvpgJh5u59lprW8CCwc/vvjuDxon5Lr8k2rWpznLltqFAowMMP/x2pqaZTV5YvfwJFRZewc+dP\nePDBe/H++5845X7dmd/LjuNcdQFuS7wFPhwa81mZWSYi7GV0jTWXnb+3N8ITfbD7d9NOg25Ou7mo\nr5ybiWW/ftNuWaJD/cAXaGDeXPxzxDO4dK0BkZkBCPATg8efyrq6XaRfBEobyqDQsMwXt2F1Gjcm\nxtaI8ZimQm3fboACngAZYQMQI7Eci9dAg+UZD6BR0ay3ivx9LMdsQ7yD8WjGg/jlyj4M6ZEBQBto\npCNS5ovKFoPVommWoOXYGHgP2mmSjxefu6gDQN/gPlg9bAUCxQE20w3tMRi39r4Jf9/zDADtNqQM\nAwyUpemXpbXWMTShnaFjrmP59mK5KYz1++iGlNJCkhHsFYTJ8XlW03IRdW71YqiY9r4LY+L8YzE3\naQb6SBPgL5LAX2Q7Ytz8fIBI27E33qQJAGL9o/V/R/jZ9oSyud+N8TXugLXNDjHuVDEA1GYvxvKZ\ng1z2LrBBY+ouQLf1anJyKn799RcAwMWLhfj88/VoaGjAxx9/gNjYnpg3bwEkkgA0NTWybtd6I/HR\nHxuwr/QgalvrWCN2jVmUdhfGJGgthmCvIIutVq25I3UNkvkysLoxQqFZZ4BLsBSgbbxDfYLNjgE+\nQh8kR4fqLV5rDSLDMLAj7keLxnSs0BpRftqx2kgbu6yZZAqtK3tcDPvqYAKeAAFiQ2Ma3bavs8Zs\nw4poSST+1nemvg6N65LP45lYwvER/oDK0qPgZUeQlw6pV2C7Dai3wAteAi+kh2o729kRmViUNs9k\ndzgBw8cdfWchwtdUBNJCDPERMWHaZx/UR/v+hXibvgOODgO0h/niS7YC03TeDh+hD54b9jgyw9Ot\npuXinWhP9Mz5e8YDnNMyDIOhEYMt9l7gCpv3BQD6SBOwdOAi3J40A7mxY2zmwW+n02IRLMcwJr9D\nBozFb8FL6Jr15K1Bou4CdFuv1tRUo6SkGPfddw9eemk1BgxIh5+fH2pqqrFgwR146KFFSElJhb9/\nAAYMSMeTTz6GwkKWweAbCIVKyRp0ZEy/EMMylc8OfQxPZZnu7GcsnrMTb7Y4rousV9WEYJBwsr6h\nMw6Umxw33q7e9T39/tZuGmuNJgPThojLND4ew+ckGgFiCd4c8yKmxBuGebLC2V2ojmwkJeBza+QF\nAtN0fKOgo6Uz+mPpDMs1AThZhR1gbtIMPDLofv37ZPz98Hl8ZPUYhCkJpsNjdyTP0v/dv1cwHpsz\nEPfcpL2+V2Ac7utvmP/NdTqmvYT7mI0Fs3xxc5KmY1rCRIS3E9RmDN88EMyIF4Y/hZWZyzj9JnSd\njISAOLss9Y6i6wSyuex7S+MxLGJwu0MB5p2W5GDTqX89/aMxNnoE5Ge0YykMLIc/oiSmHWgfgfVp\nqa7A493vXQHb1qvGPPzwoxbH5s9fiPnzF7qyWN2CZ357ya70rNNgjH6YUX6GhSB0vWydSzo9oQfm\n9zdYpMYiMjq6/XFZQBvoBFhGBLO1j+bR9Toi/MJRVG/Y5pKLG1Tq68V5Wo95Outj1ZbiMLPPNPzv\nr6+s5q1r0HRuzSSp5apgACDxMrVWjAXUz1uItIRg5DPjsOfKAZP94l2BTmyFfKHJ3u/GHh5dnfHM\nGnnjumQYBokxpgsApRiJgCtcruE+obh/gOnCMebuXkC7QI09gg7Yfu+4uMO7mklx49HQ2oibEhyP\nUzL+zh5OX4xos1kJPIaH6b1vguLyefx4uBjJcZZT3WIkUXgq6xE8f3AtANPpgZ0BiTrhcRj/MNkC\nxZRtY27mbjFjUddtwLAycxm+PP8NzlVfsMjn7xkPoKd/jNE1hv2xjRfV0GHNUr+l12TsLz2s/8x1\nbJPnoCVoTWzY3LijoobZFHWd6zFaEokVmQ+bLFpijPmQCFtw103x4yHkCbG18Aer93MKVqqNrUzm\nx+ypc0e/H1uMjs7mZP1yGZoxx56531zoxGFkAFqv1MK0O52Wn7WpgAAwa2wvTBwSC39fkamXre2h\nw33DsHzQ/fAR+nTqeDpA7neimzA3aQZSg/vi/v53t5/YCLbxeZ2lbm45mwaeGSzQuX1nmKSbljAR\ngeIARPiautkeHfyg/m+2RWOsWepeAi8TQbUVzaxPw+NbbbjZ3L7RbYFv2RGZVt3Cjqxab1zWSL8e\nVuMQzAXD3ALWYa2OnIm15+cypmyP8DkirI7c33wMF3DM9W/PKm03OgzDwN+3bXqcle85LiDWIt6n\nMyBRJ7oFYoEYi/vPsxjjavc6G5a6+ZittWjyIC+p3s0OALmxo/GP7JUWAhYjiULfIO0ymWwCybcS\nlW8OF+HgM3yr6dgs7gCxBK+N+gduS5xuPVMrg+qpNna3c3QIwFowY1cKC1uZzAXTHqvLFRYaW2eI\nzf3uiKg7y1LXvX+uiilwZ9zhmUnUiS6jvKkSmy98i6uNZe2mdbTBYbPUNW3uMluibv7j5Ppj1aVj\ns55sBSKZpOMgbBKRn93R1SK+0KbQWLPUk4Ksr+fN9Xsx9z5Y80aYz0xwBdYtdcsymQumPY22K9zv\nxmXUxS9EGI2dDwrVBhwaR/I7kndH0E2HZJsWqUM3J918CdruD4k6cQPz0+Vf8PPlX7G6LaDEFo42\nOGzRrov7z0ecfwxyYkaZHGdzv+vgbHW1JWOzlo3nzz839HEAwNT4CQBMA+3GRA+3mn2odwgGh6Vj\nTtJ08Bz8+erK5mXR4WGXdVvCzVXUGZi737Wf4/xN93tvNZtXPzjMdMnfCT25bgdrSv+Q9pfqZetM\nacymR9lnqTu/eTWeznZv2l14YvBSk3nY81Lm4I3RL3CejmmMsyz1m+LzMS9lDibHj7ea5u7U2zE4\nLB0TezqwLa4b09lxBGxQoBzRZajaWTnusYyH8NKRNwA43uCwNcK9AuOwnGX+rMkiEkzHLHU2gTS2\n1IO9g/DWmJf093lgwD04dv0UMsIG6Le/ZCNA7I+7Uma3ldG5omHNUrflEeDufrfMY93oNRZCqmjb\nnU+X753Js3G47BgA7suNsrEw7U7cv1M768SaMLO63x2KNNDiTEvdW+CNZmUzauWGBY5FfCGiJKbb\nfDIM04EhDOeUV8QX6te0t0aoj0z/Hrsbd/SdhVY1y0JQHHAH9zuJOtGpFNRcQqRfODRg/wH09u6H\n883atfpj/A3uu45YEXenzoWknaU427sHVwtN735nzd+0sTXOM1AcYNNCN89fm5+DDYi+cGbXWxlT\nd4YFx3UHLp2lrlte1vg6RwWdK2xiyGVjF2s4c0x9WfpibDq/FWOjRzgtT4IdR5bCdSdI1IlOo6Dm\nEl49+g4A7VzyUG/LebTJPaJwvtByAx573e/9QpL1Y/W6lcPaw1pENsDd6tK142xj6mK+CMMjhyDe\nzOXsKB21ChgGWDpwEV4/9i8ANix1G27+9tbS1sFWH2zoot8DHRgT7ihsot5bGo/hEVnYW3rQ7vyc\nabVF+IXjwYELnJYf4RrIUiduKK4ZBcQpNSqUNpVapNFtY9hflmpy3JbgsrEo7S7OQqLDVseBu9Wl\ns9TZ731b4i12lYmlIPo/HbWgjcvWWxqPvNgx+LFol9Uy27qPmmMdc91YJi9mDOrk9Q6PnXPBWsPL\n5vngMTxMTZjgmKi7wwArB3TrKziyLC/hfpCoE52GbgcsW/SXpeKBAfcgIcB04QdHXM32Nqo23e8c\ne+CuiHg2LYfRvRwUDYMMM23/tZ2P7UA5bmXwFfrg3n53IszX9v7ufiJf3JVym8mxRzMeRKvKvo1p\nbGGtxMK2bWpDzRbQcUXAmzuxOnsFypsq290tjuCAG/TjSNSJTqNaXtNuGoZh9HO9jeFqEXYEZ4yp\n6yxpe70EXDEWYGtiEx/QE+XNlRw3cTG0Q9bKzFYvDw1YiNOVZy02PLFFmqz9CHQ2jKO7nYKNQLmX\nhq+C2Mxiddwj0j0IFAd06hrtngy534kbClXb+KtGzUBxuS9EPc9wvpbr2G1HsOl+5xz9rqUjUdNc\nsSY2M/tMQ0pwEvpzFdF2Oixs90kM6oXEoF7c8u9G+IksrVV3aKgJ90Y3hOEObwqJOuFSiuqKsf7s\nFwhUxuFC+XXAH5CfGgEI7HOnusryNcYZ87ED2iweqVegU8pkjrHHwJqr30sgxqAwy13PDOhW/ILJ\n/x0ZU++O2NvwOjrM4Q4NPNHZdP23TqJOuJSvCrahtPEaSjTXoGak4ANaTVEbhGJw2ED9XGRrqOF6\nS91WMB5X9/tN8XkQ80UYHdX+9LSO0lGxZSxk3dp9ur6hci7Oi7WwRXdxvxPOwx1+Kp7VBSfcjtKG\nqwC0LztfUm04oTIIqK15obptC6WdMObnDPe7t8AbUxMmIEDs+m0qHQ3gMnd6tPdk9s48cHfsbXfJ\n/U5wp+vfFRJ1wmWo1Co0KBqhaTUNPAoO8MYLCwyWrK150H/PeBAPpy+2e29oR7C9clrX/1gBJy0+\no7Mh9Yb6jWap20d3mZpGdD3u8KaQqBMuY1vhLwAAdYuPyfFlMwcgwMdwzJZo+Ap9bO5r7EycMaWt\nM3FWmdq11D2tmSCRJlyFG7xbNKZOOJ3CqiK8feBzFDdfAgAwAoU+OhQAxEK+yZKfbMuFdgW2x9Td\nQ9iMN35xnqjbzscN2imn4mGPQ7gR7tD5d4/WlPAoXt7zHqpaDOPnvSVJuMacQaOySX/M2CqO9Y9G\nRtiAdjeBcDXOGFN3FanBfZEa0hdZ4en6Yx1d+p1roJyn0dXfJeF5MAwDjYamtBEewMnyP6DUqLC/\n9BCuNJRCyBOiqrlGrxMh/Cjcnz0NLx65pBd13Rjl0oGL4CP0Bo/hYV7KnK56BD1OWXzGRXgJxBgR\nOcTsqKMryplGyiUE9gQADOmR4VB+3Q93aHoJwjWQqBMOo1Kr8N6pTyxPGLWZQ2NTIRaIEOcfi+tN\nFSbJekvjXVxC+3DHMXVX3lX3TH2kCVg15FGEeAe58G7dH6nYNWsPEJ5E13cYSdQJzpQ2XEOYjwx/\nVP6Jbwp/wMiIYSbnVbVBYLyawBO36I+J2zbyiJFE4eC13wG4r/vTlvu9qyLAbc11drhELAv56DbS\ncfKd3BJHvsrXR6+xf13/TlgwiXAv3CH+hESd4MTpirN49+THGBczEj9f/hUAsPH8Fv15jVKI1nOD\nERXqh4T0chyq0qZRqpUAzN3XbvDms+COlrptOlgmd3ykTsH+B3f1Xu6Ep9D1Pyp6UwmrlDRcRauq\nFd4Cb/xSeBQA9IJujqK4D3y9hHjwljQk9w7F0cKB+O7ij8iOyAJg+qq7Q2+WDWesKOeJeNqTe9rz\nEF2PrtPvDu8WiTrBSmnDNaw59Jr+s6ZVDMbKltixgn64//bZ8PUS6o9FSyKxKG2eUSqj3cXc4tW3\nxJ2j350JOYUJwjW4QztBok5ApVbhoz8+g1zVioX97oCIL8KLh9eZpGFEctZr1XIvzBs81UTQ2egO\nhq4ta7yrLHXX3FW3oQvX3LvBl2cH7tDwEh6KG7xaLhX1NWvW4MSJE2AYBitWrEBaWpr+3I4dO/Du\nu+9CJBJh0qRJmDt3Lg4ePIglS5agd+/eAIA+ffrgqaeecmURPRrdzmbGgtSsbAGP4aFV1Yp9pQeh\nUYjxbfE3+vOP/PgSmOt9oIpWcbqH/MQohORzWefc/S11d9yNzGagXAc7GlyvDvOVAQBSgpM6dD+3\nwT1fP8IDcIe2zWWifujQIRQVFWHjxo0oKCjAihUrsHHjRgCAWq3G888/jy1btiAwMBALFixATk4O\nACAzMxNvvPGGq4plE4VKgbqWeijUSgh5AqjUKqihgYDhmzSgTYomiPgiNCtbUNVSjdKGaxgYmobr\nzeUobbiGEO9gBIj8EegVgIbWBpyrvoAAsT8i/Xrgct0VKDUqCBg+egXG4eC1o2hQNCItJAWRfuGQ\nq1ohYPgoabwKHnj6LTwlIj+oNWpcbSxDjbwWidJe4DN8FNReQoh3EBQqJYobShDuE4ojZcexvWgn\neOCB0QiQHZaNML8Q/HBlG+pbGxDh2wOljVctnl+jFEAtrgeitVHqGoUIjLAVALAs/T6cqTqHHy79\nrE+fGpiKSfMyOYkLY/WDezEnaTpCvIItjrvDj9VZ2BuU7S+S4J8jnoGXwMs1BepkPOm7JNwDd3qj\nXCbqBw4c0At1QkICamtr0dDQAD8/P1RXV8Pf3x9BQdp5sUOGDMH+/fsRGRnpquJw4r/nNuunXdnL\n+j+/sDjmxfdCi6qFJbUl31/8yaH7Atq1udm2JlVDDTCt+PX6LuC64TiboAOA/NxgMDwVBBEFAADF\nxVR49duHMVEjkRDYE3EBMcgMG4j3Tn2CsqZyiEV8xIRx242M6QaWOgB9YF93QMS3PeRhDamXdse7\nMJ9Qztf4CH3aT0QA0M5nr5bXwF/s39VFIToZd2jbXCbqFRUVSElJ0X8OCgpCeXk5/Pz8EBQUhMbG\nRly6dAmRkZE4ePAgMjMzERkZiQsXLmDRokWora3FAw88gOzsbFcV0YIMWTquVNegRF7AKb1A5QOF\nRgFGoGA9z1XQO4q1vcZVVWFQN/pD0OMSaxlbzw8E49UAYfR5AMDwPr1w+9hkvLrxOP66UosVcweh\nV9QkfXoew0OYL3chMIFh/ZPoANF+kZjYMwcpIfa5xXNiRkHACDAk4kZZQa5zWZ5xP85W/oXkoD5d\nXRSis2AYt4lA7bRAOY2Rz49hGLz44otYsWIFJBIJoqKiAAA9e/bEAw88gAkTJqC4uBh33HEHfvzx\nR4hEVsKuAUilPhAInLPfs6A0HBf29IYwrgUCWYnJOfnZweAHlUEQdll/rOlKDDRyH4j7HOV8D3Wz\nD3jeTe0nbKP52Gh4D/zF8PlQHgAeBNF/Qtjjkv64RiGC/I+h8BqwGwDQcmIENHJf/H3uIKz9+keI\n+x42yTfZfyCWPHQHzlwpwbpTrwAAHp2rXUzm+cXZOH+5Bv37yFjLxOdrx57FYgFkMnZL3fy4f723\n/u+QEAl8Rd3L8msW1un/tvbMrkDQVtdeYiHrfe8Kne5QvreHT+lQuboT5vXm5+fl0u9QBgl6t7Vp\nnkJnvvPdEZ2h4uMj4twmugqXiXpoaCgqKgzLgl6/fh0ymUEkMjMzsWHDBgDA2rVrERkZibCwMEyc\nOBEAEBMTg5CQEJSVlSE6OtrqfaqruQtke1RWNwIA1A0BgJmoAwwUl5OguNIb3oPaxpUVYiSES3GF\nQ95CZQAUglp4a6SQw3aZpXUDERqugbevCujTExev5ELSowqDg4ZAmC9ASXkjGoMrcbzmkv4aEU+E\nfy7OxZZLjRAppfhBru3o9I0KwNLpg/DuGa2oJ0qSca7+DLJj+0EpVyAhWDt+LOQJUF5er88vQupl\n8tkYlUrrGZDLlaxpZDKJxfH6ekP0fGVlA5oE3ALx3IXqBsN3Zq1enI1MJoGyra5b5IpOu68nwfYu\nNjbKqS7tgK0OCVN0JmtzM/vv1Nl1aKuD4DJRz87OxptvvonZs2fjjz/+QGhoKPz8/PTn77nnHrz0\n0kvw9vbGrl27MG/ePHzzzTcoLy/H3XffjfLyclRWViIsLMzGXZxM2zejKo+GXCmCuPdx/al+ccGo\nvuaL/r1CsEOpFfVFN/VHgLcvXjv6M1tuJqwevRSljddwsbYI3xSadxhMyRkUg9HRbcMO/QAg2SLN\n7isVOF5jsL5D/H3h6y3C3L4z0SxX4ofvDIvEyCRG9T5gFsqayhEXEAMA4PP4eDprucvHTLvDinLE\njYE7jHsSnoVhv8Ouf7dcJurp6elISUnB7NmzwTAMVq1ahc2bN0MikSA3NxczZ87E/PnzwTAMFi5c\niKCgIIwdOxbLly/Hzz//DIVCgWeeecam691V5GfGIjluAN69aBD1KdnxiAuIBQAklN+J/VcPIS00\nESVWgs7M8RP5oo8oAcX17II+InIo9pQcAMBtatWIyCEQ8PjYfmkXKluqTPYk9xYLMDevD0ICtNHK\nYoHYcE7gpRd0HQ6Pk9sBSTpBEITrcemY+vLly00+JyUZAnry8vKQl5dnct7Pzw//+te/XFkkm+i2\npAwP9kFqXDBw0XDOWGjTZClIk2mDAIU8QwRyuE8orjUZhZmzILCyhrTxhiF8XvuizmN4yI7Iwm9X\nf9eKOmOa79h0w5iemG8QdWcsohLsHYSypnIE2BHdy5CsE24CvX2EJ+N+q224KdasZ4HReuG3953R\nbj4CHntQH8/oq7C1Brk5orZOhfke2cbodkpzFnOTZmJ87FhMjMt16PobeR11wg2g949wEbba4c6C\nlok1wtaiHFZF3cjy5rI9p7Flb4yx0Nlag9zy/toOgKptNzQ2nL1SWoBYgikJ+XZdY/x83bFJ9TIa\nwiC6N+4w7kl4Gu7zTpGos8D29VgXdYNIh/loo/uFPAEUVkTWWj7Gx+0RYX5bp0KpsR1NHuEbbpe7\n3LW4zw+AK0FeUsxLvg1Rkq5dIIkgCMIWJOocsSa0QiN3urfAG+tGr8HJijP48PR61vTW5MxRUde5\n/1Vq26K+IvNhznm6AtMV5bonGeEDu7oIBEG4Me7gfqcxdTZYVIdnparMA98EPIGFKGeEDWC9tldg\nnFH+xu537mPq/LZORXuWOsMwXTqWbbr2e3eVdcITIPc74Wzc6Y0iUeeItfFytmh24zHx4RFZmJcy\nh/XapQMX6f9mjK6xZ0ydz9FS73K6+Zg64UHQC0i4iq431EnUjXEkUI7tuPExoY1NN4wtZ57J3/aM\nqbeJejuWeldjOqGNWot85WcAACAASURBVFWi66D3j3A6buR9JFFnge1Hb4/QGqc1nz/O5RpHxtSV\n7m6pU0NKEAThcihQzghbQQ62hPaBAffAV2BYZtXYfW4+L10XPT1AlmpynOngmLpKY31KmztgMqXN\njXq1xI0HvX2EJ0OizgKb5tgS9b5mWywaLx7jLfA2ORfmI8M/slfCX2S6IL+JqHNYUU7H6KhsHL9+\nGrMSb+Z8TVdALk/CfaB3kXAN7hD9TqJujANj6u2lDWdZVz1QHMD5+vYI8pLiuWGPc07fVVAzSrgL\n5CginI07vVI0pm6DuUmGZV/tCl4zShvmY/9mKc5eAc4tMIl+d6efAEEQhOfggerhOOaGenpYf/3f\njlrqEpGfjZTs2DOm3l0wiX4nU4noUuj9IzwXEnUWdJpjvCAMz46GwFjURVbWeud6vedADSnhHtCb\nSHgynqgeTsPh9diN0jpilXpio+OJz0R0T2j4h3A27vROkaizoPuCHJ2G5ZmWdscglzvhNtCrSDgd\n7UvlDtHvpD5GaMyWlHNUnO3ZD50gCIIgnAWJOhsd7Mnbs3b7jYI7uae6E1RrzofeRcKTIfUxoqsd\nJ7r92P0ciJh3d8j97hhd/U56JvQuEi7CDX6wtPgMCx39yas1aoeue3zwEtS11sNP6NvBErgj1JAS\n7oIbtLyER+FONguJujFO+q0HeUmRFT4IqSF97bi1BiK+CCHewc4phJvhRu88QRCEx0KizkYHFYhh\nGNyRPMs5ZfEQaByTIAjC9dCYOtE5kKY7BFWbK6BaJTwXEnUjaKTNdZCl7hj0TroCqlXCNdA8dTeF\nBIggCILgjm7xma6HxtSN0Vh+JSszl4HnTqGN3RTqKBEE4am4U+tGos6CsYZH+IV3XUE8COoXEQRB\nuB5yvxvhDq4Tz4VU3RGo1lwB1SrhKrpeRUjUu5iBsn4AgGhJZBeXxLWQ+90xur6J8ESoVgnn4k7t\nG7nfjWAZUnc5dybPRm7jaMRIojr/5p0ILRNLEAThekjUWehMARLyhYj1j+60+xEEQRCeC7nfiU7B\nndxTBEEQngqJOgskP86HvO+OQdVGEN2HrhjCNYdE3QiNO3wjHgvJkyPQG0kQ3QA3at5I1IlOwY3e\neYIgCBfR9d1wEnUjuv7r8GRI1gmC8EzcKWaIRJ0FGv91PlSnhPtALyPhGtzBMCRRJzoFd+rJdieo\n1lyBOzS9BOEaSNSNod864WbQK0kQhD2QqLNC9pGzoRXlCIIgXA+JuhFkFbkOcr8TBEG4HpeK+po1\nazBr1izMnj0bJ0+eNDm3Y8cOTJ8+HbfddhvWr1/P6ZrOgoxKV0CVShCEZ6NxA9PQZWu/Hzp0CEVF\nRdi4cSMKCgqwYsUKbNy4EQCgVqvx/PPPY8uWLQgMDMSCBQuQk5ODy5cvW72mU6DFZ1wGSbpjUL0R\nhPvjTp5Il4n6gQMHkJOTAwBISEhAbW0tGhoa4Ofnh+rqavj7+yMoKAgAMGTIEOzfvx/FxcVWr+lM\n3Ofr8RxoTJ0gCML1uMz9XlFRAalUqv8cFBSE8vJy/d+NjY24dOkSFAoFDh48iIqKCpvXdAZkpxME\nQRDdmU7betV4XXWGYfDiiy9ixYoVkEgkiIpi30ucy1rsUqkPBAK+U8ro5ycGAAQEeEMmkzglzxsV\n8/prFtZZPUdYh8fX9ru9xEKqNwcxrzeJxIvq0k6ovmzD42k9kV5e1n+nnVWHLhP10NBQVFRU6D9f\nv34dMplM/zkzMxMbNmwAAKxduxaRkZGQy+U2r2GjurrJaWWur5cDAGrrmlFeXu+0fG80ZDKJRf1V\nNxi+J6pbbshkEqhUagBAi1xB9eYAbO9ifX0L1aUdsNUhYYq6zQBtbm5lrStn16GtDoLL3O/Z2dnY\nvn07AOCPP/5AaGioydj4Pffcg8rKSjQ1NWHXrl0YOnRou9d0Fu4U9OAp0Ji6Y1CtEYT7406a4TJL\nPT09HSkpKZg9ezYYhsGqVauwefNmSCQS5ObmYubMmZg/fz4YhsHChQsRFBSEoKAgi2sIz8B9XnmC\nIAjPxaVj6suXLzf5nJSUpP87Ly8PeXl57V7TJZACOR136skSBEF4KrSinBHusHCAx0Lud4egN5Ig\nuhNd/4slUWeB5Mf5UJ0SBOGpuFP7RqJuTNd3sjwYd3rtuw9UawRB2AOJOgvkKXY+NKZOEAThekjU\niU6BOkoEQRCuh0TdCPK+uxJSdUegd5IgugPa9s0d9gQjUWeFBMjZUI0SBOGpGBbX6npVJ1E3gsta\n84SjkKw7AtUaQRD2QKLOAo3/Oh+qU4IgCNdDok50ChT9ThCEp+MOvl4SdRZIfpwPbejiGO7QSBAE\n0X3gJOo3yljzDfKYBEEQhBOJC4gFAIT7hnZxSThu6DJmzBhMnToVt956K6Kjo11dpq6HjEqnQ+53\nx6BaIwj35/akW9E/JAXpoWldXRRulvoXX3wBmUyGFStWYN68edi6dStaW1tdXbZOhwx1V0LyRBCE\nZ+It8MLg8IHg8/hdXRRuoi6TyTB37lx8+umneOaZZ/Df//4XI0aMwGuvvQa5XO7qMnY6ZFU6HxpS\nJwiCcD2cA+UOHz6MJ554AgsWLEB6ejo2bNgAf39/LFmyxJXl61xoUN1lUEfJMeiNJAjCHjiNqefm\n5iIyMhIzZ87Ec889B6FQCABISEjAjh07XFrALoH0hyAIguiGcBL1f//739BoNOjZsycA4MyZM0hO\nTgYAbNiwwWWF62zIKnIdZKk7BtUaQRD2wMn9vnnzZrz33nv6z++//z5eeeUVAJ45/9jznsgNoEol\nCIJwOZxE/eDBg3jhhRf0n19//XX8/vvvLisU4XmQpU4QBOF6OIm6QqEwmcLW2NgIpVLpskJ1GeR/\ndxkk6o5BryRBEPbAaUx99uzZmDhxIlJTU6FWq3Hq1Ck88MADri5bl0Hy43w8cJSGIAjC7eAk6jNm\nzEB2djZOnToFhmHwxBNPwM/Pz9Vl63TIKnIlpOqOQLVGEIQ9cJ6n3tTUhKCgIEilUhQWFmLmzJmu\nLFfXQmal06EaJQiCcD2cLPXVq1dj3759qKioQExMDIqLizF//nxXl63TuVE2rukaSNYJgiBcDSdL\n/dSpU9i2bRuSkpKwadMmfPTRR2hubnZ12boMkh/n44lTHwmCINwNTqIuEokAaKPgNRoNUlNTcfTo\nUZcWjPAsSNIJgiBcDyf3e1xcHD777DNkZGRg3rx5iIuLQ319vavL1mWQUUm4CzQgRBCEPXAS9Wef\nfRa1tbXw9/fHd999h8rKStx7772uLlunQ0PqBEEQRHeGk6ivWbMGK1euBADcdNNNLi0QQRAGyGlE\nEIQ9cBpT5/P5OHDgAORyOdRqtf6fp0GGuisheSLcBXoXCc+Fk6X+xRdf4JNPPjGZ8sUwDM6ePeuy\ngnUlFKntfER8IYb0yEB8QGxXF4W4QXlwwAL8XPwrMsL6d3VRCMJlcBL1G2fzFrLVXcnf+nrwgkUu\ngt5I55EU1BtJQb27uhgE4VI4ifq6detYjy9ZssSphSEIgiAIwnE4j6nr/qnVahw8eNAjp7RR9Dvh\nbtBAEEEQ9sDJUjffkU2lUuHBBx90SYHcARpSJwiCILojnDd0MUapVOLy5cvOLgtBEARBEB2Ak6U+\natQok4jw2tpa3HzzzS4rFEEQWmhEiCAIe+Ak6hs2bND/zTAM/Pz84O/v77JCdTUMjWQSBEEQ3RBO\n7vfm5mZ8/vnniIyMREREBF544QWcP3/e1WXrdChQjnA3qHtJEIQ9cBL1Z599FqNGjdJ/nj59Op57\n7jmXFarLoZaUIAiC6IZwcr+rVCpkZGToP2dkZJisLmeNNWvW4MSJE2AYBitWrEBaWpr+3GeffYZv\nvvkGPB4PqampWLlyJTZv3ox169YhJiYGADBs2DAsXrzY3mdyGA2NYBIEQRDdGE6iLpFIsGHDBmRl\nZUGtVmPPnj3w9fW1ec2hQ4dQVFSEjRs3oqCgACtWrMDGjRsBAA0NDfjwww/x448/QiAQYP78+Th+\n/DgAYOLEiXjsscc6+Fgdgwx1wl2gbiZBEPbASdRfeOEFrF27Fv/9738BAOnp6XjhhRdsXnPgwAHk\n5OQAABISElBbW4uGhgb4+flBKBRCKPz/9u49KKr7/OP457iworIKS3exGi2ETmXqhciPxCrGGAva\niU1n6sQMSY3amtZEO00vGqhlYjIOXqJJzJjO1HqZyVAaaJW2ahtIOxOadLLFSbWoOI6VaRIvDewK\notwU8Pz+MN2udaUgbJZzeL/+ytllD88+s/HDc77nnI1VW1ubRo4cqfb2do0ZM6afb2UA8C8oAMDC\nehXqbrdb3/72t5WSkiJJOnnypNxud4+vCQQCmjx58k378Pv9io+P1/Dhw7V69Wrl5ORo+PDhWrhw\noVJTU3X06FEdPnxYK1asUFdXl/Lz8/XFL37xzt/dnWJUxyDBRxFAX/Qq1F955RU1NDQEp/Of//zn\nuuuuu7RmzZpe/6LQNfiWlhbt3LlTFRUVio+P17Jly3Tq1CllZGTI7XZr7ty5Onr0qPLz83Xw4MEe\n95uYOFIxMY5e19GTESOcN/aZMFIej2tA9jlU0b+B4XDcOJc1bngsPb1D9K3/6GH/fVo97FWoV1dX\nq7S0NLi9fft2PfbYYz2+xuv1KhAIBLcbGhrk8XgkSXV1dZowYUJw2s/KytKJEyf0yCOPKC0tTZI0\nffp0NTY2qru7Ww7H7UO7qamtN2+hV9rar0mSLl1ql3+k/e5t/2nxeFzy++lff3k8LnV3X5ckdVzt\npKd3gM9i/9HD/hvoHvb0B0KvLmnr7OzUtWvXgtutra3q6urq8TXZ2dmqrKyUJNXW1srr9So+Pl6S\nNH78eNXV1amjo0OSdOLECaWkpGjXrl06dOiQJOn06dNyu909BvqAY00dgwwfSQB90atJPS8vTw89\n9JCmTJmi69ev6/jx41q2bFmPr8nMzNTkyZOVl5cnwzC0fv16lZeXy+VyKTc3VytWrNDSpUvlcDg0\nffp0ZWVl6a677tLatWtVWlqqrq4uFRUVDcib7Cu+0AUAYEW9CvXFixcrJSVFTU1NMgxD8+bN086d\nO7V8+fIeX/ffa+7p6enB/87Ly1NeXt5Nz48dO1bFxcW9LH3gcZ06Bhv+vgTQF70K9aKiIv3lL39R\nIBDQxIkTdfbsWX3rW9+KdG0AAKAPerWmfuzYMb355ptKT0/X/v37tXfvXrW3t0e6NgAA0Ae9CnWn\n88alXp2dnTJNU1OmTNGRI0ciWlg08IUuGGz4SALoi14dfk9NTVVJSYmysrL0zW9+U6mpqbpyxb6X\nOHCiHADAinoV6i+88IKam5s1evRo/f73v9fFixe1cuXKSNcGDHn8fQmgL3oV6oZhKCEhQZL08MMP\nR7SgwcDgn1IAgAX1ak19qGBNHQBgZYQ6AAA2QaiH4OYzAAArI9TD4Ox3AIAVEeqhGNQBABZGqAMA\nYBOEeggGdQCAlRHqYRgsqgMALIhQD8WoDgCwMEI9DOZ0AIAVEeohuE4dAGBlhHo4jOoAAAsi1AEA\nsAlCPQQH3wEAVkaoh8HRdwCAFRHqoRjVAQAWRqiHw81nAAAWRKiHYFDHYPNQaq4kKXvcjChXAsAK\nYqJdwGDEnI7B4r6xmfo/b4YcwxzRLgWABTCphzKZ1TH4EOgAeotQD4MldQCAFRHqIZjTAQBWRqgD\nAGAThHoIltQBAFZGqIdhsKgOALAgQv0mjOoAAOsi1MNgTgcAWBGhDgCATRDqIThRDgBgZYR6OBx/\nBwBYEKEegkEdAGBlhHoYDOoAACsi1EMxqgMALIxQD4ebzwAALIhQD2EyqgMALCwmkjvfuHGjampq\nZBiG1q1bp2nTpgWfKykp0YEDBzRs2DBNmTJFP/nJT9TZ2amCggJduHBBDodDmzZt0oQJEyJZYljM\n6QAAK4rYpH748GF9+OGHKisrU1FRkYqKioLPtbS0aM+ePSopKdEbb7yhuro6/f3vf9ehQ4c0evRo\nvfHGG3rqqaf00ksvRaq88BjUAQAWFrFQ9/l8ysnJkSSlpaWpublZLS0tkqTY2FjFxsaqra1NXV1d\nam9v15gxY+Tz+ZSbmytJmjVrlo4cORKp8nrEpA4AsKKIhXogEFBiYmJw2+12y+/3S5KGDx+u1atX\nKycnRw8++KAyMjKUmpqqQCAgt9t9o7Bhw2QYhq5duxapEm/BoA4AsLKIrqmHMkPuwdrS0qKdO3eq\noqJC8fHxWrZsmU6dOtXja24nMXGkYmIcA1JjXFysJCkpKV4e98gB2edQ5fG4ol2CLdDH/qOH/UcP\n++/T6mHEQt3r9SoQCAS3Gxoa5PF4JEl1dXWaMGFCcCrPysrSiRMn5PV65ff7lZ6ers7OTpmmKafT\n2ePvaWpqG7Ca29s7JUkXG1tkdHcP2H6HGo/HJb//SrTLsDz62H/0sP/oYf8NdA97+gMhYoffs7Oz\nVVlZKUmqra2V1+tVfHy8JGn8+PGqq6tTR0eHJOnEiRNKSUlRdna2KioqJElvv/22ZsyYEanyemSw\nqg4AsKCITeqZmZmaPHmy8vLyZBiG1q9fr/LycrlcLuXm5mrFihVaunSpHA6Hpk+frqysLHV3d+u9\n997TY489JqfTqc2bN0eqvNtgVR0AYF2G2ZuF60FsIA9p7DpYK19tvbatmiX36LgB2+9Qw+G6gUEf\n+48e9h897D9bHH4HAACfLkI9hKUPWQAAhjxCHQAAmyDUQzGqAwAsjFAPw+CrVwEAFkSoh2BQBwBY\nGaEOAIBNEOohLH7JPgBgiCPUw2BJHQBgRYQ6AAA2QaiHwaAOALAiQj0ES+oAACsj1MNhUR0AYEGE\neggGdQCAlRHqYTCnAwCsiFAHAMAmCPVQnCkHALAwQj0cjr8DACyIUA/BnA4AsDJCPQwGdQCAFRHq\noRjVAQAWRqiHYXDzGQCABRHqIRjUAQBWRqgDAGAThHoIk+vUAQAWRqiHwZI6AMCKCHUAAGyCUA+D\nQR0AYEWEegiW1AEAVkaoh8WsDgCwHkIdAACbINTD4Ox3AIAVEeoAANgEoR6Cm88AAKyMUAcAwCYI\n9RDM6QAAKyPUw+BEOQCAFRHqAADYBKEehsHNZwAAFkSoh+DkdwCAlRHq4TCoAwAsKCaSO9+4caNq\nampkGIbWrVunadOmSZLq6+u1Zs2a4M+dPXtWP/rRj9TZ2alXX31VEydOlCTNmjVLTz/9dCRLvInJ\n+e8AAAuLWKgfPnxYH374ocrKylRXV6d169aprKxMkpScnKzi4mJJUldXl5544gnNmzdPlZWVeuih\nh5Sfnx+psnqFQR0AYEURO/zu8/mUk5MjSUpLS1Nzc7NaWlpu+bnf/OY3WrBggUaNGhWpUnqPQR0A\nYGERC/VAIKDExMTgttvtlt/vv+Xnfv3rX+uRRx4Jbh8+fFgrVqzQsmXLdPLkyUiV1yOuUwcAWFFE\n19RDhbuv+tGjR3X33XcrPj5ekpSRkSG32625c+fq6NGjys/P18GDB3vcb2LiSMXEOAakxtjYG/v5\nzGdccsYOzD6HKo/HFe0SbIE+9h897D962H+fVg8jFuper1eBQCC43dDQII/Hc9PPVFVVaebMmcHt\ntLQ0paWlSZKmT5+uxsZGdXd3y+G4fcA2NbUNWM3XOrslSYFAi2JjuDDgTnk8Lvn9V6JdhuXRx/6j\nh/1HD/tvoHvY0x8IEUuu7OxsVVZWSpJqa2vl9XqDE/m/HT9+XOnp6cHtXbt26dChQ5Kk06dPy+12\n9xjoAADgPyI2qWdmZmry5MnKy8uTYRhav369ysvL5XK5lJubK0ny+/1KSkoKvubhhx/W2rVrVVpa\nqq6uLhUVFUWqvPC4+wwAwMIiuqYeei26pJumckm3rJePHTs2eKlbNHGiHADAilg4DsGcDgCwMkId\nAACbINRDsKQOALAyQj0M1tQBAFZEqAMAYBOEehgGX+kCALAgQj1EuFvZAgBgFYR6OAzqAAALItQB\nALAJQj0MBnUAgBUR6iFYUgcAWBmhHobBheoAAAsi1EMwqAMArIxQBwDAJgh1AABsglAPxZlyAAAL\nI9T/C+fIAQCsKibaBQwmY5NGqb2zO9plAABwRwj1EMu+MknupHg1NbZGuxQAAPqMw+8hDMNQjIOW\nAACsiQQDAMAmCHUAAGyCUAcAwCYIdQAAbIJQBwDAJgh1AABsglAHAMAmCHUAAGyCUAcAwCYIdQAA\nbIJQBwDAJgzT5EvEAQCwAyZ1AABsglAHAMAmCHUAAGyCUAcAwCYIdQAAbIJQBwDAJmKiXcBgsnHj\nRtXU1MgwDK1bt07Tpk2LdkmD1osvvqi//e1v6urq0sqVKzV16lQ9++yz6u7ulsfj0datW+V0OnXg\nwAG9/vrrGjZsmB599FEtXrw42qUPKh0dHfrqV7+qVatWaebMmfTwDhw4cEC7d+9WTEyMvve972nS\npEn0sQ9aW1uVn5+v5uZmdXZ2avXq1fJ4PHr++eclSZMmTdILL7wgSdq9e7cqKipkGIa++93v6oEH\nHohi5YPD6dOntWrVKi1fvlxLlizRv/71r15//jo7O1VQUKALFy7I4XBo06ZNmjBhQv8KMmGapmlW\nV1eb3/nOd0zTNM0zZ86Yjz76aJQrGrx8Pp/55JNPmqZpmo2NjeYDDzxgFhQUmH/4wx9M0zTNl156\nySwpKTFbW1vN+fPnm5cvXzbb29vNhQsXmk1NTdEsfdB5+eWXzUWLFpn79++nh3egsbHRnD9/vnnl\nyhWzvr7eLCwspI99VFxcbG7bts00TdP8+OOPzQULFphLliwxa2pqTNM0zR/+8IdmVVWV+dFHH5lf\n//rXzatXr5oXL140FyxYYHZ1dUWz9KhrbW01lyxZYhYWFprFxcWmaZp9+vyVl5ebzz//vGmapvnu\nu++azzzzTL9r4vD7J3w+n3JyciRJaWlpam5uVktLS5SrGpzuvfdevfrqq5Kk0aNHq729XdXV1fry\nl78sSXrwwQfl8/lUU1OjqVOnyuVyKS4uTpmZmTpy5Eg0Sx9U6urqdObMGc2dO1eS6OEd8Pl8mjlz\npuLj4+X1erVhwwb62EeJiYm6dOmSJOny5ctKSEjQ+fPng0cq/93D6upq3X///XI6nXK73Ro/frzO\nnDkTzdKjzul0ateuXfJ6vcHH+vL58/l8ys3NlSTNmjVrQD6ThPonAoGAEhMTg9tut1t+vz+KFQ1e\nDodDI0eOlCTt27dPc+bMUXt7u5xOpyQpKSlJfr9fgUBAbrc7+Dp6erMtW7aooKAguE0P++7cuXPq\n6OjQU089pccff1w+n48+9tHChQt14cIF5ebmasmSJXr22Wc1evTo4PP08PZiYmIUFxd302N9+fyF\nPj5s2DAZhqFr1671r6Z+vdrGTO6e+z/96U9/0r59+7R3717Nnz8/+PjtekdP/+O3v/2t7rnnntuu\nn9HD3rt06ZJee+01XbhwQUuXLr2pR/Txf/vd736ncePGac+ePTp16pRWr14tl8sVfJ4e3rm+9m4g\nekqof8Lr9SoQCAS3Gxoa5PF4oljR4Pbuu+/qZz/7mXbv3i2Xy6WRI0eqo6NDcXFxqq+vl9frDdvT\ne+65J4pVDx5VVVU6e/asqqqq9PHHH8vpdNLDO5CUlKTp06crJiZGEydO1KhRo+RwOOhjHxw5ckSz\nZ8+WJKWnp+vq1avq6uoKPh/aw3/+85+3PI6b9eX/Y6/XK7/fr/T0dHV2dso0zeCUf6c4/P6J7Oxs\nVVZWSpJqa2vl9XoVHx8f5aoGpytXrujFF1/Uzp07lZCQIOnGetC/+/fWW2/p/vvvV0ZGho4fP67L\nly+rtbVVR44cUVZWVjRLHzS2b9+u/fv361e/+pUWL16sVatW0cM7MHv2bP31r3/V9evX1dTUpLa2\nNvrYR5/73OdUU1MjSTp//rxGjRqltLQ0vf/++5L+08MvfelLqqqq0rVr11RfX6+GhgZ9/vOfj2bp\ng1JfPn/Z2dmqqKiQJL399tuaMWNGv38/39IWYtu2bXr//fdlGIbWr1+v9PT0aJc0KJWVlWnHjh1K\nTU0NPrZ582YVFhbq6tWrGjdunDZt2qTY2FhVVFRoz549MgxDS5Ys0de+9rUoVj447dixQ+PHj9fs\n2bOVn59PD/uotLRU+/btkyQ9/fTTmjp1Kn3sg9bWVq1bt04XL15UV1eXnnnmGXk8Hj333HO6fv26\nMjIy9OMf/1iSVFxcrIMHD8owDH3/+9/XzJkzo1x9dJ04cUJbtmzR+fPnFRMTo+TkZG3btk0FBQW9\n+vx1d3ersLBQH3zwgZxOpzZv3qzPfvaz/aqJUAcAwCY4/A4AgE0Q6gAA2AShDgCATRDqAADYBKEO\nAIBNEOoAIqa8vFxr1qyJdhnAkEGoAwBgE9wmFoCKi4v15ptvqru7W3fffbeefPJJrVy5UnPmzNGp\nU6ckSa+88oqSk5NVVVWln/70p4qLi9OIESO0YcMGJScnq6amRhs3blRsbKzGjBmjLVu2SJJaWlq0\nZs0a1dXVady4cXrttddkGEY03y5gW0zqwBB37Ngx/fGPf1RJSYnKysrkcrn03nvv6ezZs1q0aJF+\n+ctf6r777tPevXvV3t6uwsJC7dixQ8XFxZozZ462b98uSVq7dq02bNigX/ziF7r33nv15z//WZJ0\n5swZbdiwQeXl5frHP/6h2traaL5dwNaY1IEhrrq6Wh999JGWLl0qSWpra1N9fb0SEhI0ZcoUSVJm\nZqZef/11ffDBB0pKStLYsWMlSffdd59KS0vV2Nioy5cv6wtf+IIkafny5ZJurKlPnTpVI0aMkCQl\nJyfrypUrn/I7BIYOQh0Y4pxOp+bNm6fnnnsu+Ni5c+e0aNGi4LZpmjIM45bD5qGP3+6O0w6H45bX\nAIgMDr8DQ1xmZqbeeecdtba2SpJKSkrk9/vV3NyskydPSrrx9ZyTJk1SSkqKLl68qAsXLkiSfD6f\nMjIylJiYqISEq9UPlgAAALdJREFUBB07dkyStHfvXpWUlETnDQFDGJM6MMRNnTpV3/jGN/TEE09o\n+PDh8nq9mjFjhpKTk1VeXq7NmzfLNE29/PLLiouLU1FRkX7wgx8EvwO+qKhIkrR161Zt3LhRMTEx\ncrlc2rp1q956660ovztgaOFb2gDc4ty5c3r88cf1zjvvRLsUAH3A4XcAAGyCSR0AAJtgUgcAwCYI\ndQAAbIJQBwDAJgh1AABsglAHAMAmCHUAAGzi/wHRZug2ymhotAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7Mz/Aws6mCgf82f4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}